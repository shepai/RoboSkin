{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import letRun #This library can be deleted, it is used for debugging\n",
    "import RoboSkin as sk\n",
    "import cv2 \n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def sigmoid(x):                                        \n",
    "   return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DATA SET CREATOR\n",
    "class dataset:\n",
    "    def __init__(self,names=[\"flat_detection.avi\",\"edge_detection.avi\",\"flat_slip_detection.avi\"]):\n",
    "        self.path=letRun.path\n",
    "        self.names=names\n",
    "        self.SIZE=0.3\n",
    "        name=\"C:/Users/dexte/OneDrive/Documents/AI/Data_Labeller/pickle_imputer_small.pkl\" #use standard imputer or one for small\n",
    "        self.reg=None\n",
    "        with open(name,'rb') as file:\n",
    "            self.reg=pickle.load(file)\n",
    "    def predict(self,reg,dat):\n",
    "        p=reg.predict(dat)\n",
    "        p=(p.reshape((p.shape[0],p.shape[1]//2,2))*255/self.SIZE)\n",
    "        return p\n",
    "    def generate(self,STORE=10,y_labels=[]):\n",
    "        BIG_DATA_X=None\n",
    "        BIG_DATA_y=None\n",
    "        assert len(y_labels)==len(self.names),\"Incorrect length of labels\"\n",
    "        for j,name in enumerate(self.names):\n",
    "            skin=sk.Skin(videoFile=self.path+name)#videoFile=path+\"Movement4.avi\") #load skin object using demo video\n",
    "            cap = cv2.VideoCapture(self.path+name)\n",
    "            length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            skin.sharpen=False #falsify the sharpness if recorded with sharpness\n",
    "            frame=skin.getFrame()\n",
    "            h=frame.shape[1]*self.SIZE\n",
    "            w=frame.shape[0]*self.SIZE\n",
    "            frame=cv2.resize(frame,(int(h),int(w)),interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).flatten()/255\n",
    "            past=self.predict(self.reg,np.array([frame]))[0]\n",
    "            initial=past.copy()\n",
    "            initial_frame=frame.copy()\n",
    "\n",
    "            X=[]\n",
    "            y=[] #label as [edge surface soft hard slippery]\n",
    "            lastFrames=[]\n",
    "            for i in range(length): #lop through all\n",
    "                frame_=skin.getFrame()\n",
    "                frame=cv2.resize(frame_,(int(h),int(w)),interpolation=cv2.INTER_AREA)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).flatten()/255\n",
    "                points=self.predict(self.reg,np.array([frame]))[0]\n",
    "                #get pressure map\n",
    "                diff=np.sum(np.abs(initial_frame-frame))/(frame.shape[0]*3)\n",
    "                vecs=initial-points\n",
    "                lastFrames.append(vecs)\n",
    "                if len(lastFrames)>STORE: lastFrames.pop(0)\n",
    "                if diff>0.01 and len(lastFrames)==STORE: #significant contact\n",
    "                    X.append(np.array(lastFrames)) #store temporal element\n",
    "                    y.append(y_labels[j])\n",
    "            if type(BIG_DATA_y)==type(None):\n",
    "                BIG_DATA_y=np.array(y.copy())\n",
    "                BIG_DATA_X=np.array(X.copy())\n",
    "            else:\n",
    "                BIG_DATA_y= np.concatenate((np.array(y.copy()),BIG_DATA_y))\n",
    "                BIG_DATA_X= np.concatenate((np.array(X.copy()),BIG_DATA_X))\n",
    "        a,b=np.array(BIG_DATA_X),np.array(BIG_DATA_y)\n",
    "        a=a.reshape((a.shape))\n",
    "        return a,b\n",
    "\n",
    "d=dataset()\n",
    "x,y=d.generate(STORE=5,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1032, 2660) (1032, 5)\n",
      "(259, 2660) (259, 5)\n"
     ]
    }
   ],
   "source": [
    "path=\"C:/Users/dexte/github/RoboSkin/Code/Models/labeller/\"\n",
    "lin_path=\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/Models/labeller\"\n",
    "\n",
    "#load datasets\n",
    "X1=np.load(path+\"X_data_push.npy\")\n",
    "y1=np.load(path+\"y_data_push.npy\")\n",
    "\n",
    "X2=np.load(path+\"X_data_edge.npy\")\n",
    "y2=np.load(path+\"y_data_edge.npy\")\n",
    "\n",
    "X3=np.load(path+\"X_data_slip.npy\")\n",
    "y3=np.load(path+\"y_data_slip.npy\")\n",
    "\n",
    "#merge datasets\n",
    "X=np.concatenate([X1,X2,X3])\n",
    "SIZE=X.shape[1]\n",
    "Xa=X.reshape((X.shape[0],133*2*SIZE))/100\n",
    "ya=np.concatenate([y1,y2,y3])/10\n",
    "\n",
    "X, data_test, y, labels_test = train_test_split(Xa, ya, test_size=0.20, random_state=42)\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "print(data_test.shape,labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the size of the input (n) and output (m) layers\n",
    "n_inputs = 133*2*SIZE\n",
    "m_outputs = len(y[0])\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size,layers=[100,10],drop_out_prob=0.2):\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        self.fc=[nn.Linear(input_size, layers[0])]\n",
    "        self.fc.append(nn.ReLU())\n",
    "        self.fc.append(nn.Dropout(p=drop_out_prob))\n",
    "        for i in range(1,len(layers)): #create layers \n",
    "                self.fc.append(nn.Linear(layers[i-1], layers[i]))\n",
    "                self.fc.append(nn.ReLU())\n",
    "                self.fc.append(nn.Dropout(p=drop_out_prob))\n",
    "        self.fc.append(nn.Linear(layers[-1], output_size))\n",
    "        self.fc_layers = nn.Sequential(*self.fc)\n",
    "    def forward(self, x):\n",
    "        x=self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Create the neural network\n",
    "model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def get_acc(model,predictions,should_be=[]):\n",
    "    predictions*=10 #normalize\n",
    "    pred_array=np.zeros_like(predictions)\n",
    "    inds=np.argmax(predictions[:,0:2],axis=1) #convert at threshold\n",
    "    inds2=np.argmax(predictions[:,2:-1],axis=1) #convert at threshold\n",
    "    for i in range(len(pred_array)):\n",
    "        pred_array[i][inds[i]]=1\n",
    "        pred_array[i][2+inds2[i]]=1\n",
    "    correct=0\n",
    "    for j,pred in enumerate(pred_array): #loopthrough predictions\n",
    "        inds=np.where(pred==1) #\n",
    "        if len(should_be)>0: #validation task\n",
    "            sb=should_be[j]*10\n",
    "            sb=np.where(sb==1)\n",
    "            if len(sb[0])==len(inds[0]):\n",
    "                c=0\n",
    "                for i in range(len(sb[0])):\n",
    "                    if sb[0][i]==inds[0][i]: c+=1\n",
    "                if c==len(sb[0]): correct+=1\n",
    "    return correct/len(should_be)\n",
    "\n",
    "def train(model,num_epochs=1500):\n",
    "    loss_ar=[]\n",
    "    accuracies=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        y_pred = model(X_tensor)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(y_pred, y_tensor)\n",
    "\n",
    "        # Zero gradients, backward pass, and update the weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ar.append(loss.item())\n",
    "        #predict\n",
    "        predictions = model(torch.tensor(X, dtype=torch.float32))\n",
    "        accuracies.append(get_acc(model,predictions.detach().numpy(),should_be=y))\n",
    "        # Print the current loss to monitor training progress\n",
    "        if epoch%1000==0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\",\"Accuracy\",accuracies[-1])\n",
    "    return np.array(loss_ar),np.array(accuracies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Loss while training tactile model\")\n",
    "plt.ylabel(\"Loss and accuracy/5\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "a,b=train(model)\n",
    "#plt.plot(a,label=\"Loss\")\n",
    "plt.plot(b,label=\"Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct: 62.54826254826254 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['surface', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['edge', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['edge', 'hard'],\n",
       " ['surface', 'hard']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After training, you can use the trained model for predictions on new data.\n",
    "# For example, if you have new input data 'X_new', you can do:\n",
    "with torch.no_grad():\n",
    "     model.eval()\n",
    "     predictions = model(torch.tensor(data_test, dtype=torch.float32))\n",
    "\n",
    "\n",
    "def predict(predictions,should_be=[]):\n",
    "    predictions*=10 #normalize\n",
    "    pred_array=np.zeros_like(predictions)\n",
    "    inds=np.argmax(predictions[:,0:2],axis=1) #convert at threshold\n",
    "    inds2=np.argmax(predictions[:,2:-1],axis=1) #convert at threshold\n",
    "    for i in range(len(pred_array)):\n",
    "        pred_array[i][inds[i]]=1\n",
    "        pred_array[i][2+inds2[i]]=1\n",
    "    names=[\"edge\", \"surface\", \"soft\", \"hard\", \"slippery\"]\n",
    "    array=[]\n",
    "    correct=0\n",
    "    for j,pred in enumerate(pred_array): #loopthrough predictions\n",
    "        inds=np.where(pred==1) #\n",
    "        ar=[]\n",
    "        if len(should_be)>0: #validation task\n",
    "            sb=should_be[j]*10\n",
    "            sb=np.where(sb==1)\n",
    "            if len(sb[0])==len(inds[0]):\n",
    "                c=0\n",
    "                for i in range(len(sb[0])):\n",
    "                    if sb[0][i]==inds[0][i]: c+=1\n",
    "                if c==len(sb[0]): correct+=1\n",
    "        for i in inds[0]:\n",
    "            ar.append(names[i])\n",
    "        array.append(ar)\n",
    "    if correct!=0: print(\"Percentage correct:\",(correct/len(should_be))*100,\"%\")\n",
    "    return array\n",
    "\n",
    "p=predict(predictions,should_be=labels_test)\n",
    "p[0:10]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "### With and without slippage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial A 0 Acc: 0.0\n",
      "Epoch [1/1500], Loss: 0.0385 Accuracy 0.26453488372093026\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5155038759689923\n",
      "Trial A 1 Acc: 0.3127413127413127\n",
      "Epoch [1/1500], Loss: 0.0473 Accuracy 0.018410852713178296\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5174418604651163\n",
      "Trial A 2 Acc: 0.416988416988417\n",
      "Epoch [1/1500], Loss: 0.0290 Accuracy 0.29457364341085274\n",
      "Epoch [1001/1500], Loss: 0.0007 Accuracy 0.31589147286821706\n",
      "Trial A 3 Acc: 0.46911196911196906\n",
      "Epoch [1/1500], Loss: 0.0278 Accuracy 0.11337209302325581\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5319767441860465\n",
      "Trial A 4 Acc: 0.5003861003861003\n",
      "Epoch [1/1500], Loss: 0.0355 Accuracy 0.5474806201550387\n",
      "Epoch [1001/1500], Loss: 0.0018 Accuracy 0.31589147286821706\n",
      "Trial A 5 Acc: 0.47232947232947237\n",
      "Epoch [1/1500], Loss: 0.0275 Accuracy 0.28294573643410853\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5339147286821705\n",
      "Trial A 6 Acc: 0.4942084942084942\n",
      "Epoch [1/1500], Loss: 0.0514 Accuracy 0.14631782945736435\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5736434108527132\n",
      "Trial A 7 Acc: 0.5106177606177607\n",
      "Epoch [1/1500], Loss: 0.0342 Accuracy 0.5038759689922481\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5329457364341085\n",
      "Trial A 8 Acc: 0.5233805233805234\n",
      "Epoch [1/1500], Loss: 0.0242 Accuracy 0.25387596899224807\n",
      "Epoch [1001/1500], Loss: 0.0006 Accuracy 0.5203488372093024\n",
      "Trial A 9 Acc: 0.5335907335907336\n",
      "Epoch [1/1500], Loss: 0.0360 Accuracy 0.43507751937984496\n",
      "Epoch [1001/1500], Loss: 0.0006 Accuracy 0.5261627906976745\n",
      "Trial A 10 Acc: 0.541944541944542\n",
      "Epoch [1/1500], Loss: 0.0425 Accuracy 0.0009689922480620155\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5358527131782945\n",
      "Trial A 11 Acc: 0.548906048906049\n",
      "Epoch [1/1500], Loss: 0.0260 Accuracy 0.25872093023255816\n",
      "Epoch [1001/1500], Loss: 0.0007 Accuracy 0.5232558139534884\n",
      "Trial A 12 Acc: 0.5547965547965549\n",
      "Epoch [1/1500], Loss: 0.0294 Accuracy 0.0\n",
      "Epoch [1001/1500], Loss: 0.0018 Accuracy 0.31589147286821706\n",
      "Trial A 13 Acc: 0.5388858246001104\n",
      "Epoch [1/1500], Loss: 0.0342 Accuracy 0.015503875968992248\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5387596899224806\n",
      "Trial A 14 Acc: 0.5446589446589447\n",
      "Epoch [1/1500], Loss: 0.0333 Accuracy 0.0009689922480620155\n",
      "Epoch [1001/1500], Loss: 0.0007 Accuracy 0.5358527131782945\n",
      "Trial A 15 Acc: 0.5497104247104247\n",
      "Epoch [1/1500], Loss: 0.0323 Accuracy 0.08042635658914729\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.31589147286821706\n",
      "Trial A 16 Acc: 0.5369066545537134\n",
      "Epoch [1/1500], Loss: 0.0395 Accuracy 0.40310077519379844\n",
      "Epoch [1001/1500], Loss: 0.0018 Accuracy 0.31589147286821706\n",
      "Trial A 17 Acc: 0.5255255255255256\n",
      "Epoch [1/1500], Loss: 0.0240 Accuracy 0.2751937984496124\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5319767441860465\n",
      "Trial A 18 Acc: 0.5307864255232676\n",
      "Epoch [1/1500], Loss: 0.0380 Accuracy 0.1385658914728682\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5222868217054264\n",
      "Trial A 19 Acc: 0.5355212355212355\n",
      "Epoch [1/1500], Loss: 0.0854 Accuracy 0.29844961240310075\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5339147286821705\n",
      "Trial A 20 Acc: 0.5398051112336827\n",
      "Epoch [1/1500], Loss: 0.0252 Accuracy 0.3439922480620155\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5765503875968992\n",
      "Trial A 21 Acc: 0.5436995436995438\n",
      "Epoch [1/1500], Loss: 0.0205 Accuracy 0.2800387596899225\n",
      "Epoch [1001/1500], Loss: 0.0018 Accuracy 0.31589147286821706\n",
      "Trial A 22 Acc: 0.5344972301494041\n",
      "Epoch [1/1500], Loss: 0.0259 Accuracy 0.17829457364341086\n",
      "Epoch [1001/1500], Loss: 0.0014 Accuracy 0.31589147286821706\n",
      "Trial A 23 Acc: 0.5260617760617761\n",
      "Epoch [1/1500], Loss: 0.0732 Accuracy 0.0\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5164728682170543\n",
      "Trial A 24 Acc: 0.5300386100386101\n",
      "Epoch [1/1500], Loss: 0.0348 Accuracy 0.17344961240310078\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.5329457364341085\n",
      "Trial A 25 Acc: 0.5337095337095337\n",
      "Epoch [1/1500], Loss: 0.0354 Accuracy 0.4563953488372093\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5271317829457365\n",
      "Trial A 26 Acc: 0.5371085371085371\n",
      "Epoch [1/1500], Loss: 0.0137 Accuracy 0.2374031007751938\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.31589147286821706\n",
      "Trial A 27 Acc: 0.5297848869277441\n",
      "Epoch [1/1500], Loss: 0.0283 Accuracy 0.01744186046511628\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.5251937984496124\n",
      "Trial A 28 Acc: 0.5330848089468779\n",
      "Epoch [1/1500], Loss: 0.0174 Accuracy 0.20833333333333334\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5348837209302325\n",
      "Trial A 29 Acc: 0.5361647361647361\n",
      "Epoch [1/1500], Loss: 0.0370 Accuracy 0.30910852713178294\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.5368217054263565\n",
      "Trial A 30 Acc: 0.5390459584007972\n",
      "Epoch [1/1500], Loss: 0.0198 Accuracy 0.14631782945736435\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5261627906976745\n",
      "Trial A 31 Acc: 0.5417471042471043\n",
      "Epoch [1/1500], Loss: 0.0324 Accuracy 0.0029069767441860465\n",
      "Epoch [1001/1500], Loss: 0.0006 Accuracy 0.5261627906976745\n",
      "Trial A 32 Acc: 0.5442845442845443\n",
      "Epoch [1/1500], Loss: 0.0433 Accuracy 0.09786821705426356\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.31589147286821706\n",
      "Trial A 33 Acc: 0.5380422439245969\n",
      "Epoch [1/1500], Loss: 0.0622 Accuracy 0.0009689922480620155\n",
      "Epoch [1001/1500], Loss: 0.0006 Accuracy 0.5242248062015504\n",
      "Trial A 34 Acc: 0.5405405405405406\n",
      "Epoch [1/1500], Loss: 0.0297 Accuracy 0.2810077519379845\n",
      "Epoch [1001/1500], Loss: 0.0006 Accuracy 0.5242248062015504\n",
      "Trial A 35 Acc: 0.5429000429000429\n",
      "Epoch [1/1500], Loss: 0.0222 Accuracy 0.26453488372093026\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.31589147286821706\n",
      "Trial A 36 Acc: 0.5372012939580507\n",
      "Epoch [1/1500], Loss: 0.0541 Accuracy 0.12403100775193798\n",
      "Epoch [1001/1500], Loss: 0.0018 Accuracy 0.31589147286821706\n",
      "Trial A 37 Acc: 0.5318024791709002\n",
      "Epoch [1/1500], Loss: 0.0270 Accuracy 0.08624031007751938\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.5251937984496124\n",
      "Trial A 38 Acc: 0.5342045342045342\n",
      "Epoch [1/1500], Loss: 0.0285 Accuracy 0.14631782945736435\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.561046511627907\n",
      "Trial A 39 Acc: 0.5364864864864864\n",
      "Epoch [1/1500], Loss: 0.0436 Accuracy 0.33042635658914726\n",
      "Epoch [1001/1500], Loss: 0.0018 Accuracy 0.31589147286821706\n",
      "Trial A 40 Acc: 0.5315001412562388\n",
      "Epoch [1/1500], Loss: 0.0414 Accuracy 0.0\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5329457364341085\n",
      "Trial A 41 Acc: 0.5337378194521052\n",
      "Epoch [1/1500], Loss: 0.0450 Accuracy 0.1375968992248062\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.5319767441860465\n",
      "Trial A 42 Acc: 0.5358714195923499\n",
      "Epoch [1/1500], Loss: 0.0778 Accuracy 0.15503875968992248\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5678294573643411\n",
      "Trial A 43 Acc: 0.5379080379080379\n",
      "Epoch [1/1500], Loss: 0.0511 Accuracy 0.02131782945736434\n",
      "Epoch [1001/1500], Loss: 0.0006 Accuracy 0.5222868217054264\n",
      "Trial A 44 Acc: 0.5398541398541399\n",
      "Epoch [1/1500], Loss: 0.0468 Accuracy 0.2248062015503876\n",
      "Epoch [1001/1500], Loss: 0.0006 Accuracy 0.5290697674418605\n",
      "Trial A 45 Acc: 0.5417156286721504\n",
      "Epoch [1/1500], Loss: 0.0394 Accuracy 0.3236434108527132\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5746124031007752\n",
      "Trial A 46 Acc: 0.5434979052000328\n",
      "Epoch [1/1500], Loss: 0.0748 Accuracy 0.23546511627906977\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5678294573643411\n",
      "Trial A 47 Acc: 0.5452059202059202\n",
      "Epoch [1/1500], Loss: 0.0341 Accuracy 0.1501937984496124\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5697674418604651\n",
      "Trial A 48 Acc: 0.5468442203136081\n",
      "Epoch [1/1500], Loss: 0.0376 Accuracy 0.29844961240310075\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.31589147286821706\n",
      "Trial A 49 Acc: 0.5425482625482626\n",
      "Epoch [1/1500], Loss: 0.0387 Accuracy 0.3536821705426357\n",
      "Epoch [1001/1500], Loss: 0.0006 Accuracy 0.5203488372093024\n",
      "Trial A 50 Acc: 0.5441744265273677\n",
      "Epoch [1/1500], Loss: 0.0271 Accuracy 0.26744186046511625\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.31589147286821706\n",
      "Trial A 51 Acc: 0.5400950400950401\n",
      "Epoch [1/1500], Loss: 0.0181 Accuracy 0.12887596899224807\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5203488372093024\n",
      "Trial A 52 Acc: 0.541706126611787\n",
      "Epoch [1/1500], Loss: 0.0383 Accuracy 0.0029069767441860465\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.5358527131782945\n",
      "Trial A 53 Acc: 0.5432575432575433\n",
      "Epoch [1/1500], Loss: 0.0426 Accuracy 0.08624031007751938\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5300387596899225\n",
      "Trial A 54 Acc: 0.5447525447525448\n",
      "Epoch [1/1500], Loss: 0.0623 Accuracy 0.01065891472868217\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5368217054263565\n",
      "Trial A 55 Acc: 0.5461941533370105\n",
      "Epoch [1/1500], Loss: 0.0328 Accuracy 0.22286821705426357\n",
      "Epoch [1001/1500], Loss: 0.0006 Accuracy 0.5290697674418605\n",
      "Trial A 56 Acc: 0.5475851791641265\n",
      "Epoch [1/1500], Loss: 0.0455 Accuracy 0.027131782945736434\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.5319767441860465\n",
      "Trial A 57 Acc: 0.548928238583411\n",
      "Epoch [1/1500], Loss: 0.0212 Accuracy 0.001937984496124031\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.5348837209302325\n",
      "Trial A 58 Acc: 0.5502257705647536\n",
      "Epoch [1/1500], Loss: 0.0407 Accuracy 0.0009689922480620155\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5746124031007752\n",
      "Trial A 59 Acc: 0.5514800514800515\n",
      "Epoch [1/1500], Loss: 0.0190 Accuracy 0.07945736434108527\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5416666666666666\n",
      "Trial A 60 Acc: 0.5526932084309134\n",
      "Epoch [1/1500], Loss: 0.0619 Accuracy 0.006782945736434108\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5281007751937985\n",
      "Trial A 61 Acc: 0.5538672312865861\n",
      "Epoch [1/1500], Loss: 0.0389 Accuracy 0.2761627906976744\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5348837209302325\n",
      "Trial A 62 Acc: 0.5550039835754121\n",
      "Epoch [1/1500], Loss: 0.0328 Accuracy 0.27325581395348836\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5736434108527132\n",
      "Trial A 63 Acc: 0.5561052123552124\n",
      "Epoch [1/1500], Loss: 0.0143 Accuracy 0.25193798449612403\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5310077519379846\n",
      "Trial A 64 Acc: 0.5571725571725572\n",
      "Epoch [1/1500], Loss: 0.0476 Accuracy 0.27325581395348836\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.31589147286821706\n",
      "Trial A 65 Acc: 0.5537615537615538\n",
      "Epoch [1/1500], Loss: 0.0366 Accuracy 0.0\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5203488372093024\n",
      "Trial A 66 Acc: 0.5548320175185847\n",
      "Epoch [1/1500], Loss: 0.0235 Accuracy 0.3556201550387597\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5368217054263565\n",
      "Trial A 67 Acc: 0.5558709970474677\n",
      "Epoch [1/1500], Loss: 0.0600 Accuracy 0.22771317829457363\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5193798449612403\n",
      "Trial A 68 Acc: 0.5568798612276873\n",
      "Epoch [1/1500], Loss: 0.0656 Accuracy 0.0\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.5726744186046512\n",
      "Trial A 69 Acc: 0.5578599007170436\n",
      "Epoch [1/1500], Loss: 0.0302 Accuracy 0.24224806201550386\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5368217054263565\n",
      "Trial A 70 Acc: 0.5588123334602209\n",
      "Epoch [1/1500], Loss: 0.0312 Accuracy 0.3546511627906977\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5319767441860465\n",
      "Trial A 71 Acc: 0.5597383097383097\n",
      "Epoch [1/1500], Loss: 0.0152 Accuracy 0.30910852713178294\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.5281007751937985\n",
      "Trial A 72 Acc: 0.5606389168033004\n",
      "Epoch [1/1500], Loss: 0.0606 Accuracy 0.0\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5290697674418605\n",
      "Trial A 73 Acc: 0.5615151831368048\n",
      "Epoch [1/1500], Loss: 0.0311 Accuracy 0.05426356589147287\n",
      "Epoch [1001/1500], Loss: 0.0006 Accuracy 0.5300387596899225\n",
      "Trial A 74 Acc: 0.5623680823680824\n",
      "Epoch [1/1500], Loss: 0.0138 Accuracy 0.0687984496124031\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5271317829457365\n",
      "Trial A 75 Acc: 0.5631985368827475\n",
      "Epoch [1/1500], Loss: 0.0433 Accuracy 0.31589147286821706\n",
      "Epoch [1001/1500], Loss: 0.0006 Accuracy 0.5319767441860465\n",
      "Trial A 76 Acc: 0.5640074211502784\n",
      "Epoch [1/1500], Loss: 0.0327 Accuracy 0.06298449612403101\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.5339147286821705\n",
      "Trial A 77 Acc: 0.5647955647955648\n",
      "Epoch [1/1500], Loss: 0.0363 Accuracy 0.23934108527131784\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5445736434108527\n",
      "Trial A 78 Acc: 0.5655637554371732\n",
      "Epoch [1/1500], Loss: 0.0245 Accuracy 0.3430232558139535\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5707364341085271\n",
      "Trial A 79 Acc: 0.5663127413127413\n",
      "Epoch [1/1500], Loss: 0.0648 Accuracy 0.1560077519379845\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5242248062015504\n",
      "Trial A 80 Acc: 0.5670432337099004\n",
      "Epoch [1/1500], Loss: 0.0290 Accuracy 0.3556201550387597\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.31589147286821706\n",
      "Trial A 81 Acc: 0.5641774178359544\n",
      "Epoch [1/1500], Loss: 0.0421 Accuracy 0.003875968992248062\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.31589147286821706\n",
      "Trial A 82 Acc: 0.5613806577661999\n",
      "Epoch [1/1500], Loss: 0.0315 Accuracy 0.4127906976744186\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5348837209302325\n",
      "Trial A 83 Acc: 0.5621437764294908\n",
      "Epoch [1/1500], Loss: 0.0372 Accuracy 0.47189922480620156\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.5348837209302325\n",
      "Trial A 84 Acc: 0.5628889393595277\n",
      "Epoch [1/1500], Loss: 0.0411 Accuracy 0.06782945736434108\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.5242248062015504\n",
      "Trial A 85 Acc: 0.5636167729190985\n",
      "Epoch [1/1500], Loss: 0.0406 Accuracy 0.06298449612403101\n",
      "Epoch [1001/1500], Loss: 0.0006 Accuracy 0.5717054263565892\n",
      "Trial A 86 Acc: 0.5643278746727023\n",
      "Epoch [1/1500], Loss: 0.0574 Accuracy 0.007751937984496124\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5164728682170543\n",
      "Trial A 87 Acc: 0.565022815022815\n",
      "Epoch [1/1500], Loss: 0.0107 Accuracy 0.27906976744186046\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5348837209302325\n",
      "Trial A 88 Acc: 0.5657021387358466\n",
      "Epoch [1/1500], Loss: 0.0237 Accuracy 0.012596899224806201\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5310077519379846\n",
      "Trial A 89 Acc: 0.5663663663663664\n",
      "Epoch [1/1500], Loss: 0.0354 Accuracy 0.09496124031007752\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.562984496124031\n",
      "Trial A 90 Acc: 0.5670159955874242\n",
      "Epoch [1/1500], Loss: 0.0290 Accuracy 0.22577519379844962\n",
      "Epoch [1001/1500], Loss: 0.0018 Accuracy 0.31589147286821706\n",
      "Trial A 91 Acc: 0.5644619775054558\n",
      "Epoch [1/1500], Loss: 0.0308 Accuracy 0.23255813953488372\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.5290697674418605\n",
      "Trial A 92 Acc: 0.5651181135052104\n",
      "Epoch [1/1500], Loss: 0.0481 Accuracy 0.2558139534883721\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5213178294573644\n",
      "Trial A 93 Acc: 0.5657602891645445\n",
      "Epoch [1/1500], Loss: 0.0336 Accuracy 0.3236434108527132\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5678294573643411\n",
      "Trial A 94 Acc: 0.5663889453363138\n",
      "Epoch [1/1500], Loss: 0.0414 Accuracy 0.18992248062015504\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.5387596899224806\n",
      "Trial A 95 Acc: 0.5670045045045046\n",
      "Epoch [1/1500], Loss: 0.0352 Accuracy 0.0436046511627907\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5397286821705426\n",
      "Trial A 96 Acc: 0.5676073717310831\n",
      "Epoch [1/1500], Loss: 0.0140 Accuracy 0.21124031007751937\n",
      "Epoch [1001/1500], Loss: 0.0009 Accuracy 0.5581395348837209\n",
      "Trial A 97 Acc: 0.5681979355448743\n",
      "Epoch [1/1500], Loss: 0.0279 Accuracy 0.11337209302325581\n",
      "Epoch [1001/1500], Loss: 0.0005 Accuracy 0.5145348837209303\n",
      "Trial A 98 Acc: 0.5687765687765688\n",
      "Epoch [1/1500], Loss: 0.0132 Accuracy 0.45348837209302323\n",
      "Epoch [1001/1500], Loss: 0.0007 Accuracy 0.5213178294573644\n",
      "Trial A 99 Acc: 0.5693436293436294\n",
      "Epoch [1/1500], Loss: 0.0628 Accuracy 0.14728682170542637\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5310077519379846\n",
      "Trial B 0 Acc: 0.0\n",
      "Epoch [1/1500], Loss: 0.0213 Accuracy 0.6568627450980392\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.9101307189542484\n",
      "Trial B 1 Acc: 0.5\n",
      "Epoch [1/1500], Loss: 0.0400 Accuracy 0.05392156862745098\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.8986928104575164\n",
      "Trial B 2 Acc: 0.6666666666666666\n",
      "Epoch [1/1500], Loss: 0.0326 Accuracy 0.33169934640522875\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9771241830065359\n",
      "Trial B 3 Acc: 0.7483766233766234\n",
      "Epoch [1/1500], Loss: 0.0226 Accuracy 0.8937908496732027\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9656862745098039\n",
      "Trial B 4 Acc: 0.7987012987012987\n",
      "Epoch [1/1500], Loss: 0.0398 Accuracy 0.18137254901960784\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9035947712418301\n",
      "Trial B 5 Acc: 0.8322510822510822\n",
      "Epoch [1/1500], Loss: 0.0268 Accuracy 0.12745098039215685\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9395424836601307\n",
      "Trial B 6 Acc: 0.8562152133580705\n",
      "Epoch [1/1500], Loss: 0.0226 Accuracy 0.4068627450980392\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.8986928104575164\n",
      "Trial B 7 Acc: 0.8741883116883117\n",
      "Epoch [1/1500], Loss: 0.0302 Accuracy 0.45751633986928103\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9820261437908496\n",
      "Trial B 8 Acc: 0.8881673881673882\n",
      "Epoch [1/1500], Loss: 0.0432 Accuracy 0.4297385620915033\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9820261437908496\n",
      "Trial B 9 Acc: 0.8993506493506495\n",
      "Epoch [1/1500], Loss: 0.0166 Accuracy 0.6715686274509803\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.9003267973856209\n",
      "Trial B 10 Acc: 0.9085005903187722\n",
      "Epoch [1/1500], Loss: 0.0279 Accuracy 0.45098039215686275\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.9395424836601307\n",
      "Trial B 11 Acc: 0.9161255411255412\n",
      "Epoch [1/1500], Loss: 0.0475 Accuracy 0.4199346405228758\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 12 Acc: 0.8866133866133866\n",
      "Epoch [1/1500], Loss: 0.0614 Accuracy 0.16830065359477125\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9052287581699346\n",
      "Trial B 13 Acc: 0.8947124304267161\n",
      "Epoch [1/1500], Loss: 0.0564 Accuracy 0.26633986928104575\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9787581699346405\n",
      "Trial B 14 Acc: 0.9017316017316017\n",
      "Epoch [1/1500], Loss: 0.0150 Accuracy 0.3366013071895425\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.923202614379085\n",
      "Trial B 15 Acc: 0.9078733766233766\n",
      "Epoch [1/1500], Loss: 0.0174 Accuracy 0.6356209150326797\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.9035947712418301\n",
      "Trial B 16 Acc: 0.9132925897631781\n",
      "Epoch [1/1500], Loss: 0.0439 Accuracy 0.08169934640522876\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.9003267973856209\n",
      "Trial B 17 Acc: 0.9181096681096681\n",
      "Epoch [1/1500], Loss: 0.0214 Accuracy 0.3954248366013072\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9705882352941176\n",
      "Trial B 18 Acc: 0.9224196855775804\n",
      "Epoch [1/1500], Loss: 0.0401 Accuracy 0.3415032679738562\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 19 Acc: 0.9029220779220779\n",
      "Epoch [1/1500], Loss: 0.0326 Accuracy 0.35130718954248363\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9183006535947712\n",
      "Trial B 20 Acc: 0.9075448361162647\n",
      "Epoch [1/1500], Loss: 0.0515 Accuracy 0.553921568627451\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.9003267973856209\n",
      "Trial B 21 Acc: 0.9117473435655253\n",
      "Epoch [1/1500], Loss: 0.0301 Accuracy 0.35784313725490197\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9820261437908496\n",
      "Trial B 22 Acc: 0.9155844155844156\n",
      "Epoch [1/1500], Loss: 0.0150 Accuracy 0.4133986928104575\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9019607843137255\n",
      "Trial B 23 Acc: 0.9191017316017316\n",
      "Epoch [1/1500], Loss: 0.0432 Accuracy 0.08823529411764706\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.8872549019607843\n",
      "Trial B 24 Acc: 0.9223376623376623\n",
      "Epoch [1/1500], Loss: 0.0245 Accuracy 0.4803921568627451\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 25 Acc: 0.9253246753246753\n",
      "Epoch [1/1500], Loss: 0.0307 Accuracy 0.5849673202614379\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9738562091503268\n",
      "Trial B 26 Acc: 0.9280904280904281\n",
      "Epoch [1/1500], Loss: 0.0623 Accuracy 0.3872549019607843\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.8856209150326797\n",
      "Trial B 27 Acc: 0.9306586270871985\n",
      "Epoch [1/1500], Loss: 0.0151 Accuracy 0.7009803921568627\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.9019607843137255\n",
      "Trial B 28 Acc: 0.9330497089117779\n",
      "Epoch [1/1500], Loss: 0.0275 Accuracy 0.4624183006535948\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 29 Acc: 0.9196969696969697\n",
      "Epoch [1/1500], Loss: 0.0477 Accuracy 0.6209150326797386\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.8774509803921569\n",
      "Trial B 30 Acc: 0.9222873900293255\n",
      "Epoch [1/1500], Loss: 0.0547 Accuracy 0.0\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9199346405228758\n",
      "Trial B 31 Acc: 0.9247159090909091\n",
      "Epoch [1/1500], Loss: 0.0130 Accuracy 0.6323529411764706\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9640522875816994\n",
      "Trial B 32 Acc: 0.9269972451790633\n",
      "Epoch [1/1500], Loss: 0.0308 Accuracy 0.4934640522875817\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9624183006535948\n",
      "Trial B 33 Acc: 0.9291443850267379\n",
      "Epoch [1/1500], Loss: 0.0313 Accuracy 0.10784313725490197\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9019607843137255\n",
      "Trial B 34 Acc: 0.9311688311688312\n",
      "Epoch [1/1500], Loss: 0.0209 Accuracy 0.5931372549019608\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9281045751633987\n",
      "Trial B 35 Acc: 0.9330808080808082\n",
      "Epoch [1/1500], Loss: 0.0407 Accuracy 0.2777777777777778\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9869281045751634\n",
      "Trial B 36 Acc: 0.934889434889435\n",
      "Epoch [1/1500], Loss: 0.0452 Accuracy 0.45751633986928103\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9967320261437909\n",
      "Trial B 37 Acc: 0.9366028708133972\n",
      "Epoch [1/1500], Loss: 0.0173 Accuracy 0.36764705882352944\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 38 Acc: 0.9262404262404264\n",
      "Epoch [1/1500], Loss: 0.0659 Accuracy 0.46895424836601307\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9950980392156863\n",
      "Trial B 39 Acc: 0.9280844155844157\n",
      "Epoch [1/1500], Loss: 0.0815 Accuracy 0.32679738562091504\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9117647058823529\n",
      "Trial B 40 Acc: 0.9298384542286983\n",
      "Epoch [1/1500], Loss: 0.0447 Accuracy 0.369281045751634\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9673202614379085\n",
      "Trial B 41 Acc: 0.931508967223253\n",
      "Epoch [1/1500], Loss: 0.0652 Accuracy 0.08006535947712418\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9918300653594772\n",
      "Trial B 42 Acc: 0.9331017819389914\n",
      "Epoch [1/1500], Loss: 0.0874 Accuracy 0.45588235294117646\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 43 Acc: 0.9239964580873674\n",
      "Epoch [1/1500], Loss: 0.0613 Accuracy 0.5196078431372549\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9771241830065359\n",
      "Trial B 44 Acc: 0.9256854256854259\n",
      "Epoch [1/1500], Loss: 0.0134 Accuracy 0.6944444444444444\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.9003267973856209\n",
      "Trial B 45 Acc: 0.9273009599096558\n",
      "Epoch [1/1500], Loss: 0.0509 Accuracy 0.3055555555555556\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9330065359477124\n",
      "Trial B 46 Acc: 0.9288477479966843\n",
      "Epoch [1/1500], Loss: 0.0520 Accuracy 0.016339869281045753\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.988562091503268\n",
      "Trial B 47 Acc: 0.9303300865800868\n",
      "Epoch [1/1500], Loss: 0.0411 Accuracy 0.4166666666666667\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9640522875816994\n",
      "Trial B 48 Acc: 0.93175192154784\n",
      "Epoch [1/1500], Loss: 0.0200 Accuracy 0.7058823529411765\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 49 Acc: 0.923766233766234\n",
      "Epoch [1/1500], Loss: 0.0319 Accuracy 0.1830065359477124\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9852941176470589\n",
      "Trial B 50 Acc: 0.9252610134963078\n",
      "Epoch [1/1500], Loss: 0.0567 Accuracy 0.2565359477124183\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9820261437908496\n",
      "Trial B 51 Acc: 0.9266983016983019\n",
      "Epoch [1/1500], Loss: 0.0184 Accuracy 0.6683006535947712\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 52 Acc: 0.9192599852977215\n",
      "Epoch [1/1500], Loss: 0.0315 Accuracy 0.5228758169934641\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.9150326797385621\n",
      "Trial B 53 Acc: 0.920755170755171\n",
      "Epoch [1/1500], Loss: 0.0236 Accuracy 0.27124183006535946\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9869281045751634\n",
      "Trial B 54 Acc: 0.9221959858323497\n",
      "Epoch [1/1500], Loss: 0.0437 Accuracy 0.17647058823529413\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9934640522875817\n",
      "Trial B 55 Acc: 0.9235853432282006\n",
      "Epoch [1/1500], Loss: 0.0311 Accuracy 0.41013071895424835\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.9019607843137255\n",
      "Trial B 56 Acc: 0.9249259512417409\n",
      "Epoch [1/1500], Loss: 0.0281 Accuracy 0.16830065359477125\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 57 Acc: 0.9181594267801167\n",
      "Epoch [1/1500], Loss: 0.0527 Accuracy 0.6111111111111112\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.9052287581699346\n",
      "Trial B 58 Acc: 0.9195465551397758\n",
      "Epoch [1/1500], Loss: 0.0181 Accuracy 0.545751633986928\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 59 Acc: 0.9130952380952384\n",
      "Epoch [1/1500], Loss: 0.0392 Accuracy 0.46078431372549017\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9787581699346405\n",
      "Trial B 60 Acc: 0.9145199063231854\n",
      "Epoch [1/1500], Loss: 0.0284 Accuracy 0.3284313725490196\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9640522875816994\n",
      "Trial B 61 Acc: 0.915898617511521\n",
      "Epoch [1/1500], Loss: 0.0167 Accuracy 0.08496732026143791\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.8709150326797386\n",
      "Trial B 62 Acc: 0.9172335600907032\n",
      "Epoch [1/1500], Loss: 0.0395 Accuracy 0.0\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.8856209150326797\n",
      "Trial B 63 Acc: 0.918526785714286\n",
      "Epoch [1/1500], Loss: 0.0584 Accuracy 0.016339869281045753\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9068627450980392\n",
      "Trial B 64 Acc: 0.9197802197802201\n",
      "Epoch [1/1500], Loss: 0.0306 Accuracy 0.41013071895424835\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.9084967320261438\n",
      "Trial B 65 Acc: 0.9207988980716256\n",
      "Epoch [1/1500], Loss: 0.0565 Accuracy 0.0016339869281045752\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.8823529411764706\n",
      "Trial B 66 Acc: 0.9219810040705566\n",
      "Epoch [1/1500], Loss: 0.0260 Accuracy 0.05392156862745098\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9166666666666666\n",
      "Trial B 67 Acc: 0.9231283422459896\n",
      "Epoch [1/1500], Loss: 0.0398 Accuracy 0.21568627450980393\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9787581699346405\n",
      "Trial B 68 Acc: 0.9242424242424245\n",
      "Epoch [1/1500], Loss: 0.0194 Accuracy 0.3104575163398693\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9689542483660131\n",
      "Trial B 69 Acc: 0.9253246753246757\n",
      "Epoch [1/1500], Loss: 0.0147 Accuracy 0.7941176470588235\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.8905228758169934\n",
      "Trial B 70 Acc: 0.9263764404609478\n",
      "Epoch [1/1500], Loss: 0.0288 Accuracy 0.3888888888888889\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.9019607843137255\n",
      "Trial B 71 Acc: 0.9273989898989902\n",
      "Epoch [1/1500], Loss: 0.0492 Accuracy 0.058823529411764705\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9133986928104575\n",
      "Trial B 72 Acc: 0.9283935242839355\n",
      "Epoch [1/1500], Loss: 0.0315 Accuracy 0.7418300653594772\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.8937908496732027\n",
      "Trial B 73 Acc: 0.9293611793611797\n",
      "Epoch [1/1500], Loss: 0.0290 Accuracy 0.30718954248366015\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9820261437908496\n",
      "Trial B 74 Acc: 0.9303030303030306\n",
      "Epoch [1/1500], Loss: 0.0446 Accuracy 0.021241830065359478\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.8921568627450981\n",
      "Trial B 75 Acc: 0.9312200956937802\n",
      "Epoch [1/1500], Loss: 0.0519 Accuracy 0.0016339869281045752\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.8970588235294118\n",
      "Trial B 76 Acc: 0.9321133412042506\n",
      "Epoch [1/1500], Loss: 0.0455 Accuracy 0.5016339869281046\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9084967320261438\n",
      "Trial B 77 Acc: 0.9329836829836833\n",
      "Epoch [1/1500], Loss: 0.0092 Accuracy 0.006535947712418301\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 78 Acc: 0.9279138582936054\n",
      "Epoch [1/1500], Loss: 0.0200 Accuracy 0.6519607843137255\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9607843137254902\n",
      "Trial B 79 Acc: 0.9288149350649354\n",
      "Epoch [1/1500], Loss: 0.0313 Accuracy 0.826797385620915\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.8856209150326797\n",
      "Trial B 80 Acc: 0.9296937630270967\n",
      "Epoch [1/1500], Loss: 0.0371 Accuracy 0.46078431372549017\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9003267973856209\n",
      "Trial B 81 Acc: 0.9305511561609126\n",
      "Epoch [1/1500], Loss: 0.0189 Accuracy 0.17647058823529413\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.8839869281045751\n",
      "Trial B 82 Acc: 0.9313878892192148\n",
      "Epoch [1/1500], Loss: 0.0283 Accuracy 0.029411764705882353\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.9052287581699346\n",
      "Trial B 83 Acc: 0.9322047000618432\n",
      "Epoch [1/1500], Loss: 0.0335 Accuracy 0.272875816993464\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.9183006535947712\n",
      "Trial B 84 Acc: 0.9330022918258215\n",
      "Epoch [1/1500], Loss: 0.0408 Accuracy 0.40522875816993464\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.8643790849673203\n",
      "Trial B 85 Acc: 0.933781334944126\n",
      "Epoch [1/1500], Loss: 0.0239 Accuracy 0.49019607843137253\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 86 Acc: 0.9291685326168088\n",
      "Epoch [1/1500], Loss: 0.0489 Accuracy 0.20751633986928106\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.9836601307189542\n",
      "Trial B 87 Acc: 0.9299734356552541\n",
      "Epoch [1/1500], Loss: 0.0115 Accuracy 0.35130718954248363\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 88 Acc: 0.9255070771924708\n",
      "Epoch [1/1500], Loss: 0.0221 Accuracy 0.5441176470588235\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.9215686274509803\n",
      "Trial B 89 Acc: 0.9262626262626266\n",
      "Epoch [1/1500], Loss: 0.0358 Accuracy 0.3464052287581699\n",
      "Epoch [1001/1500], Loss: 0.0001 Accuracy 0.946078431372549\n",
      "Trial B 90 Acc: 0.9270729270729273\n",
      "Epoch [1/1500], Loss: 0.0189 Accuracy 0.3382352941176471\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9722222222222222\n",
      "Trial B 91 Acc: 0.9278656126482216\n",
      "Epoch [1/1500], Loss: 0.0074 Accuracy 0.6650326797385621\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9705882352941176\n",
      "Trial B 92 Acc: 0.9286412512218967\n",
      "Epoch [1/1500], Loss: 0.0050 Accuracy 0.3464052287581699\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 93 Acc: 0.9244266371925949\n",
      "Epoch [1/1500], Loss: 0.0250 Accuracy 0.5310457516339869\n",
      "Epoch [1001/1500], Loss: 0.0003 Accuracy 0.8986928104575164\n",
      "Trial B 94 Acc: 0.9252221462747782\n",
      "Epoch [1/1500], Loss: 0.0264 Accuracy 0.3627450980392157\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9754901960784313\n",
      "Trial B 95 Acc: 0.9260010822510826\n",
      "Epoch [1/1500], Loss: 0.0129 Accuracy 0.5718954248366013\n",
      "Epoch [1001/1500], Loss: 0.0010 Accuracy 0.5392156862745098\n",
      "Trial B 96 Acc: 0.9219440353460975\n",
      "Epoch [1/1500], Loss: 0.0049 Accuracy 0.4477124183006536\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.8790849673202614\n",
      "Trial B 97 Acc: 0.9227405247813414\n",
      "Epoch [1/1500], Loss: 0.0573 Accuracy 0.17647058823529413\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9411764705882353\n",
      "Trial B 98 Acc: 0.9235209235209239\n",
      "Epoch [1/1500], Loss: 0.0321 Accuracy 0.20588235294117646\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.9477124183006536\n",
      "Trial B 99 Acc: 0.9242857142857146\n",
      "Epoch [1/1500], Loss: 0.0257 Accuracy 0.2826797385620915\n",
      "Epoch [1001/1500], Loss: 0.0002 Accuracy 0.8905228758169934\n",
      "Accuracies 0.5755984555984557 0.9342857142857146\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_l1=np.zeros((1500,))\n",
    "average_a1=np.zeros((1500,))\n",
    "\n",
    "X, data_test, y, labels_test = train_test_split(Xa, ya, test_size=0.20, random_state=42)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "p=0\n",
    "TRIALS=100\n",
    "for i in range(TRIALS):\n",
    "    print(\"Trial A\",i,\"Acc:\",p/(i+1))\n",
    "    # Create the neural network\n",
    "    model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    l,a=train(model)\n",
    "    average_l1+=np.array(l)\n",
    "    average_a1+=np.array(a)\n",
    "\n",
    "    #unseen data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(torch.tensor(data_test, dtype=torch.float32))\n",
    "    p+=get_acc(model,predictions,should_be=labels_test)\n",
    "average_l1=average_l1/TRIALS\n",
    "average_a1=average_a1/(TRIALS) #average by 10 and then divide by 5 for scaling\n",
    "p/=TRIALS\n",
    "#plt.plot(average_l,'--',c=\"b\",label=\"Loss with slip data\")\n",
    "plt.plot(average_a1,c=\"b\",label=\"Accuracy with slip data\")\n",
    "\n",
    "\n",
    "#without slippage\n",
    "#merge datasets\n",
    "X=np.concatenate([X1,X2])\n",
    "SIZE=X.shape[1]\n",
    "X=X.reshape((X.shape[0],133*2*SIZE))/100\n",
    "y=np.concatenate([y1,y2])/10\n",
    "\n",
    "X, data_test, y, labels_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "average_l=np.zeros((1500,))\n",
    "average_a=np.zeros((1500,))\n",
    "p_=0\n",
    "\n",
    "for i in range(TRIALS):\n",
    "    print(\"Trial B\",i,\"Acc:\",p_/(i+1))\n",
    "    # Create the neural network\n",
    "    model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    l,a=train(model)\n",
    "    average_l+=np.array(l)\n",
    "    average_a+=np.array(a)\n",
    "    #unseen data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(torch.tensor(data_test, dtype=torch.float32))\n",
    "    p_+=get_acc(model,predictions,should_be=labels_test)\n",
    "\n",
    "average_l=average_l/TRIALS\n",
    "average_a=average_a/(TRIALS) #average by 10 and then divide by 5 for scaling\n",
    "p_/=TRIALS\n",
    "\n",
    "print(\"Accuracies\",p,p_)\n",
    "plt.title(\"Performance of models with and without slippage over 100 trials\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.plot(average_l,c=\"r\",label=\"Loss without slip data\")\n",
    "plt.plot(average_a,c=\"r\",label=\"Accuracy without slip data\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05983560609199703"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.std(average_a),np.std(average_a1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dexte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1500], Loss: 0.0164 Accuracy 0.0\n",
      "Epoch [1001/1500], Loss: 0.0018 Accuracy 0.3223938223938224\n",
      "1\n",
      "Epoch [1/1500], Loss: 0.0368 Accuracy 0.0\n",
      "Epoch [1001/1500], Loss: 0.0004 Accuracy 0.5366795366795367\n"
     ]
    }
   ],
   "source": [
    "TRIALS=1\n",
    "TIMES=15\n",
    "average_a=np.zeros((TIMES,1500))\n",
    "\n",
    "for i in range(TIMES):\n",
    "    print(i)\n",
    "    d=dataset()\n",
    "    x,y=d.generate(STORE=i,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]])\n",
    "    SIZE=x.shape[1]\n",
    "    n_inputs = 133*2*SIZE\n",
    "    m_outputs = len(y[0])\n",
    "    for j in range(TRIALS):\n",
    "        x=x.reshape((x.shape[0],133*2*SIZE))/100\n",
    "        y=y/10\n",
    "        X, data_test, y, labels_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "        \n",
    "        model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "        l,a=train(model)\n",
    "        average_a[i]+=a\n",
    "    average_a[i]/=TRIALS #get average\n",
    "#diplay\n",
    "plt.title(\"Performance of models with different sizes of temporal information\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.plot(average_l,c=\"r\",label=\"Loss without slip data\")\n",
    "for i,dat in enumerate(average_a):\n",
    "    plt.plot(dat,label=\"T=\"+str(i))\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
