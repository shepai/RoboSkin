{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n",
      "GPU: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import letRun #This library can be deleted, it is used for debugging\n",
    "import RoboSkin as sk\n",
    "import cv2 \n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "\n",
    "#if linux\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.version.cuda)\n",
    "print(\"GPU:\",torch.cuda.is_available())\n",
    "def sigmoid(x):                                        \n",
    "   return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DATA SET CREATOR\n",
    "class dataset:\n",
    "    def __init__(self,names=[\"flat_detection.avi\",\"edge_detection.avi\",\"flat_slip_detection.avi\"]):\n",
    "        self.path=letRun.path\n",
    "        self.names=names\n",
    "        self.SIZE=0.3\n",
    "        name=\"\"\n",
    "        if os.name == 'nt':\n",
    "            name=\"C:/Users/dexte/OneDrive/Documents/AI/Data_Labeller/pickle_imputer_small.pkl\" #use standard imputer or one for small\n",
    "        else:\n",
    "            name=\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/Models/TacTip reader/pickle_imputer_small.pkl\" #for linux\n",
    "        self.reg=None\n",
    "        with open(name,'rb') as file:\n",
    "            self.reg=pickle.load(file)\n",
    "    def predict(self,reg,dat):\n",
    "        p=reg.predict(dat)\n",
    "        p=(p.reshape((p.shape[0],p.shape[1]//2,2))*255/self.SIZE)\n",
    "        return p\n",
    "    def generate(self,STORE=5,y_labels=[],scale=False):\n",
    "        BIG_DATA_X=None\n",
    "        BIG_DATA_y=None\n",
    "        assert len(y_labels)>=len(self.names),\"Incorrect length of labels\"\n",
    "        for j,name in enumerate(self.names):\n",
    "            skin=sk.Skin(videoFile=self.path+name)#videoFile=path+\"Movement4.avi\") #load skin object using demo video\n",
    "            cap = cv2.VideoCapture(self.path+name)\n",
    "            length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            skin.sharpen=False #falsify the sharpness if recorded with sharpness\n",
    "            frame=skin.getFrame()\n",
    "            h=frame.shape[1]*self.SIZE\n",
    "            w=frame.shape[0]*self.SIZE\n",
    "            frame=cv2.resize(frame,(int(h),int(w)),interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).flatten()/255\n",
    "            past=self.predict(self.reg,np.array([frame]))[0]\n",
    "            initial=past.copy()\n",
    "            initial_frame=frame.copy()\n",
    "            counter=0\n",
    "            X=[]\n",
    "            y=[] #label as [edge surface soft hard slippery]\n",
    "            lastFrames=[]\n",
    "            gyro=np.zeros((length,6))\n",
    "            try:\n",
    "                gyro=np.load(self.path+name.replace(\".avi\",\"\")+\"_gyro.npy\")\n",
    "            except:\n",
    "                pass\n",
    "            for i in range(length): #lop through all\n",
    "                frame_=skin.getFrame()\n",
    "                frame=cv2.resize(frame_,(int(h),int(w)),interpolation=cv2.INTER_AREA)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).flatten()/255\n",
    "                points=self.predict(self.reg,np.array([frame]))[0]\n",
    "                #get pressure map\n",
    "                diff=np.sum(np.abs(initial_frame-frame))/(frame.shape[0]*3)\n",
    "                vecs=initial-points\n",
    "                lastFrames.append(np.concatenate((vecs.flatten(),gyro[i]*1)))\n",
    "                if len(lastFrames)>STORE: lastFrames.pop(0)\n",
    "                if diff>0.01 and len(lastFrames)==STORE: #significant contact\n",
    "                    X.append(np.array(lastFrames).flatten()) #store temporal element\n",
    "                    y.append(y_labels[j])\n",
    "                    counter+=1\n",
    "            if type(BIG_DATA_y)==type(None):\n",
    "                BIG_DATA_y=np.array(y.copy())\n",
    "                BIG_DATA_X=np.array(X.copy())\n",
    "            else:\n",
    "                BIG_DATA_y= np.concatenate((np.array(y.copy()),BIG_DATA_y))\n",
    "                BIG_DATA_X= np.concatenate((np.array(X.copy()),BIG_DATA_X))\n",
    "            print(name,\"Length:\",counter)\n",
    "        \n",
    "        a,b=np.array(BIG_DATA_X),np.array(BIG_DATA_y)\n",
    "        if scale:\n",
    "            scaler1 = preprocessing.StandardScaler().fit(a)\n",
    "            a = scaler1.transform(a)\n",
    "        return a,b\n",
    "    def generate_average(self,STORE=5,y_labels=[],scale=False):\n",
    "        BIG_DATA_X=None\n",
    "        BIG_DATA_y=None\n",
    "        assert len(y_labels)>=len(self.names),\"Incorrect length of labels\"\n",
    "        for j,name in enumerate(self.names):\n",
    "            skin=sk.Skin(videoFile=self.path+name)#videoFile=path+\"Movement4.avi\") #load skin object using demo video\n",
    "            cap = cv2.VideoCapture(self.path+name)\n",
    "            length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            skin.sharpen=False #falsify the sharpness if recorded with sharpness\n",
    "            frame=skin.getFrame()\n",
    "            h=frame.shape[1]*self.SIZE\n",
    "            w=frame.shape[0]*self.SIZE\n",
    "            frame=cv2.resize(frame,(int(h),int(w)),interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).flatten()/255\n",
    "            past=self.predict(self.reg,np.array([frame]))[0]\n",
    "            initial=past.copy()\n",
    "            initial_frame=frame.copy()\n",
    "\n",
    "            X=[]\n",
    "            y=[] #label as [edge surface soft hard slippery]\n",
    "            lastFrames=[]\n",
    "            gyro=np.zeros((length,6))\n",
    "            try:\n",
    "                gyro=np.load(self.path+name.replace(\".avi\",\"\")+\"_gyro.npy\")\n",
    "            except:\n",
    "                pass\n",
    "            counter=0\n",
    "            for i in range(length): #lop through all\n",
    "                frame_=skin.getFrame()\n",
    "                frame=cv2.resize(frame_,(int(h),int(w)),interpolation=cv2.INTER_AREA)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).flatten()/255\n",
    "                points=self.predict(self.reg,np.array([frame]))[0]\n",
    "                #get pressure map\n",
    "                diff=np.sum(np.abs(initial_frame-frame))/(frame.shape[0]*3)\n",
    "                vecs=initial-points\n",
    "                average=np.average(vecs,axis=0).flatten()\n",
    "                lastFrames.append(np.concatenate((average,gyro[i]/10)))\n",
    "                if len(lastFrames)>STORE: lastFrames.pop(0)\n",
    "                if diff>0.01 and len(lastFrames)==STORE: #significant contact\n",
    "                    X.append(np.array(lastFrames).flatten()) #store temporal element\n",
    "                    y.append(y_labels[j])\n",
    "                    counter+=1\n",
    "            if type(BIG_DATA_y)==type(None):\n",
    "                BIG_DATA_y=np.array(y.copy())\n",
    "                BIG_DATA_X=np.array(X.copy())\n",
    "            else:\n",
    "                BIG_DATA_y= np.concatenate((np.array(y.copy()),BIG_DATA_y))\n",
    "                BIG_DATA_X= np.concatenate((np.array(X.copy()),BIG_DATA_X))\n",
    "            print(name,\"Length:\",counter)\n",
    "        a,b=np.array(BIG_DATA_X),np.array(BIG_DATA_y)\n",
    "        #a=a.reshape((a.shape))\n",
    "        #regulise\n",
    "        if scale:\n",
    "            scaler1 = preprocessing.StandardScaler().fit(a)\n",
    "            a = scaler1.transform(a)\n",
    "        return a,b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gyro plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyro_edge=np.load(letRun.path+\"edge_detection\"+\"_gyro.npy\")\n",
    "gyro_flat=np.load(letRun.path+\"flat_detection\"+\"_gyro.npy\")\n",
    "gyro_slip=np.load(letRun.path+\"flat_slip_detection\"+\"_gyro.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gyro_edge[:,0],label=\"Accelerometer x\")\n",
    "plt.plot(gyro_edge[:,1],label=\"Accelerometer y\")\n",
    "plt.plot(gyro_edge[:,2],label=\"Accelerometer z\")\n",
    "\n",
    "plt.plot(gyro_flat[:,0],label=\"Accelerometer x\")\n",
    "plt.plot(gyro_flat[:,1],label=\"Accelerometer y\")\n",
    "plt.plot(gyro_flat[:,2],label=\"Accelerometer z\")\n",
    "\n",
    "plt.plot(gyro_slip[:,0],label=\"Accelerometer x\")\n",
    "plt.plot(gyro_slip[:,1],label=\"Accelerometer y\")\n",
    "plt.plot(gyro_slip[:,2],label=\"Accelerometer z\")\n",
    "\n",
    "plt.title(\"Accelerometer over time\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gyro_edge[:,3],c=\"g\",label=\"Accelerometer x\")\n",
    "plt.plot(gyro_edge[:,4],c=\"g\",label=\"Accelerometer y\")\n",
    "plt.plot(gyro_edge[:,5],c=\"g\",label=\"Accelerometer z\")\n",
    "\n",
    "plt.plot(gyro_flat[:,3],c=\"r\",label=\"Accelerometer x\")\n",
    "plt.plot(gyro_flat[:,4],c=\"r\",label=\"Accelerometer y\")\n",
    "plt.plot(gyro_flat[:,5],c=\"r\",label=\"Accelerometer z\")\n",
    "\n",
    "plt.plot(gyro_slip[:,3],c=\"b\",label=\"Accelerometer x\")\n",
    "plt.plot(gyro_slip[:,4],c=\"b\",label=\"Accelerometer y\")\n",
    "plt.plot(gyro_slip[:,5],c=\"b\",label=\"Accelerometer z\")\n",
    "\n",
    "plt.title(\"Gyro over time\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/drs25/miniconda3/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Ridge from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat_detection.avi Length: 338\n",
      "edge_detection.avi Length: 262\n",
      "flat_slip_detection.avi Length: 327\n",
      "831556.4168598601\n",
      "(741, 1360) (741, 5)\n",
      "(186, 1360) (186, 5)\n"
     ]
    }
   ],
   "source": [
    "path=\"C:/Users/dexte/github/RoboSkin/Code/Models/labeller/\"\n",
    "lin_path=\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/Models/labeller\"\n",
    "\n",
    "d=dataset()\n",
    "X,ya=d.generate(STORE=5,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]])\n",
    "print(np.sum(X))\n",
    "#Xa=X/10\n",
    "ya=ya/10\n",
    "\n",
    "X, data_test, y, labels_test = train_test_split(X, ya, test_size=0.20, random_state=42)\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "print(data_test.shape,labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the size of the input (n) and output (m) layers\n",
    "n_inputs = X.shape[1]\n",
    "m_outputs = len(y[0])\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size,layers=[500,100,50],drop_out_prob=0.2):\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        self.fc=[nn.Linear(input_size, layers[0])]\n",
    "        self.fc.append(nn.Sigmoid())\n",
    "        self.fc.append(nn.Dropout(p=drop_out_prob))\n",
    "        for i in range(1,len(layers)): #create layers \n",
    "                self.fc.append(nn.Linear(layers[i-1], layers[i]))\n",
    "                self.fc.append(nn.Sigmoid())\n",
    "                self.fc.append(nn.Dropout(p=drop_out_prob))\n",
    "        self.fc.append(nn.Linear(layers[-1], output_size))\n",
    "        self.fc_layers = nn.Sequential(*self.fc)\n",
    "    def forward(self, x):\n",
    "        x=self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Create the neural network\n",
    "model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss() #nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def get_acc(predictions,should_be=[]):\n",
    "    predictions*=10 #normalize\n",
    "    pred_array=np.zeros_like(predictions)\n",
    "\n",
    "    if len(predictions[0])>2:\n",
    "        inds=np.argmax(predictions[:,0:2],axis=1) #convert at threshold\n",
    "        inds2=np.argmax(predictions[:,2:-1],axis=1) #convert at threshold\n",
    "        for i in range(len(pred_array)):\n",
    "            pred_array[i][inds[i]]=1\n",
    "            pred_array[i][2+inds2[i]]=1\n",
    "    else:\n",
    "        inds=np.argmax(predictions,axis=1) #convert at threshold\n",
    "        for i in range(len(pred_array)):\n",
    "            pred_array[i][inds[i]]=1\n",
    "    correct=0\n",
    "    for j,pred in enumerate(pred_array): #loopthrough predictions\n",
    "        inds=np.where(pred==1) #\n",
    "        if len(should_be)>0: #validation task\n",
    "            sb=should_be[j]*10\n",
    "            sb=np.where(sb==1)\n",
    "            if len(sb[0])==len(inds[0]):\n",
    "                c=0\n",
    "                for i in range(len(sb[0])):\n",
    "                    if sb[0][i]==inds[0][i]: c+=1\n",
    "                if c==len(sb[0]): correct+=1\n",
    "    return correct/len(should_be)\n",
    "\n",
    "def train(model,num_epochs=2500):\n",
    "    loss_ar=[]\n",
    "    accuracies=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        y_pred = model(X_tensor)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(y_pred, y_tensor)\n",
    "\n",
    "        # Zero gradients, backward pass, and update the weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ar.append(loss.item())\n",
    "        #predict\n",
    "        predictions = model(torch.tensor(X, dtype=torch.float32).to(device))\n",
    "        accuracies.append(get_acc(predictions.cpu().detach().numpy(),should_be=y))\n",
    "        # Print the current loss to monitor training progress\n",
    "        if epoch%1000==0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\",\"Accuracy\",accuracies[-1])\n",
    "    return np.array(loss_ar),np.array(accuracies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2500], Loss: 0.3087 Accuracy 0.3697705802968961\n",
      "Epoch [1001/2500], Loss: 0.1440 Accuracy 0.6275303643724697\n",
      "Epoch [2001/2500], Loss: 0.1417 Accuracy 0.6477732793522267\n"
     ]
    }
   ],
   "source": [
    "plt.title(\"Loss while training tactile model\")\n",
    "plt.ylabel(\"Loss and accuracy/5\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "a,b=train(model)\n",
    "#plt.plot(a,label=\"Loss\")\n",
    "plt.plot(b,label=\"Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct: 57.52688172043011 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['surface', 'hard'],\n",
       " ['edge', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['edge', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['surface', 'hard']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After training, you can use the trained model for predictions on new data.\n",
    "# For example, if you have new input data 'X_new', you can do:\n",
    "with torch.no_grad():\n",
    "     model.eval()\n",
    "     predictions = model(torch.tensor(data_test, dtype=torch.float32).to(device))\n",
    "\n",
    "\n",
    "def predict(predictions,should_be=[]):\n",
    "    predictions*=10 #normalize\n",
    "    pred_array=np.zeros_like(predictions)\n",
    "    if len(predictions[0])>2:\n",
    "        inds=np.argmax(predictions[:,0:2],axis=1) #convert at threshold\n",
    "        inds2=np.argmax(predictions[:,2:-1],axis=1) #convert at threshold\n",
    "        for i in range(len(pred_array)):\n",
    "            pred_array[i][inds[i]]=1\n",
    "            pred_array[i][2+inds2[i]]=1\n",
    "    else:\n",
    "        inds=np.argmax(predictions,axis=1) #convert at threshold\n",
    "        for i in range(len(pred_array)):\n",
    "            pred_array[i][inds[i]]=1\n",
    "    names=[\"edge\", \"surface\", \"soft\", \"hard\", \"slippery\"]\n",
    "    array=[]\n",
    "    correct=0\n",
    "    for j,pred in enumerate(pred_array): #loopthrough predictions\n",
    "        inds=np.where(pred==1) #\n",
    "        ar=[]\n",
    "        if len(should_be)>0: #validation task\n",
    "            sb=should_be[j]*10\n",
    "            sb=np.where(sb==1)\n",
    "            if len(sb[0])==len(inds[0]):\n",
    "                c=0\n",
    "                for i in range(len(sb[0])):\n",
    "                    if sb[0][i]==inds[0][i]: c+=1\n",
    "                if c==len(sb[0]): correct+=1\n",
    "        for i in inds[0]:\n",
    "            ar.append(names[i])\n",
    "        array.append(ar)\n",
    "    if correct!=0: print(\"Percentage correct:\",(correct/len(should_be))*100,\"%\")\n",
    "    return array\n",
    "\n",
    "p=predict(predictions.cpu(),should_be=labels_test)\n",
    "p[0:10]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "### With and without slippage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/drs25/miniconda3/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Ridge from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m#without slippage\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#merge datasets\u001b[39;00m\n\u001b[1;32m      4\u001b[0m d\u001b[39m=\u001b[39mdataset(names\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mflat_detection.avi\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39medge_detection.avi\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m X,ya\u001b[39m=\u001b[39md\u001b[39m.\u001b[39;49mgenerate(STORE\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,y_labels\u001b[39m=\u001b[39;49m[[\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m]])\n\u001b[1;32m      6\u001b[0m Xa\u001b[39m=\u001b[39mX\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m\n\u001b[1;32m      7\u001b[0m ya\u001b[39m=\u001b[39mya\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m\n",
      "Cell \u001b[0;32mIn[22], line 46\u001b[0m, in \u001b[0;36mdataset.generate\u001b[0;34m(self, STORE, y_labels, scale)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(length): \u001b[39m#lop through all\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     frame_\u001b[39m=\u001b[39mskin\u001b[39m.\u001b[39;49mgetFrame()\n\u001b[1;32m     47\u001b[0m     frame\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mresize(frame_,(\u001b[39mint\u001b[39m(h),\u001b[39mint\u001b[39m(w)),interpolation\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_AREA)\n\u001b[1;32m     48\u001b[0m     frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\u001b[39m.\u001b[39mflatten()\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/RoboSkin/Code/RoboSkin/__init__.py:113\u001b[0m, in \u001b[0;36mSkin.getFrame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m# Applying CLAHE to L-channel\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m# feel free to try different values for the limit and grid size:\u001b[39;00m\n\u001b[1;32m    112\u001b[0m clahe \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcreateCLAHE(clipLimit\u001b[39m=\u001b[39m\u001b[39m4.0\u001b[39m, tileGridSize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m8\u001b[39m))\n\u001b[0;32m--> 113\u001b[0m cl \u001b[39m=\u001b[39m clahe\u001b[39m.\u001b[39;49mapply(l_channel)\n\u001b[1;32m    115\u001b[0m \u001b[39m# merge the CLAHE enhanced L-channel with the a and b channel\u001b[39;00m\n\u001b[1;32m    116\u001b[0m limg \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mmerge((cl,a,b))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRIALS=100\n",
    "#without slippage\n",
    "#merge datasets\n",
    "d=dataset(names=[\"flat_detection.avi\",\"edge_detection.avi\"])\n",
    "X,ya=d.generate(STORE=5,y_labels=[[0,1,0,1,0],[1,0,0,1,0]])\n",
    "Xa=X/100\n",
    "ya=ya/10\n",
    "\n",
    "X, data_test, y, labels_test = train_test_split(Xa, ya, test_size=0.20, random_state=42)\n",
    "\n",
    "average_a=np.zeros((2500,))\n",
    "p_=0\n",
    "\n",
    "for i in range(TRIALS):\n",
    "    print(\"Trial B\",i,\"Acc:\",p_/(i+1))\n",
    "    # Create the neural network\n",
    "    model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    l,a=train(model)\n",
    "    average_a+=np.array(a)\n",
    "    #unseen data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(torch.tensor(data_test, dtype=torch.float32).to(device))\n",
    "    p_+=get_acc(predictions.cpu(),should_be=labels_test)\n",
    "\n",
    "average_a=average_a/(TRIALS) #average by 10 and then divide by 5 for scaling\n",
    "p_/=TRIALS\n",
    "\n",
    "average_a1=np.zeros((2500,))\n",
    "\n",
    "d=dataset()\n",
    "X,ya=d.generate(STORE=5,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]])\n",
    "Xa=X/100\n",
    "ya=ya/10\n",
    "\n",
    "X, data_test, y, labels_test = train_test_split(Xa, ya, test_size=0.20, random_state=42)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "p=0\n",
    "for i in range(TRIALS):\n",
    "    print(\"Trial A\",i,\"Acc:\",p/(i+1))\n",
    "    # Create the neural network\n",
    "    model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    l,a=train(model)\n",
    "    average_a1+=np.array(a)\n",
    "\n",
    "    #unseen data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(torch.tensor(data_test, dtype=torch.float32).to(device))\n",
    "    p+=get_acc(predictions.cpu(),should_be=labels_test)\n",
    "average_a1=average_a1/(TRIALS) #average by 10 and then divide by 5 for scaling\n",
    "p/=TRIALS\n",
    "#plt.plot(average_l,'--',c=\"b\",label=\"Loss with slip data\")\n",
    "plt.plot(average_a1,c=\"b\",label=\"Accuracy with slip data\")\n",
    "\n",
    "\n",
    "print(\"Accuracies\",p,p_)\n",
    "plt.title(\"Performance of models with and without slippage over 100 trials\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.plot(average_l,c=\"r\",label=\"Loss without slip data\")\n",
    "plt.plot(average_a,c=\"r\",label=\"Accuracy without slip data\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(np.std(average_a),np.std(average_a1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path+\"BignetNoSlip\",average_a)\n",
    "np.save(path+\"Bignet\",average_a1)\n",
    "\n",
    "\n",
    "ar1=np.load(path+\"40netNoSlip.npy\")\n",
    "ar2=np.load(path+\"40net.npy\")\n",
    "plt.title(\"Performance of models with and without slippage over 100 trials\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.plot(average_l,c=\"r\",label=\"Loss without slip data\")\n",
    "plt.plot(ar1,c=\"g\",label=\"Accuracy compressed input without slip data\")\n",
    "plt.plot(ar2,c=\"y\",label=\"Accuracy compressed input\")\n",
    "plt.plot(average_a,c=\"r\",label=\"Accuracy without slip data\")\n",
    "plt.plot(average_a1,c=\"b\",label=\"Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With or without compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/drs25/miniconda3/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Ridge from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TRIALS=50\n",
    "num_epochs=3500\n",
    "average_a1=np.zeros((num_epochs,))\n",
    "\n",
    "d=dataset()\n",
    "X,ya=d.generate_average(STORE=5,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]],scale=True)\n",
    "Xa=X/100\n",
    "ya=ya/10\n",
    "n_inputs=X.shape[1]\n",
    "X, data_test, y, labels_test = train_test_split(Xa, ya, test_size=0.20, random_state=42)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "p=0\n",
    "for i in range(TRIALS):\n",
    "    print(\"Trial A\",i,\"Acc:\",p/(i+1))\n",
    "    # Create the neural network\n",
    "    model = SimpleNeuralNetwork(n_inputs, m_outputs,layers=[100,50,10]).to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    l,a=train(model,num_epochs)\n",
    "    average_a1+=np.array(a)\n",
    "\n",
    "    #unseen data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(torch.tensor(data_test, dtype=torch.float32).to(device))\n",
    "    p+=get_acc(predictions.cpu(),should_be=labels_test)\n",
    "average_a1=average_a1/(TRIALS) #average by 10 and then divide by 5 for scaling\n",
    "p/=TRIALS\n",
    "#plt.plot(average_l,'--',c=\"b\",label=\"Loss with slip data\")\n",
    "plt.plot(average_a1,c=\"b\",label=\"Accuracy with slip data\")\n",
    "\n",
    "\n",
    "print(\"Accuracies\",p,p_)\n",
    "plt.title(\"Performance of models with and without slippage over 100 trials\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.plot(average_l,c=\"r\",label=\"Loss without slip data\")\n",
    "plt.plot(average_a,c=\"r\",label=\"Accuracy without slip data\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(np.std(average_a),np.std(average_a1))\n",
    "\n",
    "average_a2=np.zeros((num_epochs,))\n",
    "\n",
    "d=dataset()\n",
    "X,ya=d.generate(STORE=5,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]],scale=True)\n",
    "Xa=X/100\n",
    "ya=ya/10\n",
    "n_inputs=X.shape[1]\n",
    "X, data_test, y, labels_test = train_test_split(Xa, ya, test_size=0.20, random_state=42)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "p=0\n",
    "for i in range(TRIALS):\n",
    "    print(\"Trial A\",i,\"Acc:\",p/(i+1))\n",
    "    # Create the neural network\n",
    "    model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    l,a=train(model,num_epochs)\n",
    "    average_a2+=np.array(a)\n",
    "\n",
    "    #unseen data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(torch.tensor(data_test, dtype=torch.float32).to(device))\n",
    "    p+=get_acc(predictions.cpu(),should_be=labels_test)\n",
    "average_a2=average_a2/(TRIALS) #average by 10 and then divide by 5 for scaling\n",
    "p/=TRIALS\n",
    "#plt.plot(average_l,'--',c=\"b\",label=\"Loss with slip data\")\n",
    "plt.plot(average_a1,c=\"b\",label=\"With compression\")\n",
    "\n",
    "\n",
    "print(\"Accuracies\",p,p_)\n",
    "plt.title(\"Performance of models with and without slippage over 100 trials\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.plot(average_l,c=\"r\",label=\"Loss without slip data\")\n",
    "plt.plot(average_a2,c=\"r\",label=\"Without compression\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(np.std(average_a),np.std(average_a1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With or without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/drs25/miniconda3/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Ridge from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat_detection.avi Length: 338\n",
      "edge_detection.avi Length: 262\n",
      "flat_slip_detection.avi Length: 327\n",
      "Trial A 0 Acc: 0.0\n",
      "Epoch [1/3500], Loss: 0.1813 Accuracy 0.3643724696356275\n",
      "Epoch [1001/3500], Loss: 0.0120 Accuracy 0.22267206477732793\n",
      "Epoch [2001/3500], Loss: 0.0077 Accuracy 0.24561403508771928\n",
      "Epoch [3001/3500], Loss: 0.0055 Accuracy 0.26450742240215924\n",
      "Trial A 1 Acc: 0.17204301075268819\n",
      "Epoch [1/3500], Loss: 0.0760 Accuracy 0.3252361673414305\n",
      "Epoch [1001/3500], Loss: 0.0130 Accuracy 0.19973009446693657\n",
      "Epoch [2001/3500], Loss: 0.0085 Accuracy 0.242914979757085\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.28475033738191635\n",
      "Trial A 2 Acc: 0.22939068100358426\n",
      "Epoch [1/3500], Loss: 0.1676 Accuracy 0.17813765182186234\n",
      "Epoch [1001/3500], Loss: 0.0132 Accuracy 0.2321187584345479\n",
      "Epoch [2001/3500], Loss: 0.0084 Accuracy 0.22941970310391363\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.24561403508771928\n",
      "Trial A 3 Acc: 0.25806451612903225\n",
      "Epoch [1/3500], Loss: 0.0617 Accuracy 0.17408906882591094\n",
      "Epoch [1001/3500], Loss: 0.0142 Accuracy 0.21592442645074225\n",
      "Epoch [2001/3500], Loss: 0.0088 Accuracy 0.2564102564102564\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.24021592442645073\n",
      "Trial A 4 Acc: 0.2752688172043011\n",
      "Epoch [1/3500], Loss: 0.0408 Accuracy 0.22402159244264508\n",
      "Epoch [1001/3500], Loss: 0.0142 Accuracy 0.22807017543859648\n",
      "Epoch [2001/3500], Loss: 0.0089 Accuracy 0.26855600539811064\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.2564102564102564\n",
      "Trial A 5 Acc: 0.28673835125448033\n",
      "Epoch [1/3500], Loss: 0.1248 Accuracy 0.0728744939271255\n",
      "Epoch [1001/3500], Loss: 0.0121 Accuracy 0.242914979757085\n",
      "Epoch [2001/3500], Loss: 0.0082 Accuracy 0.26450742240215924\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.26720647773279355\n",
      "Trial A 6 Acc: 0.2949308755760369\n",
      "Epoch [1/3500], Loss: 0.1078 Accuracy 0.2874493927125506\n",
      "Epoch [1001/3500], Loss: 0.0123 Accuracy 0.21592442645074225\n",
      "Epoch [2001/3500], Loss: 0.0085 Accuracy 0.26045883940620784\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.2699055330634278\n",
      "Trial A 7 Acc: 0.30107526881720437\n",
      "Epoch [1/3500], Loss: 0.0360 Accuracy 0.2699055330634278\n",
      "Epoch [1001/3500], Loss: 0.0140 Accuracy 0.19838056680161945\n",
      "Epoch [2001/3500], Loss: 0.0087 Accuracy 0.20647773279352227\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.2550607287449393\n",
      "Trial A 8 Acc: 0.3058542413381124\n",
      "Epoch [1/3500], Loss: 0.0603 Accuracy 0.08367071524966262\n",
      "Epoch [1001/3500], Loss: 0.0132 Accuracy 0.23346828609986506\n",
      "Epoch [2001/3500], Loss: 0.0088 Accuracy 0.23616734143049933\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.25371120107962214\n",
      "Trial A 9 Acc: 0.3096774193548388\n",
      "Epoch [1/3500], Loss: 0.1226 Accuracy 0.002699055330634278\n",
      "Epoch [1001/3500], Loss: 0.0137 Accuracy 0.252361673414305\n",
      "Epoch [2001/3500], Loss: 0.0090 Accuracy 0.24426450742240216\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.27125506072874495\n",
      "Trial A 10 Acc: 0.3128054740957968\n",
      "Epoch [1/3500], Loss: 0.0752 Accuracy 0.3090418353576248\n",
      "Epoch [1001/3500], Loss: 0.0139 Accuracy 0.21052631578947367\n",
      "Epoch [2001/3500], Loss: 0.0089 Accuracy 0.24426450742240216\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.252361673414305\n",
      "Trial A 11 Acc: 0.3154121863799284\n",
      "Epoch [1/3500], Loss: 0.0312 Accuracy 0.2726045883940621\n",
      "Epoch [1001/3500], Loss: 0.0120 Accuracy 0.23751686909581646\n",
      "Epoch [2001/3500], Loss: 0.0082 Accuracy 0.23616734143049933\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.25101214574898784\n",
      "Trial A 12 Acc: 0.31761786600496283\n",
      "Epoch [1/3500], Loss: 0.0599 Accuracy 0.3468286099865047\n",
      "Epoch [1001/3500], Loss: 0.0120 Accuracy 0.23751686909581646\n",
      "Epoch [2001/3500], Loss: 0.0078 Accuracy 0.2550607287449393\n",
      "Epoch [3001/3500], Loss: 0.0055 Accuracy 0.27530364372469635\n",
      "Trial A 13 Acc: 0.31950844854070665\n",
      "Epoch [1/3500], Loss: 0.1040 Accuracy 0.0\n",
      "Epoch [1001/3500], Loss: 0.0119 Accuracy 0.24156545209176788\n",
      "Epoch [2001/3500], Loss: 0.0081 Accuracy 0.24426450742240216\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.2807017543859649\n",
      "Trial A 14 Acc: 0.3211469534050179\n",
      "Epoch [1/3500], Loss: 0.2002 Accuracy 0.018893387314439947\n",
      "Epoch [1001/3500], Loss: 0.0132 Accuracy 0.2550607287449393\n",
      "Epoch [2001/3500], Loss: 0.0085 Accuracy 0.26450742240215924\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.2901484480431849\n",
      "Trial A 15 Acc: 0.3225806451612903\n",
      "Epoch [1/3500], Loss: 0.0794 Accuracy 0.21997300944669365\n",
      "Epoch [1001/3500], Loss: 0.0126 Accuracy 0.21862348178137653\n",
      "Epoch [2001/3500], Loss: 0.0084 Accuracy 0.22807017543859648\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.2591093117408907\n",
      "Trial A 16 Acc: 0.3238456672991777\n",
      "Epoch [1/3500], Loss: 0.1679 Accuracy 0.0\n",
      "Epoch [1001/3500], Loss: 0.0123 Accuracy 0.20647773279352227\n",
      "Epoch [2001/3500], Loss: 0.0087 Accuracy 0.242914979757085\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.25371120107962214\n",
      "Trial A 17 Acc: 0.3249701314217443\n",
      "Epoch [1/3500], Loss: 0.1634 Accuracy 0.27125506072874495\n",
      "Epoch [1001/3500], Loss: 0.0134 Accuracy 0.23076923076923078\n",
      "Epoch [2001/3500], Loss: 0.0083 Accuracy 0.24561403508771928\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.2726045883940621\n",
      "Trial A 18 Acc: 0.3259762308998302\n",
      "Epoch [1/3500], Loss: 0.1101 Accuracy 0.010796221322537112\n",
      "Epoch [1001/3500], Loss: 0.0123 Accuracy 0.22402159244264508\n",
      "Epoch [2001/3500], Loss: 0.0080 Accuracy 0.26720647773279355\n",
      "Epoch [3001/3500], Loss: 0.0056 Accuracy 0.25371120107962214\n",
      "Trial A 19 Acc: 0.32688172043010744\n",
      "Epoch [1/3500], Loss: 0.1046 Accuracy 0.012145748987854251\n",
      "Epoch [1001/3500], Loss: 0.0144 Accuracy 0.21187584345479082\n",
      "Epoch [2001/3500], Loss: 0.0092 Accuracy 0.24561403508771928\n",
      "Epoch [3001/3500], Loss: 0.0063 Accuracy 0.2388663967611336\n",
      "Trial A 20 Acc: 0.32770097286226313\n",
      "Epoch [1/3500], Loss: 0.1723 Accuracy 0.0\n",
      "Epoch [1001/3500], Loss: 0.0131 Accuracy 0.2388663967611336\n",
      "Epoch [2001/3500], Loss: 0.0085 Accuracy 0.22672064777327935\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.27125506072874495\n",
      "Trial A 21 Acc: 0.32844574780058644\n",
      "Epoch [1/3500], Loss: 0.0787 Accuracy 0.2766531713900135\n",
      "Epoch [1001/3500], Loss: 0.0133 Accuracy 0.23481781376518218\n",
      "Epoch [2001/3500], Loss: 0.0088 Accuracy 0.2483130904183536\n",
      "Epoch [3001/3500], Loss: 0.0057 Accuracy 0.28205128205128205\n",
      "Trial A 22 Acc: 0.32912575970079466\n",
      "Epoch [1/3500], Loss: 0.1608 Accuracy 0.36707152496626183\n",
      "Epoch [1001/3500], Loss: 0.0131 Accuracy 0.21592442645074225\n",
      "Epoch [2001/3500], Loss: 0.0082 Accuracy 0.24156545209176788\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.28475033738191635\n",
      "Trial A 23 Acc: 0.3297491039426522\n",
      "Epoch [1/3500], Loss: 0.1272 Accuracy 0.3427800269905533\n",
      "Epoch [1001/3500], Loss: 0.0126 Accuracy 0.22807017543859648\n",
      "Epoch [2001/3500], Loss: 0.0082 Accuracy 0.242914979757085\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.2726045883940621\n",
      "Trial A 24 Acc: 0.33032258064516123\n",
      "Epoch [1/3500], Loss: 0.0496 Accuracy 0.33738191632928477\n",
      "Epoch [1001/3500], Loss: 0.0123 Accuracy 0.21592442645074225\n",
      "Epoch [2001/3500], Loss: 0.0080 Accuracy 0.24561403508771928\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.300944669365722\n",
      "Trial A 25 Acc: 0.33085194375516946\n",
      "Epoch [1/3500], Loss: 0.1546 Accuracy 0.3252361673414305\n",
      "Epoch [1001/3500], Loss: 0.0135 Accuracy 0.23346828609986506\n",
      "Epoch [2001/3500], Loss: 0.0085 Accuracy 0.24561403508771928\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.2807017543859649\n",
      "Trial A 26 Acc: 0.3313420947829549\n",
      "Epoch [1/3500], Loss: 0.0915 Accuracy 0.06612685560053981\n",
      "Epoch [1001/3500], Loss: 0.0125 Accuracy 0.24426450742240216\n",
      "Epoch [2001/3500], Loss: 0.0083 Accuracy 0.23346828609986506\n",
      "Epoch [3001/3500], Loss: 0.0057 Accuracy 0.27125506072874495\n",
      "Trial A 27 Acc: 0.33179723502304137\n",
      "Epoch [1/3500], Loss: 0.2375 Accuracy 0.18083670715249664\n",
      "Epoch [1001/3500], Loss: 0.0139 Accuracy 0.22267206477732793\n",
      "Epoch [2001/3500], Loss: 0.0089 Accuracy 0.25775978407557354\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.23076923076923078\n",
      "Trial A 28 Acc: 0.3322209862810529\n",
      "Epoch [1/3500], Loss: 0.0494 Accuracy 0.2483130904183536\n",
      "Epoch [1001/3500], Loss: 0.0142 Accuracy 0.20107962213225372\n",
      "Epoch [2001/3500], Loss: 0.0087 Accuracy 0.22267206477732793\n",
      "Epoch [3001/3500], Loss: 0.0063 Accuracy 0.24021592442645073\n",
      "Trial A 29 Acc: 0.332616487455197\n",
      "Epoch [1/3500], Loss: 0.0844 Accuracy 0.16059379217273953\n",
      "Epoch [1001/3500], Loss: 0.0143 Accuracy 0.22672064777327935\n",
      "Epoch [2001/3500], Loss: 0.0090 Accuracy 0.23616734143049933\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.26045883940620784\n",
      "Trial A 30 Acc: 0.33298647242455764\n",
      "Epoch [1/3500], Loss: 0.0721 Accuracy 0.2591093117408907\n",
      "Epoch [1001/3500], Loss: 0.0127 Accuracy 0.22402159244264508\n",
      "Epoch [2001/3500], Loss: 0.0086 Accuracy 0.25775978407557354\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.25101214574898784\n",
      "Trial A 31 Acc: 0.3333333333333332\n",
      "Epoch [1/3500], Loss: 0.1311 Accuracy 0.24696356275303644\n",
      "Epoch [1001/3500], Loss: 0.0126 Accuracy 0.2321187584345479\n",
      "Epoch [2001/3500], Loss: 0.0085 Accuracy 0.2321187584345479\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.25775978407557354\n",
      "Trial A 32 Acc: 0.3336591723688497\n",
      "Epoch [1/3500], Loss: 0.1035 Accuracy 0.300944669365722\n",
      "Epoch [1001/3500], Loss: 0.0138 Accuracy 0.24021592442645073\n",
      "Epoch [2001/3500], Loss: 0.0091 Accuracy 0.2726045883940621\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.2591093117408907\n",
      "Trial A 33 Acc: 0.3339658444022769\n",
      "Epoch [1/3500], Loss: 0.1062 Accuracy 0.24696356275303644\n",
      "Epoch [1001/3500], Loss: 0.0124 Accuracy 0.23481781376518218\n",
      "Epoch [2001/3500], Loss: 0.0079 Accuracy 0.2388663967611336\n",
      "Epoch [3001/3500], Loss: 0.0056 Accuracy 0.24426450742240216\n",
      "Trial A 34 Acc: 0.3342549923195083\n",
      "Epoch [1/3500], Loss: 0.2264 Accuracy 0.04723346828609987\n",
      "Epoch [1001/3500], Loss: 0.0137 Accuracy 0.20107962213225372\n",
      "Epoch [2001/3500], Loss: 0.0087 Accuracy 0.24426450742240216\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.2591093117408907\n",
      "Trial A 35 Acc: 0.3345280764635602\n",
      "Epoch [1/3500], Loss: 0.2083 Accuracy 0.31713900134952766\n",
      "Epoch [1001/3500], Loss: 0.0134 Accuracy 0.2078272604588394\n",
      "Epoch [2001/3500], Loss: 0.0086 Accuracy 0.24696356275303644\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.27800269905533065\n",
      "Trial A 36 Acc: 0.3347863993025282\n",
      "Epoch [1/3500], Loss: 0.0606 Accuracy 0.1700404858299595\n",
      "Epoch [1001/3500], Loss: 0.0134 Accuracy 0.21727395411605938\n",
      "Epoch [2001/3500], Loss: 0.0089 Accuracy 0.24426450742240216\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.252361673414305\n",
      "Trial A 37 Acc: 0.3350311262026031\n",
      "Epoch [1/3500], Loss: 0.0644 Accuracy 0.05668016194331984\n",
      "Epoch [1001/3500], Loss: 0.0135 Accuracy 0.22267206477732793\n",
      "Epoch [2001/3500], Loss: 0.0093 Accuracy 0.2483130904183536\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.2631578947368421\n",
      "Trial A 38 Acc: 0.3352633030052383\n",
      "Epoch [1/3500], Loss: 0.1023 Accuracy 0.2807017543859649\n",
      "Epoch [1001/3500], Loss: 0.0132 Accuracy 0.25775978407557354\n",
      "Epoch [2001/3500], Loss: 0.0089 Accuracy 0.2550607287449393\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.28609986504723345\n",
      "Trial A 39 Acc: 0.3354838709677418\n",
      "Epoch [1/3500], Loss: 0.0882 Accuracy 0.23076923076923078\n",
      "Epoch [1001/3500], Loss: 0.0129 Accuracy 0.2213225371120108\n",
      "Epoch [2001/3500], Loss: 0.0084 Accuracy 0.22807017543859648\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.2631578947368421\n",
      "Trial A 40 Acc: 0.33569367951744017\n",
      "Epoch [1/3500], Loss: 0.1535 Accuracy 0.005398110661268556\n",
      "Epoch [1001/3500], Loss: 0.0131 Accuracy 0.2145748987854251\n",
      "Epoch [2001/3500], Loss: 0.0086 Accuracy 0.24021592442645073\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.2631578947368421\n",
      "Trial A 41 Acc: 0.3358934971838196\n",
      "Epoch [1/3500], Loss: 0.0517 Accuracy 0.012145748987854251\n",
      "Epoch [1001/3500], Loss: 0.0124 Accuracy 0.21862348178137653\n",
      "Epoch [2001/3500], Loss: 0.0082 Accuracy 0.2388663967611336\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.26045883940620784\n",
      "Trial A 42 Acc: 0.33608402100525114\n",
      "Epoch [1/3500], Loss: 0.0810 Accuracy 0.029689608636977057\n",
      "Epoch [1001/3500], Loss: 0.0138 Accuracy 0.23346828609986506\n",
      "Epoch [2001/3500], Loss: 0.0088 Accuracy 0.25775978407557354\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.24156545209176788\n",
      "Trial A 43 Acc: 0.33626588465298124\n",
      "Epoch [1/3500], Loss: 0.0485 Accuracy 0.1106612685560054\n",
      "Epoch [1001/3500], Loss: 0.0132 Accuracy 0.21322537112010798\n",
      "Epoch [2001/3500], Loss: 0.0086 Accuracy 0.2388663967611336\n",
      "Epoch [3001/3500], Loss: 0.0057 Accuracy 0.2631578947368421\n",
      "Trial A 44 Acc: 0.33643966547192333\n",
      "Epoch [1/3500], Loss: 0.0967 Accuracy 0.3643724696356275\n",
      "Epoch [1001/3500], Loss: 0.0138 Accuracy 0.21322537112010798\n",
      "Epoch [2001/3500], Loss: 0.0091 Accuracy 0.22672064777327935\n",
      "Epoch [3001/3500], Loss: 0.0064 Accuracy 0.2550607287449393\n",
      "Trial A 45 Acc: 0.3366058906030854\n",
      "Epoch [1/3500], Loss: 0.0937 Accuracy 0.0\n",
      "Epoch [1001/3500], Loss: 0.0125 Accuracy 0.242914979757085\n",
      "Epoch [2001/3500], Loss: 0.0082 Accuracy 0.23616734143049933\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.26450742240215924\n",
      "Trial A 46 Acc: 0.3367650423244107\n",
      "Epoch [1/3500], Loss: 0.1299 Accuracy 0.15519568151147098\n",
      "Epoch [1001/3500], Loss: 0.0134 Accuracy 0.2078272604588394\n",
      "Epoch [2001/3500], Loss: 0.0086 Accuracy 0.21052631578947367\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.24561403508771928\n",
      "Trial A 47 Acc: 0.3369175627240142\n",
      "Epoch [1/3500], Loss: 0.0717 Accuracy 0.033738191632928474\n",
      "Epoch [1001/3500], Loss: 0.0134 Accuracy 0.24426450742240216\n",
      "Epoch [2001/3500], Loss: 0.0087 Accuracy 0.2253711201079622\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.2591093117408907\n",
      "Trial A 48 Acc: 0.33706385780118486\n",
      "Epoch [1/3500], Loss: 0.2795 Accuracy 0.0\n",
      "Epoch [1001/3500], Loss: 0.0140 Accuracy 0.20512820512820512\n",
      "Epoch [2001/3500], Loss: 0.0083 Accuracy 0.2388663967611336\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.26450742240215924\n",
      "Trial A 49 Acc: 0.33720430107526866\n",
      "Epoch [1/3500], Loss: 0.0666 Accuracy 0.2739541160593792\n",
      "Epoch [1001/3500], Loss: 0.0137 Accuracy 0.23346828609986506\n",
      "Epoch [2001/3500], Loss: 0.0089 Accuracy 0.2564102564102564\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.2388663967611336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/drs25/miniconda3/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Ridge from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat_detection.avi Length: 338\n",
      "edge_detection.avi Length: 262\n",
      "flat_slip_detection.avi Length: 327\n",
      "Trial B 0 Acc: 0.0\n",
      "Epoch [1/3500], Loss: 0.0708 Accuracy 0.006747638326585695\n",
      "Epoch [1001/3500], Loss: 0.0149 Accuracy 0.21997300944669365\n",
      "Epoch [2001/3500], Loss: 0.0092 Accuracy 0.22267206477732793\n",
      "Epoch [3001/3500], Loss: 0.0065 Accuracy 0.26180836707152494\n",
      "Trial B 1 Acc: 0.17204301075268819\n",
      "Epoch [1/3500], Loss: 0.1317 Accuracy 0.19838056680161945\n",
      "Epoch [1001/3500], Loss: 0.0133 Accuracy 0.19838056680161945\n",
      "Epoch [2001/3500], Loss: 0.0088 Accuracy 0.24021592442645073\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.2483130904183536\n",
      "Trial B 2 Acc: 0.22939068100358426\n",
      "Epoch [1/3500], Loss: 0.1021 Accuracy 0.3157894736842105\n",
      "Epoch [1001/3500], Loss: 0.0142 Accuracy 0.2078272604588394\n",
      "Epoch [2001/3500], Loss: 0.0091 Accuracy 0.24426450742240216\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.2766531713900135\n",
      "Trial B 3 Acc: 0.25806451612903225\n",
      "Epoch [1/3500], Loss: 0.1501 Accuracy 0.3090418353576248\n",
      "Epoch [1001/3500], Loss: 0.0137 Accuracy 0.2145748987854251\n",
      "Epoch [2001/3500], Loss: 0.0089 Accuracy 0.242914979757085\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.25775978407557354\n",
      "Trial B 4 Acc: 0.2752688172043011\n",
      "Epoch [1/3500], Loss: 0.0477 Accuracy 0.0620782726045884\n",
      "Epoch [1001/3500], Loss: 0.0141 Accuracy 0.1902834008097166\n",
      "Epoch [2001/3500], Loss: 0.0088 Accuracy 0.24156545209176788\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.23346828609986506\n",
      "Trial B 5 Acc: 0.28673835125448033\n",
      "Epoch [1/3500], Loss: 0.0795 Accuracy 0.004048582995951417\n",
      "Epoch [1001/3500], Loss: 0.0120 Accuracy 0.26450742240215924\n",
      "Epoch [2001/3500], Loss: 0.0080 Accuracy 0.2321187584345479\n",
      "Epoch [3001/3500], Loss: 0.0057 Accuracy 0.2766531713900135\n",
      "Trial B 6 Acc: 0.2949308755760369\n",
      "Epoch [1/3500], Loss: 0.0506 Accuracy 0.24021592442645073\n",
      "Epoch [1001/3500], Loss: 0.0127 Accuracy 0.2078272604588394\n",
      "Epoch [2001/3500], Loss: 0.0085 Accuracy 0.24561403508771928\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.25371120107962214\n",
      "Trial B 7 Acc: 0.30107526881720437\n",
      "Epoch [1/3500], Loss: 0.0693 Accuracy 0.1039136302294197\n",
      "Epoch [1001/3500], Loss: 0.0131 Accuracy 0.23076923076923078\n",
      "Epoch [2001/3500], Loss: 0.0083 Accuracy 0.24156545209176788\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.26855600539811064\n",
      "Trial B 8 Acc: 0.3058542413381124\n",
      "Epoch [1/3500], Loss: 0.0877 Accuracy 0.016194331983805668\n",
      "Epoch [1001/3500], Loss: 0.0140 Accuracy 0.23751686909581646\n",
      "Epoch [2001/3500], Loss: 0.0090 Accuracy 0.26045883940620784\n",
      "Epoch [3001/3500], Loss: 0.0063 Accuracy 0.28205128205128205\n",
      "Trial B 9 Acc: 0.3096774193548388\n",
      "Epoch [1/3500], Loss: 0.1016 Accuracy 0.2766531713900135\n",
      "Epoch [1001/3500], Loss: 0.0130 Accuracy 0.21322537112010798\n",
      "Epoch [2001/3500], Loss: 0.0086 Accuracy 0.24021592442645073\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.2941970310391363\n",
      "Trial B 10 Acc: 0.3128054740957968\n",
      "Epoch [1/3500], Loss: 0.0436 Accuracy 0.2874493927125506\n",
      "Epoch [1001/3500], Loss: 0.0125 Accuracy 0.22267206477732793\n",
      "Epoch [2001/3500], Loss: 0.0082 Accuracy 0.25371120107962214\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.27800269905533065\n",
      "Trial B 11 Acc: 0.3154121863799284\n",
      "Epoch [1/3500], Loss: 0.2755 Accuracy 0.26720647773279355\n",
      "Epoch [1001/3500], Loss: 0.0126 Accuracy 0.21322537112010798\n",
      "Epoch [2001/3500], Loss: 0.0081 Accuracy 0.23616734143049933\n",
      "Epoch [3001/3500], Loss: 0.0057 Accuracy 0.2631578947368421\n",
      "Trial B 12 Acc: 0.31761786600496283\n",
      "Epoch [1/3500], Loss: 0.0987 Accuracy 0.001349527665317139\n",
      "Epoch [1001/3500], Loss: 0.0121 Accuracy 0.2321187584345479\n",
      "Epoch [2001/3500], Loss: 0.0077 Accuracy 0.2550607287449393\n",
      "Epoch [3001/3500], Loss: 0.0054 Accuracy 0.28609986504723345\n",
      "Trial B 13 Acc: 0.31950844854070665\n",
      "Epoch [1/3500], Loss: 0.0586 Accuracy 0.018893387314439947\n",
      "Epoch [1001/3500], Loss: 0.0125 Accuracy 0.23346828609986506\n",
      "Epoch [2001/3500], Loss: 0.0084 Accuracy 0.2496626180836707\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.2807017543859649\n",
      "Trial B 14 Acc: 0.3211469534050179\n",
      "Epoch [1/3500], Loss: 0.0530 Accuracy 0.11875843454790823\n",
      "Epoch [1001/3500], Loss: 0.0139 Accuracy 0.20917678812415655\n",
      "Epoch [2001/3500], Loss: 0.0088 Accuracy 0.23751686909581646\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.27800269905533065\n",
      "Trial B 15 Acc: 0.3225806451612903\n",
      "Epoch [1/3500], Loss: 0.1067 Accuracy 0.2941970310391363\n",
      "Epoch [1001/3500], Loss: 0.0126 Accuracy 0.23346828609986506\n",
      "Epoch [2001/3500], Loss: 0.0085 Accuracy 0.21592442645074225\n",
      "Epoch [3001/3500], Loss: 0.0056 Accuracy 0.27125506072874495\n",
      "Trial B 16 Acc: 0.3238456672991777\n",
      "Epoch [1/3500], Loss: 0.1582 Accuracy 0.0\n",
      "Epoch [1001/3500], Loss: 0.0125 Accuracy 0.23481781376518218\n",
      "Epoch [2001/3500], Loss: 0.0081 Accuracy 0.26450742240215924\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.2699055330634278\n",
      "Trial B 17 Acc: 0.3249701314217443\n",
      "Epoch [1/3500], Loss: 0.1524 Accuracy 0.0620782726045884\n",
      "Epoch [1001/3500], Loss: 0.0130 Accuracy 0.19568151147098514\n",
      "Epoch [2001/3500], Loss: 0.0081 Accuracy 0.2631578947368421\n",
      "Epoch [3001/3500], Loss: 0.0057 Accuracy 0.2982456140350877\n",
      "Trial B 18 Acc: 0.3259762308998302\n",
      "Epoch [1/3500], Loss: 0.0864 Accuracy 0.1767881241565452\n",
      "Epoch [1001/3500], Loss: 0.0146 Accuracy 0.2213225371120108\n",
      "Epoch [2001/3500], Loss: 0.0084 Accuracy 0.24156545209176788\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.2739541160593792\n",
      "Trial B 19 Acc: 0.32688172043010744\n",
      "Epoch [1/3500], Loss: 0.3150 Accuracy 0.08906882591093117\n",
      "Epoch [1001/3500], Loss: 0.0123 Accuracy 0.21727395411605938\n",
      "Epoch [2001/3500], Loss: 0.0077 Accuracy 0.2388663967611336\n",
      "Epoch [3001/3500], Loss: 0.0056 Accuracy 0.2726045883940621\n",
      "Trial B 20 Acc: 0.32770097286226313\n",
      "Epoch [1/3500], Loss: 0.0535 Accuracy 0.10526315789473684\n",
      "Epoch [1001/3500], Loss: 0.0136 Accuracy 0.23751686909581646\n",
      "Epoch [2001/3500], Loss: 0.0088 Accuracy 0.25775978407557354\n",
      "Epoch [3001/3500], Loss: 0.0063 Accuracy 0.2550607287449393\n",
      "Trial B 21 Acc: 0.32844574780058644\n",
      "Epoch [1/3500], Loss: 0.1096 Accuracy 0.358974358974359\n",
      "Epoch [1001/3500], Loss: 0.0135 Accuracy 0.21727395411605938\n",
      "Epoch [2001/3500], Loss: 0.0089 Accuracy 0.24426450742240216\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.2726045883940621\n",
      "Trial B 22 Acc: 0.32912575970079466\n",
      "Epoch [1/3500], Loss: 0.0778 Accuracy 0.1349527665317139\n",
      "Epoch [1001/3500], Loss: 0.0128 Accuracy 0.19838056680161945\n",
      "Epoch [2001/3500], Loss: 0.0088 Accuracy 0.24426450742240216\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.25101214574898784\n",
      "Trial B 23 Acc: 0.3297491039426522\n",
      "Epoch [1/3500], Loss: 0.0936 Accuracy 0.22402159244264508\n",
      "Epoch [1001/3500], Loss: 0.0130 Accuracy 0.21052631578947367\n",
      "Epoch [2001/3500], Loss: 0.0082 Accuracy 0.23346828609986506\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.2388663967611336\n",
      "Trial B 24 Acc: 0.33032258064516123\n",
      "Epoch [1/3500], Loss: 0.0698 Accuracy 0.21862348178137653\n",
      "Epoch [1001/3500], Loss: 0.0126 Accuracy 0.22267206477732793\n",
      "Epoch [2001/3500], Loss: 0.0084 Accuracy 0.23076923076923078\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.25371120107962214\n",
      "Trial B 25 Acc: 0.33085194375516946\n",
      "Epoch [1/3500], Loss: 0.2692 Accuracy 0.0\n",
      "Epoch [1001/3500], Loss: 0.0137 Accuracy 0.22267206477732793\n",
      "Epoch [2001/3500], Loss: 0.0086 Accuracy 0.25101214574898784\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.2496626180836707\n",
      "Trial B 26 Acc: 0.3313420947829549\n",
      "Epoch [1/3500], Loss: 0.1617 Accuracy 0.3657219973009447\n",
      "Epoch [1001/3500], Loss: 0.0123 Accuracy 0.252361673414305\n",
      "Epoch [2001/3500], Loss: 0.0075 Accuracy 0.26720647773279355\n",
      "Epoch [3001/3500], Loss: 0.0054 Accuracy 0.26045883940620784\n",
      "Trial B 27 Acc: 0.33179723502304137\n",
      "Epoch [1/3500], Loss: 0.0415 Accuracy 0.2766531713900135\n",
      "Epoch [1001/3500], Loss: 0.0129 Accuracy 0.23751686909581646\n",
      "Epoch [2001/3500], Loss: 0.0084 Accuracy 0.26180836707152494\n",
      "Epoch [3001/3500], Loss: 0.0057 Accuracy 0.2496626180836707\n",
      "Trial B 28 Acc: 0.3322209862810529\n",
      "Epoch [1/3500], Loss: 0.1041 Accuracy 0.20242914979757085\n",
      "Epoch [1001/3500], Loss: 0.0142 Accuracy 0.23076923076923078\n",
      "Epoch [2001/3500], Loss: 0.0085 Accuracy 0.25371120107962214\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.26180836707152494\n",
      "Trial B 29 Acc: 0.332616487455197\n",
      "Epoch [1/3500], Loss: 0.2219 Accuracy 0.001349527665317139\n",
      "Epoch [1001/3500], Loss: 0.0123 Accuracy 0.242914979757085\n",
      "Epoch [2001/3500], Loss: 0.0078 Accuracy 0.2388663967611336\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.2793522267206478\n",
      "Trial B 30 Acc: 0.33298647242455764\n",
      "Epoch [1/3500], Loss: 0.0479 Accuracy 0.2793522267206478\n",
      "Epoch [1001/3500], Loss: 0.0131 Accuracy 0.22267206477732793\n",
      "Epoch [2001/3500], Loss: 0.0081 Accuracy 0.24156545209176788\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.26855600539811064\n",
      "Trial B 31 Acc: 0.3333333333333332\n",
      "Epoch [1/3500], Loss: 0.1585 Accuracy 0.11605937921727395\n",
      "Epoch [1001/3500], Loss: 0.0134 Accuracy 0.24696356275303644\n",
      "Epoch [2001/3500], Loss: 0.0087 Accuracy 0.23481781376518218\n",
      "Epoch [3001/3500], Loss: 0.0057 Accuracy 0.23076923076923078\n",
      "Trial B 32 Acc: 0.3336591723688497\n",
      "Epoch [1/3500], Loss: 0.2310 Accuracy 0.0\n",
      "Epoch [1001/3500], Loss: 0.0121 Accuracy 0.22402159244264508\n",
      "Epoch [2001/3500], Loss: 0.0081 Accuracy 0.26855600539811064\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.291497975708502\n",
      "Trial B 33 Acc: 0.3339658444022769\n",
      "Epoch [1/3500], Loss: 0.1011 Accuracy 0.001349527665317139\n",
      "Epoch [1001/3500], Loss: 0.0134 Accuracy 0.21052631578947367\n",
      "Epoch [2001/3500], Loss: 0.0087 Accuracy 0.24426450742240216\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.25101214574898784\n",
      "Trial B 34 Acc: 0.3342549923195083\n",
      "Epoch [1/3500], Loss: 0.2748 Accuracy 0.2874493927125506\n",
      "Epoch [1001/3500], Loss: 0.0110 Accuracy 0.22672064777327935\n",
      "Epoch [2001/3500], Loss: 0.0071 Accuracy 0.2591093117408907\n",
      "Epoch [3001/3500], Loss: 0.0053 Accuracy 0.2807017543859649\n",
      "Trial B 35 Acc: 0.3345280764635602\n",
      "Epoch [1/3500], Loss: 0.1076 Accuracy 0.0\n",
      "Epoch [1001/3500], Loss: 0.0134 Accuracy 0.22672064777327935\n",
      "Epoch [2001/3500], Loss: 0.0083 Accuracy 0.25775978407557354\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.252361673414305\n",
      "Trial B 36 Acc: 0.3347863993025282\n",
      "Epoch [1/3500], Loss: 0.0368 Accuracy 0.2807017543859649\n",
      "Epoch [1001/3500], Loss: 0.0135 Accuracy 0.2253711201079622\n",
      "Epoch [2001/3500], Loss: 0.0084 Accuracy 0.22941970310391363\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.27530364372469635\n",
      "Trial B 37 Acc: 0.3350311262026031\n",
      "Epoch [1/3500], Loss: 0.0493 Accuracy 0.010796221322537112\n",
      "Epoch [1001/3500], Loss: 0.0128 Accuracy 0.21592442645074225\n",
      "Epoch [2001/3500], Loss: 0.0085 Accuracy 0.21862348178137653\n",
      "Epoch [3001/3500], Loss: 0.0063 Accuracy 0.25775978407557354\n",
      "Trial B 38 Acc: 0.3352633030052383\n",
      "Epoch [1/3500], Loss: 0.0586 Accuracy 0.10121457489878542\n",
      "Epoch [1001/3500], Loss: 0.0135 Accuracy 0.242914979757085\n",
      "Epoch [2001/3500], Loss: 0.0085 Accuracy 0.24426450742240216\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.2726045883940621\n",
      "Trial B 39 Acc: 0.3354838709677418\n",
      "Epoch [1/3500], Loss: 0.1513 Accuracy 0.24156545209176788\n",
      "Epoch [1001/3500], Loss: 0.0119 Accuracy 0.23346828609986506\n",
      "Epoch [2001/3500], Loss: 0.0075 Accuracy 0.23481781376518218\n",
      "Epoch [3001/3500], Loss: 0.0055 Accuracy 0.24021592442645073\n",
      "Trial B 40 Acc: 0.33569367951744017\n",
      "Epoch [1/3500], Loss: 0.0979 Accuracy 0.014844804318488529\n",
      "Epoch [1001/3500], Loss: 0.0140 Accuracy 0.23481781376518218\n",
      "Epoch [2001/3500], Loss: 0.0086 Accuracy 0.24561403508771928\n",
      "Epoch [3001/3500], Loss: 0.0058 Accuracy 0.23481781376518218\n",
      "Trial B 41 Acc: 0.3358934971838196\n",
      "Epoch [1/3500], Loss: 0.2165 Accuracy 0.0\n",
      "Epoch [1001/3500], Loss: 0.0126 Accuracy 0.2253711201079622\n",
      "Epoch [2001/3500], Loss: 0.0085 Accuracy 0.25775978407557354\n",
      "Epoch [3001/3500], Loss: 0.0059 Accuracy 0.25101214574898784\n",
      "Trial B 42 Acc: 0.33608402100525114\n",
      "Epoch [1/3500], Loss: 0.1334 Accuracy 0.0796221322537112\n",
      "Epoch [1001/3500], Loss: 0.0143 Accuracy 0.20512820512820512\n",
      "Epoch [2001/3500], Loss: 0.0090 Accuracy 0.22672064777327935\n",
      "Epoch [3001/3500], Loss: 0.0060 Accuracy 0.2550607287449393\n",
      "Trial B 43 Acc: 0.33626588465298124\n",
      "Epoch [1/3500], Loss: 0.3090 Accuracy 0.005398110661268556\n",
      "Epoch [1001/3500], Loss: 0.0128 Accuracy 0.21727395411605938\n",
      "Epoch [2001/3500], Loss: 0.0082 Accuracy 0.25101214574898784\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.23481781376518218\n",
      "Trial B 44 Acc: 0.33643966547192333\n",
      "Epoch [1/3500], Loss: 0.0500 Accuracy 0.3184885290148448\n",
      "Epoch [1001/3500], Loss: 0.0130 Accuracy 0.2388663967611336\n",
      "Epoch [2001/3500], Loss: 0.0082 Accuracy 0.2145748987854251\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.2739541160593792\n",
      "Trial B 45 Acc: 0.3366058906030854\n",
      "Epoch [1/3500], Loss: 0.1245 Accuracy 0.0\n",
      "Epoch [1001/3500], Loss: 0.0133 Accuracy 0.2078272604588394\n",
      "Epoch [2001/3500], Loss: 0.0081 Accuracy 0.2483130904183536\n",
      "Epoch [3001/3500], Loss: 0.0056 Accuracy 0.27125506072874495\n",
      "Trial B 46 Acc: 0.3367650423244107\n",
      "Epoch [1/3500], Loss: 0.1123 Accuracy 0.005398110661268556\n",
      "Epoch [1001/3500], Loss: 0.0140 Accuracy 0.20917678812415655\n",
      "Epoch [2001/3500], Loss: 0.0089 Accuracy 0.24156545209176788\n",
      "Epoch [3001/3500], Loss: 0.0061 Accuracy 0.2658569500674764\n",
      "Trial B 47 Acc: 0.3369175627240142\n",
      "Epoch [1/3500], Loss: 0.2253 Accuracy 0.001349527665317139\n",
      "Epoch [1001/3500], Loss: 0.0140 Accuracy 0.2078272604588394\n",
      "Epoch [2001/3500], Loss: 0.0091 Accuracy 0.22267206477732793\n",
      "Epoch [3001/3500], Loss: 0.0064 Accuracy 0.2483130904183536\n",
      "Trial B 48 Acc: 0.33706385780118486\n",
      "Epoch [1/3500], Loss: 0.0356 Accuracy 0.3049932523616734\n",
      "Epoch [1001/3500], Loss: 0.0127 Accuracy 0.22672064777327935\n",
      "Epoch [2001/3500], Loss: 0.0084 Accuracy 0.22672064777327935\n",
      "Epoch [3001/3500], Loss: 0.0057 Accuracy 0.2496626180836707\n",
      "Trial B 49 Acc: 0.33720430107526866\n",
      "Epoch [1/3500], Loss: 0.0851 Accuracy 0.18758434547908232\n",
      "Epoch [1001/3500], Loss: 0.0138 Accuracy 0.2253711201079622\n",
      "Epoch [2001/3500], Loss: 0.0086 Accuracy 0.26045883940620784\n",
      "Epoch [3001/3500], Loss: 0.0062 Accuracy 0.24696356275303644\n"
     ]
    }
   ],
   "source": [
    "TRIALS=50\n",
    "num_epochs=3500\n",
    "d=dataset()\n",
    "X,ya=d.generate(STORE=5,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]],scale=True)\n",
    "ya=ya/10\n",
    "n_inputs=X.shape[1]\n",
    "X, data_test, y, labels_test = train_test_split(X, ya, test_size=0.20, random_state=42)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "average_a1=np.zeros((num_epochs,))\n",
    "p=0\n",
    "for i in range(TRIALS):\n",
    "    print(\"Trial A\",i,\"Acc:\",p/(i+1))\n",
    "    # Create the neural network\n",
    "    model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    l,a=train(model,num_epochs)\n",
    "    average_a1+=np.array(a)\n",
    "\n",
    "    #unseen data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(torch.tensor(data_test, dtype=torch.float32).to(device))\n",
    "    p+=get_acc(predictions.cpu(),should_be=labels_test)\n",
    "average_a1=average_a1/(TRIALS) #average by 10 and then divide by 5 for scaling\n",
    "\n",
    "d=dataset()\n",
    "X,ya=d.generate(STORE=5,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]],scale=False)\n",
    "X=X/100\n",
    "ya=ya/10\n",
    "\n",
    "X, data_test, y, labels_test = train_test_split(X, ya, test_size=0.20, random_state=42)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "average_a=np.zeros((num_epochs,))\n",
    "p=0\n",
    "for i in range(TRIALS):\n",
    "    print(\"Trial B\",i,\"Acc:\",p/(i+1))\n",
    "    # Create the neural network\n",
    "    model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    l,a=train(model,num_epochs)\n",
    "    average_a+=np.array(a)\n",
    "\n",
    "    #unseen data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(torch.tensor(data_test, dtype=torch.float32).to(device))\n",
    "    p+=get_acc(predictions.cpu(),should_be=labels_test)\n",
    "average_a=average_a/(TRIALS) #average by 10 and then divide by 5 for scaling\n",
    "\n",
    "plt.title(\"Performance of models with and without preprocessing\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.plot(average_l,c=\"r\",label=\"Loss without slip data\")\n",
    "plt.plot(average_a,c=\"r\",label=\"Without preprocessing\")\n",
    "plt.plot(average_a1,c=\"b\",label=\"With preprocessing\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/drs25/miniconda3/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Ridge from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat_detection.avi Length: 338\n",
      "edge_detection.avi Length: 262\n",
      "flat_slip_detection.avi Length: 327\n",
      "Trial A 0 Acc: 0.0\n",
      "Epoch [1/3500], Loss: 0.0741 Accuracy 0.46153846153846156\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 1 Acc: 0.49731182795698925\n",
      "Epoch [1/3500], Loss: 0.1171 Accuracy 0.6572199730094467\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 2 Acc: 0.6630824372759857\n",
      "Epoch [1/3500], Loss: 0.3727 Accuracy 0.6410256410256411\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.9986504723346828\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 3 Acc: 0.7459677419354839\n",
      "Epoch [1/3500], Loss: 0.1453 Accuracy 0.6572199730094467\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 4 Acc: 0.7967741935483871\n",
      "Epoch [1/3500], Loss: 0.1563 Accuracy 0.340080971659919\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 5 Acc: 0.8297491039426523\n",
      "Epoch [1/3500], Loss: 0.3020 Accuracy 0.5060728744939271\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.9986504723346828\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 6 Acc: 0.8540706605222734\n",
      "Epoch [1/3500], Loss: 0.0352 Accuracy 0.6572199730094467\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.9973009446693657\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 7 Acc: 0.8716397849462365\n",
      "Epoch [1/3500], Loss: 0.0801 Accuracy 0.6423751686909581\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 8 Acc: 0.8853046594982078\n",
      "Epoch [1/3500], Loss: 0.0854 Accuracy 0.6477732793522267\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 9 Acc: 0.8962365591397848\n",
      "Epoch [1/3500], Loss: 0.0251 Accuracy 0.6585695006747638\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.9986504723346828\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 10 Acc: 0.9051808406647115\n",
      "Epoch [1/3500], Loss: 0.2386 Accuracy 0.4399460188933873\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 11 Acc: 0.9126344086021504\n",
      "Epoch [1/3500], Loss: 0.1174 Accuracy 0.6585695006747638\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 12 Acc: 0.9193548387096773\n",
      "Epoch [1/3500], Loss: 0.0505 Accuracy 0.3427800269905533\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 13 Acc: 0.9247311827956988\n",
      "Epoch [1/3500], Loss: 0.1043 Accuracy 0.6572199730094467\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 14 Acc: 0.929390681003584\n",
      "Epoch [1/3500], Loss: 0.1468 Accuracy 0.6585695006747638\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 15 Acc: 0.9334677419354837\n",
      "Epoch [1/3500], Loss: 0.0550 Accuracy 0.3427800269905533\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.9986504723346828\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 16 Acc: 0.9373814041745728\n",
      "Epoch [1/3500], Loss: 0.0279 Accuracy 0.3427800269905533\n",
      "Epoch [1001/3500], Loss: 0.0003 Accuracy 0.99055330634278\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.9959514170040485\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 17 Acc: 0.9402628434886497\n",
      "Epoch [1/3500], Loss: 0.1906 Accuracy 0.6558704453441295\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 18 Acc: 0.9431239388794567\n",
      "Epoch [1/3500], Loss: 0.0715 Accuracy 0.3738191632928475\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 19 Acc: 0.9459677419354838\n",
      "Epoch [1/3500], Loss: 0.0764 Accuracy 0.50472334682861\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 20 Acc: 0.9482846902201741\n",
      "Epoch [1/3500], Loss: 0.0404 Accuracy 0.6572199730094467\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 21 Acc: 0.9503910068426198\n",
      "Epoch [1/3500], Loss: 0.1868 Accuracy 0.47233468286099867\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 22 Acc: 0.9523141654978964\n",
      "Epoch [1/3500], Loss: 0.0295 Accuracy 0.3427800269905533\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 23 Acc: 0.9540770609318998\n",
      "Epoch [1/3500], Loss: 0.1436 Accuracy 0.6531713900134952\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 24 Acc: 0.955698924731183\n",
      "Epoch [1/3500], Loss: 0.0465 Accuracy 0.6545209176788124\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 25 Acc: 0.9571960297766752\n",
      "Epoch [1/3500], Loss: 0.1975 Accuracy 0.524966261808367\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 26 Acc: 0.958582238152131\n",
      "Epoch [1/3500], Loss: 0.1904 Accuracy 0.48043184885290147\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 27 Acc: 0.9598694316436255\n",
      "Epoch [1/3500], Loss: 0.0560 Accuracy 0.6572199730094467\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 28 Acc: 0.9610678531701895\n",
      "Epoch [1/3500], Loss: 0.0396 Accuracy 0.6005398110661269\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 29 Acc: 0.9621863799283158\n",
      "Epoch [1/3500], Loss: 0.0947 Accuracy 0.50472334682861\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.9986504723346828\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 30 Acc: 0.9632327436697888\n",
      "Epoch [1/3500], Loss: 0.1051 Accuracy 0.562753036437247\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 31 Acc: 0.964381720430108\n",
      "Epoch [1/3500], Loss: 0.0591 Accuracy 0.6572199730094467\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 32 Acc: 0.965298142717498\n",
      "Epoch [1/3500], Loss: 0.0664 Accuracy 0.3427800269905533\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.9986504723346828\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 33 Acc: 0.9661606578115122\n",
      "Epoch [1/3500], Loss: 0.0419 Accuracy 0.3427800269905533\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 34 Acc: 0.9671274961597547\n",
      "Epoch [1/3500], Loss: 0.3385 Accuracy 0.37112010796221323\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.9973009446693657\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 35 Acc: 0.9678912783751498\n",
      "Epoch [1/3500], Loss: 0.1933 Accuracy 0.6558704453441295\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 36 Acc: 0.9686137750653883\n",
      "Epoch [1/3500], Loss: 0.1103 Accuracy 0.6248313090418354\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 37 Acc: 0.9694397283531412\n",
      "Epoch [1/3500], Loss: 0.3034 Accuracy 0.3508771929824561\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.9986504723346828\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 38 Acc: 0.9700854700854703\n",
      "Epoch [1/3500], Loss: 0.0393 Accuracy 0.48313090418353577\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 39 Acc: 0.970698924731183\n",
      "Epoch [1/3500], Loss: 0.0534 Accuracy 0.3427800269905533\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 40 Acc: 0.9712824547600316\n",
      "Epoch [1/3500], Loss: 0.1057 Accuracy 0.6572199730094467\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 41 Acc: 0.9718381976446493\n",
      "Epoch [1/3500], Loss: 0.1338 Accuracy 0.6572199730094467\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.9973009446693657\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 42 Acc: 0.9723680920230058\n",
      "Epoch [1/3500], Loss: 0.1014 Accuracy 0.3427800269905533\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 43 Acc: 0.972873900293255\n",
      "Epoch [1/3500], Loss: 0.0358 Accuracy 0.3697705802968961\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 44 Acc: 0.9733572281959378\n",
      "Epoch [1/3500], Loss: 0.0321 Accuracy 0.6572199730094467\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 45 Acc: 0.973819541841982\n",
      "Epoch [1/3500], Loss: 0.1225 Accuracy 0.3441295546558704\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 46 Acc: 0.9742621825669181\n",
      "Epoch [1/3500], Loss: 0.1212 Accuracy 0.5371120107962213\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 47 Acc: 0.9746863799283152\n",
      "Epoch [1/3500], Loss: 0.1964 Accuracy 0.6302294197031039\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.9986504723346828\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0000 Accuracy 1.0\n",
      "Trial A 48 Acc: 0.9750932631116961\n",
      "Epoch [1/3500], Loss: 0.2539 Accuracy 0.5479082321187584\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.9973009446693657\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.9986504723346828\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Trial A 49 Acc: 0.9754838709677416\n",
      "Epoch [1/3500], Loss: 0.0275 Accuracy 0.3427800269905533\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.9986504723346828\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 1.0\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/drs25/miniconda3/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Ridge from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat_detection.avi Length: 338\n",
      "edge_detection.avi Length: 262\n",
      "flat_slip_detection.avi Length: 327\n",
      "Trial A 0 Acc: 0.0\n",
      "Epoch [1/3500], Loss: 0.0606 Accuracy 0.18083670715249664\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6477732793522267\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 1 Acc: 0.2768817204301075\n",
      "Epoch [1/3500], Loss: 0.1013 Accuracy 0.36707152496626183\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6450742240215924\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6383265856950068\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 2 Acc: 0.37275985663082434\n",
      "Epoch [1/3500], Loss: 0.0805 Accuracy 0.28475033738191635\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Trial A 3 Acc: 0.42607526881720426\n",
      "Epoch [1/3500], Loss: 0.1133 Accuracy 0.10796221322537113\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6558704453441295\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 4 Acc: 0.4548387096774193\n",
      "Epoch [1/3500], Loss: 0.0749 Accuracy 0.30364372469635625\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6477732793522267\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 5 Acc: 0.4740143369175627\n",
      "Epoch [1/3500], Loss: 0.1391 Accuracy 0.27530364372469635\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6464237516869096\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Trial A 6 Acc: 0.488479262672811\n",
      "Epoch [1/3500], Loss: 0.1233 Accuracy 0.3319838056680162\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6477732793522267\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 7 Acc: 0.49865591397849457\n",
      "Epoch [1/3500], Loss: 0.0801 Accuracy 0.002699055330634278\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6477732793522267\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 8 Acc: 0.505973715651135\n",
      "Epoch [1/3500], Loss: 0.0851 Accuracy 0.2496626180836707\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Trial A 9 Acc: 0.5118279569892473\n",
      "Epoch [1/3500], Loss: 0.0699 Accuracy 0.006747638326585695\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6464237516869096\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Trial A 10 Acc: 0.5190615835777126\n",
      "Epoch [1/3500], Loss: 0.1615 Accuracy 0.2496626180836707\n",
      "Epoch [1001/3500], Loss: 0.0003 Accuracy 0.6140350877192983\n",
      "Epoch [2001/3500], Loss: 0.0002 Accuracy 0.6369770580296896\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6396761133603239\n",
      "Trial A 11 Acc: 0.5241935483870969\n",
      "Epoch [1/3500], Loss: 0.2099 Accuracy 0.2982456140350877\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.650472334682861\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6531713900134952\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6531713900134952\n",
      "Trial A 12 Acc: 0.5285359801488835\n",
      "Epoch [1/3500], Loss: 0.0874 Accuracy 0.11605937921727395\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 13 Acc: 0.5311059907834103\n",
      "Epoch [1/3500], Loss: 0.2157 Accuracy 0.22267206477732793\n",
      "Epoch [1001/3500], Loss: 0.0003 Accuracy 0.6059379217273954\n",
      "Epoch [2001/3500], Loss: 0.0002 Accuracy 0.631578947368421\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6437246963562753\n",
      "Trial A 14 Acc: 0.5344086021505378\n",
      "Epoch [1/3500], Loss: 0.0675 Accuracy 0.23076923076923078\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Trial A 15 Acc: 0.536962365591398\n",
      "Epoch [1/3500], Loss: 0.1346 Accuracy 0.3603238866396761\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6477732793522267\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6531713900134952\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Trial A 16 Acc: 0.5385831752055662\n",
      "Epoch [1/3500], Loss: 0.2739 Accuracy 0.2496626180836707\n",
      "Epoch [1001/3500], Loss: 0.0004 Accuracy 0.6207827260458839\n",
      "Epoch [2001/3500], Loss: 0.0002 Accuracy 0.6491228070175439\n",
      "Epoch [3001/3500], Loss: 0.0002 Accuracy 0.6531713900134952\n",
      "Trial A 17 Acc: 0.5403225806451615\n",
      "Epoch [1/3500], Loss: 0.1169 Accuracy 0.012145748987854251\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6477732793522267\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6518218623481782\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Trial A 18 Acc: 0.5415959252971139\n",
      "Epoch [1/3500], Loss: 0.1603 Accuracy 0.07557354925775979\n",
      "Epoch [1001/3500], Loss: 0.0003 Accuracy 0.6410256410256411\n",
      "Epoch [2001/3500], Loss: 0.0002 Accuracy 0.6518218623481782\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6531713900134952\n",
      "Trial A 19 Acc: 0.5430107526881722\n",
      "Epoch [1/3500], Loss: 0.1801 Accuracy 0.3252361673414305\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6518218623481782\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6518218623481782\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 20 Acc: 0.5448028673835127\n",
      "Epoch [1/3500], Loss: 0.1058 Accuracy 0.012145748987854251\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6531713900134952\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 21 Acc: 0.5459433040078202\n",
      "Epoch [1/3500], Loss: 0.1483 Accuracy 0.02564102564102564\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6369770580296896\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.650472334682861\n",
      "Trial A 22 Acc: 0.5469845722300142\n",
      "Epoch [1/3500], Loss: 0.1355 Accuracy 0.252361673414305\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6531713900134952\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 23 Acc: 0.5481630824372762\n",
      "Epoch [1/3500], Loss: 0.0615 Accuracy 0.349527665317139\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6383265856950068\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6531713900134952\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.650472334682861\n",
      "Trial A 24 Acc: 0.5490322580645163\n",
      "Epoch [1/3500], Loss: 0.0797 Accuracy 0.3076923076923077\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6410256410256411\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Trial A 25 Acc: 0.5500413564929696\n",
      "Epoch [1/3500], Loss: 0.0974 Accuracy 0.3144399460188934\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6410256410256411\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Trial A 26 Acc: 0.550378335324572\n",
      "Epoch [1/3500], Loss: 0.0912 Accuracy 0.002699055330634278\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.650472334682861\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 27 Acc: 0.5510752688172045\n",
      "Epoch [1/3500], Loss: 0.1160 Accuracy 0.02564102564102564\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6531713900134952\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 28 Acc: 0.5517241379310346\n",
      "Epoch [1/3500], Loss: 0.1505 Accuracy 0.2901484480431849\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6491228070175439\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 29 Acc: 0.5521505376344088\n",
      "Epoch [1/3500], Loss: 0.1265 Accuracy 0.23346828609986506\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6423751686909581\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Trial A 30 Acc: 0.5528962885882762\n",
      "Epoch [1/3500], Loss: 0.1411 Accuracy 0.012145748987854251\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6518218623481782\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Trial A 31 Acc: 0.5532594086021507\n",
      "Epoch [1/3500], Loss: 0.0956 Accuracy 0.2982456140350877\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Trial A 32 Acc: 0.5536005213424571\n",
      "Epoch [1/3500], Loss: 0.1232 Accuracy 0.28475033738191635\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6477732793522267\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6491228070175439\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Trial A 33 Acc: 0.554237824161923\n",
      "Epoch [1/3500], Loss: 0.1663 Accuracy 0.242914979757085\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6572199730094467\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6518218623481782\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Trial A 34 Acc: 0.5548387096774196\n",
      "Epoch [1/3500], Loss: 0.1038 Accuracy 0.016194331983805668\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6531713900134952\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Trial A 35 Acc: 0.5554062126642774\n",
      "Epoch [1/3500], Loss: 0.1862 Accuracy 0.1039136302294197\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6477732793522267\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6518218623481782\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 36 Acc: 0.5556524266201688\n",
      "Epoch [1/3500], Loss: 0.0761 Accuracy 0.3630229419703104\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 37 Acc: 0.5560271646859085\n",
      "Epoch [1/3500], Loss: 0.0879 Accuracy 0.0\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6518218623481782\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6531713900134952\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Trial A 38 Acc: 0.556244830438379\n",
      "Epoch [1/3500], Loss: 0.1135 Accuracy 0.23076923076923078\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 39 Acc: 0.5565860215053766\n",
      "Epoch [1/3500], Loss: 0.2004 Accuracy 0.3562753036437247\n",
      "Epoch [1001/3500], Loss: 0.0003 Accuracy 0.6153846153846154\n",
      "Epoch [2001/3500], Loss: 0.0002 Accuracy 0.6423751686909581\n",
      "Epoch [3001/3500], Loss: 0.0002 Accuracy 0.650472334682861\n",
      "Trial A 40 Acc: 0.5571728297928144\n",
      "Epoch [1/3500], Loss: 0.0351 Accuracy 0.0310391363022942\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Trial A 41 Acc: 0.5573476702508964\n",
      "Epoch [1/3500], Loss: 0.0411 Accuracy 0.016194331983805668\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6531713900134952\n",
      "Trial A 42 Acc: 0.557514378594649\n",
      "Epoch [1/3500], Loss: 0.1033 Accuracy 0.3697705802968961\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6545209176788124\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6531713900134952\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6356275303643725\n",
      "Trial A 43 Acc: 0.5577956989247315\n",
      "Epoch [1/3500], Loss: 0.0870 Accuracy 0.11740890688259109\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6518218623481782\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 44 Acc: 0.5584229390681007\n",
      "Epoch [1/3500], Loss: 0.2940 Accuracy 0.3157894736842105\n",
      "Epoch [1001/3500], Loss: 0.0005 Accuracy 0.5371120107962213\n",
      "Epoch [2001/3500], Loss: 0.0004 Accuracy 0.6045883940620783\n",
      "Epoch [3001/3500], Loss: 0.0003 Accuracy 0.5937921727395412\n",
      "Trial A 45 Acc: 0.558789153810192\n",
      "Epoch [1/3500], Loss: 0.1005 Accuracy 0.3616734143049933\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6531713900134952\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6545209176788124\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 46 Acc: 0.5589110043468317\n",
      "Epoch [1/3500], Loss: 0.0660 Accuracy 0.1659919028340081\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.6464237516869096\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6558704453441295\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 47 Acc: 0.5591397849462368\n",
      "Epoch [1/3500], Loss: 0.0683 Accuracy 0.08906882591093117\n",
      "Epoch [1001/3500], Loss: 0.0002 Accuracy 0.6518218623481782\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 48 Acc: 0.5595786701777489\n",
      "Epoch [1/3500], Loss: 0.0866 Accuracy 0.1241565452091768\n",
      "Epoch [1001/3500], Loss: 0.0001 Accuracy 0.650472334682861\n",
      "Epoch [2001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Epoch [3001/3500], Loss: 0.0001 Accuracy 0.6572199730094467\n",
      "Trial A 49 Acc: 0.5595698924731186\n",
      "Epoch [1/3500], Loss: 0.4137 Accuracy 0.32118758434547906\n",
      "Epoch [1001/3500], Loss: 0.0007 Accuracy 0.5856950067476383\n",
      "Epoch [2001/3500], Loss: 0.0005 Accuracy 0.5802968960863698\n",
      "Epoch [3001/3500], Loss: 0.0005 Accuracy 0.5748987854251012\n"
     ]
    }
   ],
   "source": [
    "TRIALS=50\n",
    "num_epochs=3500\n",
    "d=dataset()\n",
    "X,ya=d.generate(STORE=5,y_labels=[[1,0],[1,0],[0,1]],scale=True)\n",
    "ya=ya/10\n",
    "n_inputs=X.shape[1]\n",
    "m_outputs=2\n",
    "X, data_test, y, labels_test = train_test_split(X, ya, test_size=0.20, random_state=42)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "average_a1=np.zeros((num_epochs,))\n",
    "p=0\n",
    "for i in range(TRIALS):\n",
    "    print(\"Trial A\",i,\"Acc:\",p/(i+1))\n",
    "    # Create the neural network\n",
    "    model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    l,a=train(model,num_epochs)\n",
    "    average_a1+=np.array(a)\n",
    "\n",
    "    #unseen data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(torch.tensor(data_test, dtype=torch.float32).to(device))\n",
    "    p+=get_acc(predictions.cpu(),should_be=labels_test)\n",
    "average_a1=average_a1/(TRIALS) #average by 10 and then divide by 5 for scaling\n",
    "\n",
    "\n",
    "d=dataset()\n",
    "X,ya=d.generate(STORE=5,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]],scale=True)\n",
    "ya=ya/10\n",
    "n_inputs=X.shape[1]\n",
    "m_outputs=5\n",
    "X, data_test, y, labels_test = train_test_split(X, ya, test_size=0.20, random_state=42)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "average_a2=np.zeros((num_epochs,))\n",
    "p=0\n",
    "for i in range(TRIALS):\n",
    "    print(\"Trial A\",i,\"Acc:\",p/(i+1))\n",
    "    # Create the neural network\n",
    "    model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    l,a=train(model,num_epochs)\n",
    "    average_a2+=np.array(a)\n",
    " \n",
    "    #unseen data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(torch.tensor(data_test, dtype=torch.float32).to(device))\n",
    "    p+=get_acc(predictions.cpu(),should_be=labels_test)\n",
    "average_a2=average_a2/(TRIALS) #average by 10 and then divide by 5 for scaling\n",
    "\n",
    "plt.title(\"How the architecture influences model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.plot(average_l,c=\"r\",label=\"Loss without slip data\")\n",
    "plt.plot(average_a1,c=\"g\",label=\"binary-classifier\")\n",
    "plt.plot(average_a2,c=\"y\",label=\"Multi-classifier\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"How the architecture influences model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.plot(average_l,c=\"r\",label=\"Loss without slip data\")\n",
    "plt.plot(average_a1,c=\"g\",label=\"binary-classifier\")\n",
    "plt.plot(average_a2,c=\"y\",label=\"Multi-classifier\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0\n",
      "Epoch [1/2500], Loss: 0.0451 Accuracy 0.16173361522198731\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1416490486257928\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.12790697674418605\n",
      "Epoch [1/2500], Loss: 0.0177 Accuracy 0.12050739957716702\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.113107822410148\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.11416490486257928\n",
      "Epoch [1/2500], Loss: 0.0498 Accuracy 0.22727272727272727\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.15961945031712474\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.1427061310782241\n",
      "Epoch [1/2500], Loss: 0.0107 Accuracy 0.2452431289640592\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.16913319238900634\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.16596194503171247\n",
      "Epoch [1/2500], Loss: 0.0390 Accuracy 0.2769556025369979\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.13530655391120508\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.13530655391120508\n",
      "Epoch [1/2500], Loss: 0.0253 Accuracy 0.0507399577167019\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.12050739957716702\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.16596194503171247\n",
      "Epoch [1/2500], Loss: 0.0481 Accuracy 0.24841437632135308\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.16701902748414377\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.11839323467230443\n",
      "Epoch [1/2500], Loss: 0.0246 Accuracy 0.023255813953488372\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.13530655391120508\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.16913319238900634\n",
      "Epoch [1/2500], Loss: 0.0581 Accuracy 0.0708245243128964\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.13002114164904863\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.15010570824524314\n",
      "Epoch [1/2500], Loss: 0.0093 Accuracy 0.15327695560253699\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.160676532769556\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.13530655391120508\n",
      "Epoch [1/2500], Loss: 0.0654 Accuracy 0.004228329809725159\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1744186046511628\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.12473572938689217\n",
      "Epoch [1/2500], Loss: 0.0499 Accuracy 0.2547568710359408\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.17653276955602537\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.1744186046511628\n",
      "Epoch [1/2500], Loss: 0.0666 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.15750528541226216\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.13107822410147993\n",
      "Epoch [1/2500], Loss: 0.0431 Accuracy 0.006342494714587738\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.1416490486257928\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.12790697674418605\n",
      "Epoch [1/2500], Loss: 0.0702 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.16807610993657504\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.1638477801268499\n",
      "Epoch [1/2500], Loss: 0.0270 Accuracy 0.008456659619450317\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.12579281183932348\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.13107822410147993\n",
      "Epoch [1/2500], Loss: 0.0723 Accuracy 0.08985200845665962\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.16807610993657504\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.160676532769556\n",
      "Epoch [1/2500], Loss: 0.0323 Accuracy 0.12790697674418605\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.14904862579281183\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.17124735729386892\n",
      "Epoch [1/2500], Loss: 0.0448 Accuracy 0.006342494714587738\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.15644820295983086\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.14482029598308668\n",
      "Epoch [1/2500], Loss: 0.0294 Accuracy 0.005285412262156448\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.1321353065539112\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.1321353065539112\n",
      "2 0.0\n",
      "Epoch [1/2500], Loss: 0.0305 Accuracy 0.11416490486257928\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.13953488372093023\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.14059196617336153\n",
      "Epoch [1/2500], Loss: 0.0348 Accuracy 0.1522198731501057\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1553911205073996\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.16807610993657504\n",
      "Epoch [1/2500], Loss: 0.1242 Accuracy 0.0010570824524312897\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.14059196617336153\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.1649048625792812\n",
      "Epoch [1/2500], Loss: 0.0324 Accuracy 0.08773784355179703\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.15327695560253699\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.10676532769556026\n",
      "Epoch [1/2500], Loss: 0.0066 Accuracy 0.1638477801268499\n",
      "Epoch [1001/2500], Loss: 0.0007 Accuracy 0.19661733615221988\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.18604651162790697\n",
      "Epoch [1/2500], Loss: 0.0111 Accuracy 0.2346723044397463\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.12684989429175475\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.1733615221987315\n",
      "Epoch [1/2500], Loss: 0.0290 Accuracy 0.17547568710359407\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.15327695560253699\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.1744186046511628\n",
      "Epoch [1/2500], Loss: 0.0451 Accuracy 0.15010570824524314\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.16173361522198731\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.11205073995771671\n",
      "Epoch [1/2500], Loss: 0.0128 Accuracy 0.0507399577167019\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.15644820295983086\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.15644820295983086\n",
      "Epoch [1/2500], Loss: 0.0508 Accuracy 0.23150105708245244\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.12579281183932348\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.1321353065539112\n",
      "Epoch [1/2500], Loss: 0.0251 Accuracy 0.2346723044397463\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.17230443974630022\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.15961945031712474\n",
      "Epoch [1/2500], Loss: 0.0556 Accuracy 0.07822410147991543\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.1321353065539112\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.13002114164904863\n",
      "Epoch [1/2500], Loss: 0.0444 Accuracy 0.026427061310782242\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.1649048625792812\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.14904862579281183\n",
      "Epoch [1/2500], Loss: 0.0280 Accuracy 0.13107822410147993\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.16807610993657504\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.12367864693446089\n",
      "Epoch [1/2500], Loss: 0.0199 Accuracy 0.0708245243128964\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.17230443974630022\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.16279069767441862\n",
      "Epoch [1/2500], Loss: 0.0615 Accuracy 0.18921775898520085\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.12896405919661733\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.11945031712473574\n",
      "Epoch [1/2500], Loss: 0.0432 Accuracy 0.16701902748414377\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.13742071881606766\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.13002114164904863\n",
      "Epoch [1/2500], Loss: 0.0343 Accuracy 0.02536997885835095\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.16913319238900634\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.16913319238900634\n",
      "Epoch [1/2500], Loss: 0.0104 Accuracy 0.13002114164904863\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.1331923890063425\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.13953488372093023\n",
      "Epoch [1/2500], Loss: 0.0332 Accuracy 0.226215644820296\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.13742071881606766\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.14904862579281183\n",
      "3 0.0\n",
      "Epoch [1/2500], Loss: 0.0445 Accuracy 0.2167019027484144\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.17758985200845667\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.18181818181818182\n",
      "Epoch [1/2500], Loss: 0.0409 Accuracy 0.22410147991543342\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.16807610993657504\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.17019027484143764\n",
      "Epoch [1/2500], Loss: 0.0351 Accuracy 0.026427061310782242\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.17864693446088795\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.16807610993657504\n",
      "Epoch [1/2500], Loss: 0.0313 Accuracy 0.11416490486257928\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.11733615221987315\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.17230443974630022\n",
      "Epoch [1/2500], Loss: 0.0317 Accuracy 0.15327695560253699\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.1733615221987315\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.15750528541226216\n",
      "Epoch [1/2500], Loss: 0.0507 Accuracy 0.03805496828752643\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1427061310782241\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.1416490486257928\n",
      "Epoch [1/2500], Loss: 0.0288 Accuracy 0.15961945031712474\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.11839323467230443\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.16807610993657504\n",
      "Epoch [1/2500], Loss: 0.0234 Accuracy 0.12473572938689217\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.17124735729386892\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.16913319238900634\n",
      "Epoch [1/2500], Loss: 0.0310 Accuracy 0.06448202959830866\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.15327695560253699\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.11945031712473574\n",
      "Epoch [1/2500], Loss: 0.0332 Accuracy 0.05179704016913319\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1649048625792812\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.16913319238900634\n",
      "Epoch [1/2500], Loss: 0.0491 Accuracy 0.015856236786469344\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.1649048625792812\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.16913319238900634\n",
      "Epoch [1/2500], Loss: 0.0528 Accuracy 0.0010570824524312897\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.1416490486257928\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.14059196617336153\n",
      "Epoch [1/2500], Loss: 0.0395 Accuracy 0.22938689217758984\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.12684989429175475\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.1331923890063425\n",
      "Epoch [1/2500], Loss: 0.0306 Accuracy 0.1321353065539112\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.15644820295983086\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.15644820295983086\n",
      "Epoch [1/2500], Loss: 0.0333 Accuracy 0.13742071881606766\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.1416490486257928\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.12790697674418605\n",
      "Epoch [1/2500], Loss: 0.0567 Accuracy 0.0010570824524312897\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.16807610993657504\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.16807610993657504\n",
      "Epoch [1/2500], Loss: 0.0315 Accuracy 0.19238900634249473\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.17124735729386892\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.16913319238900634\n",
      "Epoch [1/2500], Loss: 0.0401 Accuracy 0.09302325581395349\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1511627906976744\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.14904862579281183\n",
      "Epoch [1/2500], Loss: 0.0437 Accuracy 0.15644820295983086\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.13002114164904863\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.10782241014799154\n",
      "Epoch [1/2500], Loss: 0.0390 Accuracy 0.16596194503171247\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.15644820295983086\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.15644820295983086\n",
      "4 0.0\n",
      "Epoch [1/2500], Loss: 0.0253 Accuracy 0.14799154334038056\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1553911205073996\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.14587737843551796\n",
      "Epoch [1/2500], Loss: 0.0414 Accuracy 0.06976744186046512\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.1321353065539112\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.10570824524312897\n",
      "Epoch [1/2500], Loss: 0.0432 Accuracy 0.035940803382663845\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.16701902748414377\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.13953488372093023\n",
      "Epoch [1/2500], Loss: 0.0430 Accuracy 0.06448202959830866\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.12790697674418605\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.17230443974630022\n",
      "Epoch [1/2500], Loss: 0.0472 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.12579281183932348\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.11205073995771671\n",
      "Epoch [1/2500], Loss: 0.0233 Accuracy 0.1109936575052854\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.16173361522198731\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.13636363636363635\n",
      "Epoch [1/2500], Loss: 0.0615 Accuracy 0.023255813953488372\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.17019027484143764\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.15327695560253699\n",
      "Epoch [1/2500], Loss: 0.0263 Accuracy 0.2124735729386892\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.17124735729386892\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.17547568710359407\n",
      "Epoch [1/2500], Loss: 0.0602 Accuracy 0.1522198731501057\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.14059196617336153\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.13847780126849896\n",
      "Epoch [1/2500], Loss: 0.0296 Accuracy 0.16173361522198731\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.1511627906976744\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.1511627906976744\n",
      "Epoch [1/2500], Loss: 0.0450 Accuracy 0.05496828752642706\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1226215644820296\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.12790697674418605\n",
      "Epoch [1/2500], Loss: 0.0617 Accuracy 0.2642706131078224\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.16913319238900634\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.12896405919661733\n",
      "Epoch [1/2500], Loss: 0.0304 Accuracy 0.15644820295983086\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.12050739957716702\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.13424947145877378\n",
      "Epoch [1/2500], Loss: 0.0280 Accuracy 0.14059196617336153\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.15961945031712474\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.15644820295983086\n",
      "Epoch [1/2500], Loss: 0.0303 Accuracy 0.21775898520084566\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.15327695560253699\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.15856236786469344\n",
      "Epoch [1/2500], Loss: 0.0312 Accuracy 0.22832980972515857\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1321353065539112\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.16279069767441862\n",
      "Epoch [1/2500], Loss: 0.0503 Accuracy 0.0010570824524312897\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.17019027484143764\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.15961945031712474\n",
      "Epoch [1/2500], Loss: 0.0622 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1427061310782241\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.13953488372093023\n",
      "Epoch [1/2500], Loss: 0.0133 Accuracy 0.21035940803382663\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.16701902748414377\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.16596194503171247\n",
      "Epoch [1/2500], Loss: 0.0430 Accuracy 0.25052854122621565\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.11839323467230443\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.15644820295983086\n",
      "5 0.0\n",
      "Epoch [1/2500], Loss: 0.0311 Accuracy 0.1321353065539112\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.16173361522198731\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.1638477801268499\n",
      "Epoch [1/2500], Loss: 0.0505 Accuracy 0.03171247357293869\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.16807610993657504\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.1416490486257928\n",
      "Epoch [1/2500], Loss: 0.0312 Accuracy 0.10359408033826638\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.13002114164904863\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dexte\\github\\RoboSkin\\Code\\Models\\labeller\\model testing.ipynb Cell 16\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X21sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     l,a\u001b[39m=\u001b[39mtrain(model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X21sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     average_a[i]\u001b[39m+\u001b[39m\u001b[39m=\u001b[39ma\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X21sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m average_a[i]\u001b[39m/\u001b[39m\u001b[39m=\u001b[39mTRIALS \u001b[39m#get average\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\dexte\\github\\RoboSkin\\Code\\Models\\labeller\\model testing.ipynb Cell 16\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X21sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Zero gradients, backward pass, and update the weights\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X21sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X21sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X21sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X21sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m loss_ar\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\dexte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dexte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRIALS=20\n",
    "TIMES=15\n",
    "average_a=np.zeros((TIMES,2500))\n",
    "\n",
    "for i in range(1,TIMES):\n",
    "    print(i,average_a[-1][-1])\n",
    "    d=dataset()\n",
    "    x,y=d.generate(STORE=i,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]])\n",
    "    SIZE=x.shape[1]\n",
    "    x=x/100\n",
    "    y=y/10\n",
    "    n_inputs = x.shape[1]\n",
    "    m_outputs = len(y[0])\n",
    "    for j in range(TRIALS):\n",
    "        X, data_test, Y, labels_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(Y, dtype=torch.float32).to(device)\n",
    "        \n",
    "        model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "        l,a=train(model)\n",
    "        average_a[i]+=a\n",
    "    average_a[i]/=TRIALS #get average\n",
    "#diplay\n",
    "plt.title(\"Performance of models with different sizes of temporal information\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.plot(average_l,c=\"r\",label=\"Loss without slip data\")\n",
    "\n",
    "\n",
    "for i,dat in enumerate(average_a):\n",
    "    plt.plot(dat,label=\"T=\"+str(i))\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,)\n"
     ]
    }
   ],
   "source": [
    "np.save(path+\"data_of_t_size\",average_a)\n",
    "print(np.max(average_a,axis=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dexte\\github\\RoboSkin\\Code\\Models\\labeller\\model testing.ipynb Cell 20\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mAccuricies vs T size\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39;49mmax(average_a,axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dexte/github/RoboSkin/Code/Models/labeller/model%20testing.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m\"\u001b[39m\u001b[39mTemporal vector size (T)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dexte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2820\u001b[0m, in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2703\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[0;32m   2704\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m   2705\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m   2706\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2707\u001b[0m \u001b[39m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   2708\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2818\u001b[0m \u001b[39m    5\u001b[39;00m\n\u001b[0;32m   2819\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2820\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmaximum, \u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[0;32m   2821\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\Users\\dexte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "plt.title(\"Accuricies vs T size\")\n",
    "plt.plot(np.max(average_a,axis=1))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Temporal vector size (T)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
