{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n",
      "GPU: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import letRun #This library can be deleted, it is used for debugging\n",
    "import RoboSkin as sk\n",
    "import cv2 \n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.version.cuda)\n",
    "print(\"GPU:\",torch.cuda.is_available())\n",
    "def sigmoid(x):                                        \n",
    "   return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DATA SET CREATOR\n",
    "class dataset:\n",
    "    def __init__(self,names=[\"flat_detection.avi\",\"edge_detection.avi\",\"flat_slip_detection.avi\"]):\n",
    "        self.path=letRun.path\n",
    "        self.names=names\n",
    "        self.SIZE=0.3\n",
    "        name=\"C:/Users/dexte/OneDrive/Documents/AI/Data_Labeller/pickle_imputer_small.pkl\" #use standard imputer or one for small\n",
    "        self.reg=None\n",
    "        with open(name,'rb') as file:\n",
    "            self.reg=pickle.load(file)\n",
    "    def predict(self,reg,dat):\n",
    "        p=reg.predict(dat)\n",
    "        p=(p.reshape((p.shape[0],p.shape[1]//2,2))*255/self.SIZE)\n",
    "        return p\n",
    "    def generate(self,STORE=5,y_labels=[]):\n",
    "        BIG_DATA_X=None\n",
    "        BIG_DATA_y=None\n",
    "        assert len(y_labels)>=len(self.names),\"Incorrect length of labels\"\n",
    "        for j,name in enumerate(self.names):\n",
    "            skin=sk.Skin(videoFile=self.path+name)#videoFile=path+\"Movement4.avi\") #load skin object using demo video\n",
    "            cap = cv2.VideoCapture(self.path+name)\n",
    "            length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            skin.sharpen=False #falsify the sharpness if recorded with sharpness\n",
    "            frame=skin.getFrame()\n",
    "            h=frame.shape[1]*self.SIZE\n",
    "            w=frame.shape[0]*self.SIZE\n",
    "            frame=cv2.resize(frame,(int(h),int(w)),interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).flatten()/255\n",
    "            past=self.predict(self.reg,np.array([frame]))[0]\n",
    "            initial=past.copy()\n",
    "            initial_frame=frame.copy()\n",
    "\n",
    "            X=[]\n",
    "            y=[] #label as [edge surface soft hard slippery]\n",
    "            lastFrames=[]\n",
    "            gyro=np.zeros((length,6))\n",
    "            try:\n",
    "                gyro=np.load(self.path+name.replace(\".avi\",\"\")+\"_gyro.npy\")\n",
    "            except:\n",
    "                pass\n",
    "            for i in range(length): #lop through all\n",
    "                frame_=skin.getFrame()\n",
    "                frame=cv2.resize(frame_,(int(h),int(w)),interpolation=cv2.INTER_AREA)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).flatten()/255\n",
    "                points=self.predict(self.reg,np.array([frame]))[0]\n",
    "                #get pressure map\n",
    "                diff=np.sum(np.abs(initial_frame-frame))/(frame.shape[0]*3)\n",
    "                vecs=initial-points\n",
    "                lastFrames.append(np.concatenate((vecs.flatten(),gyro[i]*1)))\n",
    "                if len(lastFrames)>STORE: lastFrames.pop(0)\n",
    "                if diff>0.01 and len(lastFrames)==STORE: #significant contact\n",
    "                    X.append(np.array(lastFrames).flatten()) #store temporal element\n",
    "                    y.append(y_labels[j])\n",
    "            if type(BIG_DATA_y)==type(None):\n",
    "                BIG_DATA_y=np.array(y.copy())\n",
    "                BIG_DATA_X=np.array(X.copy())\n",
    "            else:\n",
    "                BIG_DATA_y= np.concatenate((np.array(y.copy()),BIG_DATA_y))\n",
    "                BIG_DATA_X= np.concatenate((np.array(X.copy()),BIG_DATA_X))\n",
    "        a,b=np.array(BIG_DATA_X),np.array(BIG_DATA_y)\n",
    "        a=a.reshape((a.shape))\n",
    "        return a,b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gyro plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyro_edge=np.load(letRun.path+\"edge_detection\"+\"_gyro.npy\")\n",
    "gyro_flat=np.load(letRun.path+\"flat_detection\"+\"_gyro.npy\")\n",
    "gyro_slip=np.load(letRun.path+\"flat_slip_detection\"+\"_gyro.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gyro_edge[:,0],label=\"Accelerometer x\")\n",
    "plt.plot(gyro_edge[:,1],label=\"Accelerometer y\")\n",
    "plt.plot(gyro_edge[:,2],label=\"Accelerometer z\")\n",
    "\n",
    "plt.plot(gyro_flat[:,0],label=\"Accelerometer x\")\n",
    "plt.plot(gyro_flat[:,1],label=\"Accelerometer y\")\n",
    "plt.plot(gyro_flat[:,2],label=\"Accelerometer z\")\n",
    "\n",
    "plt.plot(gyro_slip[:,0],label=\"Accelerometer x\")\n",
    "plt.plot(gyro_slip[:,1],label=\"Accelerometer y\")\n",
    "plt.plot(gyro_slip[:,2],label=\"Accelerometer z\")\n",
    "\n",
    "plt.title(\"Accelerometer over time\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gyro_edge[:,3],c=\"g\",label=\"Accelerometer x\")\n",
    "plt.plot(gyro_edge[:,4],c=\"g\",label=\"Accelerometer y\")\n",
    "plt.plot(gyro_edge[:,5],c=\"g\",label=\"Accelerometer z\")\n",
    "\n",
    "plt.plot(gyro_flat[:,3],c=\"r\",label=\"Accelerometer x\")\n",
    "plt.plot(gyro_flat[:,4],c=\"r\",label=\"Accelerometer y\")\n",
    "plt.plot(gyro_flat[:,5],c=\"r\",label=\"Accelerometer z\")\n",
    "\n",
    "plt.plot(gyro_slip[:,3],c=\"b\",label=\"Accelerometer x\")\n",
    "plt.plot(gyro_slip[:,4],c=\"b\",label=\"Accelerometer y\")\n",
    "plt.plot(gyro_slip[:,5],c=\"b\",label=\"Accelerometer z\")\n",
    "\n",
    "plt.title(\"Gyro over time\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 1360) (756, 5)\n",
      "(190, 1360) (190, 5)\n"
     ]
    }
   ],
   "source": [
    "path=\"C:/Users/dexte/github/RoboSkin/Code/Models/labeller/\"\n",
    "lin_path=\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/Models/labeller\"\n",
    "\n",
    "d=dataset()\n",
    "X,ya=d.generate(STORE=5,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]])\n",
    "Xa=X/100\n",
    "ya=ya/10\n",
    "\n",
    "X, data_test, y, labels_test = train_test_split(Xa, ya, test_size=0.20, random_state=42)\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "print(data_test.shape,labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the size of the input (n) and output (m) layers\n",
    "n_inputs = X.shape[1]\n",
    "m_outputs = len(y[0])\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size,layers=[400,150,10],drop_out_prob=0.2):\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        self.fc=[nn.Linear(input_size, layers[0])]\n",
    "        self.fc.append(nn.ReLU())\n",
    "        self.fc.append(nn.Dropout(p=drop_out_prob))\n",
    "        for i in range(1,len(layers)): #create layers \n",
    "                self.fc.append(nn.Linear(layers[i-1], layers[i]))\n",
    "                self.fc.append(nn.ReLU())\n",
    "                self.fc.append(nn.Dropout(p=drop_out_prob))\n",
    "        self.fc.append(nn.Linear(layers[-1], output_size))\n",
    "        self.fc_layers = nn.Sequential(*self.fc)\n",
    "    def forward(self, x):\n",
    "        x=self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Create the neural network\n",
    "model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def get_acc(predictions,should_be=[]):\n",
    "    predictions*=10 #normalize\n",
    "    pred_array=np.zeros_like(predictions)\n",
    "    inds=np.argmax(predictions[:,0:2],axis=1) #convert at threshold\n",
    "    inds2=np.argmax(predictions[:,2:-1],axis=1) #convert at threshold\n",
    "    for i in range(len(pred_array)):\n",
    "        pred_array[i][inds[i]]=1\n",
    "        pred_array[i][2+inds2[i]]=1\n",
    "    correct=0\n",
    "    for j,pred in enumerate(pred_array): #loopthrough predictions\n",
    "        inds=np.where(pred==1) #\n",
    "        if len(should_be)>0: #validation task\n",
    "            sb=should_be[j]*10\n",
    "            sb=np.where(sb==1)\n",
    "            if len(sb[0])==len(inds[0]):\n",
    "                c=0\n",
    "                for i in range(len(sb[0])):\n",
    "                    if sb[0][i]==inds[0][i]: c+=1\n",
    "                if c==len(sb[0]): correct+=1\n",
    "    return correct/len(should_be)\n",
    "\n",
    "def train(model,num_epochs=2500):\n",
    "    loss_ar=[]\n",
    "    accuracies=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        y_pred = model(X_tensor)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(y_pred, y_tensor)\n",
    "\n",
    "        # Zero gradients, backward pass, and update the weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ar.append(loss.item())\n",
    "        #predict\n",
    "        predictions = model(torch.tensor(X, dtype=torch.float32).to(device))\n",
    "        accuracies.append(get_acc(predictions.cpu().detach().numpy(),should_be=y))\n",
    "        # Print the current loss to monitor training progress\n",
    "        if epoch%1000==0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\",\"Accuracy\",accuracies[-1])\n",
    "    return np.array(loss_ar),np.array(accuracies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2500], Loss: 0.0443 Accuracy 0.062169312169312166\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.593915343915344\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "plt.title(\"Loss while training tactile model\")\n",
    "plt.ylabel(\"Loss and accuracy/5\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "a,b=train(model)\n",
    "#plt.plot(a,label=\"Loss\")\n",
    "plt.plot(b,label=\"Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct: 63.1578947368421 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['surface', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['edge', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['edge', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['surface', 'hard'],\n",
       " ['edge', 'hard'],\n",
       " ['surface', 'hard']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After training, you can use the trained model for predictions on new data.\n",
    "# For example, if you have new input data 'X_new', you can do:\n",
    "with torch.no_grad():\n",
    "     model.eval()\n",
    "     predictions = model(torch.tensor(data_test, dtype=torch.float32).to(device))\n",
    "\n",
    "\n",
    "def predict(predictions,should_be=[]):\n",
    "    predictions*=10 #normalize\n",
    "    pred_array=np.zeros_like(predictions)\n",
    "    inds=np.argmax(predictions[:,0:2],axis=1) #convert at threshold\n",
    "    inds2=np.argmax(predictions[:,2:-1],axis=1) #convert at threshold\n",
    "    for i in range(len(pred_array)):\n",
    "        pred_array[i][inds[i]]=1\n",
    "        pred_array[i][2+inds2[i]]=1\n",
    "    names=[\"edge\", \"surface\", \"soft\", \"hard\", \"slippery\"]\n",
    "    array=[]\n",
    "    correct=0\n",
    "    for j,pred in enumerate(pred_array): #loopthrough predictions\n",
    "        inds=np.where(pred==1) #\n",
    "        ar=[]\n",
    "        if len(should_be)>0: #validation task\n",
    "            sb=should_be[j]*10\n",
    "            sb=np.where(sb==1)\n",
    "            if len(sb[0])==len(inds[0]):\n",
    "                c=0\n",
    "                for i in range(len(sb[0])):\n",
    "                    if sb[0][i]==inds[0][i]: c+=1\n",
    "                if c==len(sb[0]): correct+=1\n",
    "        for i in inds[0]:\n",
    "            ar.append(names[i])\n",
    "        array.append(ar)\n",
    "    if correct!=0: print(\"Percentage correct:\",(correct/len(should_be))*100,\"%\")\n",
    "    return array\n",
    "\n",
    "p=predict(predictions.cpu(),should_be=labels_test)\n",
    "p[0:10]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "### With and without slippage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial B 0 Acc: 0.0\n",
      "Epoch [1/2500], Loss: 0.0349 Accuracy 0.4354166666666667\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.93125\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.94375\n",
      "Trial B 1 Acc: 0.5\n",
      "Epoch [1/2500], Loss: 0.0498 Accuracy 0.5354166666666667\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.5708333333333333\n",
      "Trial B 2 Acc: 0.5111111111111111\n",
      "Epoch [1/2500], Loss: 0.0539 Accuracy 0.4979166666666667\n",
      "Epoch [1001/2500], Loss: 0.0007 Accuracy 0.8791666666666667\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.9770833333333333\n",
      "Trial B 3 Acc: 0.63125\n",
      "Epoch [1/2500], Loss: 0.0299 Accuracy 0.5541666666666667\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.9729166666666667\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.96875\n",
      "Trial B 4 Acc: 0.7033333333333334\n",
      "Epoch [1/2500], Loss: 0.0167 Accuracy 0.26458333333333334\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.8854166666666666\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9\n",
      "Trial B 5 Acc: 0.7513888888888888\n",
      "Epoch [1/2500], Loss: 0.0413 Accuracy 0.36666666666666664\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.9291666666666667\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9395833333333333\n",
      "Trial B 6 Acc: 0.7869047619047619\n",
      "Epoch [1/2500], Loss: 0.0340 Accuracy 0.5520833333333334\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.9145833333333333\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9083333333333333\n",
      "Trial B 7 Acc: 0.8135416666666666\n",
      "Epoch [1/2500], Loss: 0.0527 Accuracy 0.36875\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.9104166666666667\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.9104166666666667\n",
      "Trial B 8 Acc: 0.8333333333333334\n",
      "Epoch [1/2500], Loss: 0.0317 Accuracy 0.3625\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.88125\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9083333333333333\n",
      "Trial B 9 Acc: 0.8491666666666667\n",
      "Epoch [1/2500], Loss: 0.0266 Accuracy 0.125\n",
      "Epoch [1001/2500], Loss: 0.0008 Accuracy 0.56875\n",
      "Epoch [2001/2500], Loss: 0.0008 Accuracy 0.5708333333333333\n",
      "Trial B 10 Acc: 0.8613636363636363\n",
      "Epoch [1/2500], Loss: 0.0274 Accuracy 0.3375\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.9229166666666667\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.9270833333333334\n",
      "Trial B 11 Acc: 0.8729166666666667\n",
      "Epoch [1/2500], Loss: 0.0157 Accuracy 0.15208333333333332\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.975\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.9833333333333333\n",
      "Trial B 12 Acc: 0.8826923076923077\n",
      "Epoch [1/2500], Loss: 0.0217 Accuracy 0.09166666666666666\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.96875\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.9708333333333333\n",
      "Trial B 13 Acc: 0.8904761904761905\n",
      "Epoch [1/2500], Loss: 0.0308 Accuracy 0.2708333333333333\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.9104166666666667\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.9104166666666667\n",
      "Trial B 14 Acc: 0.8972222222222223\n",
      "Epoch [1/2500], Loss: 0.0444 Accuracy 0.07083333333333333\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.9229166666666667\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.8875\n",
      "Trial B 15 Acc: 0.9036458333333334\n",
      "Epoch [1/2500], Loss: 0.0431 Accuracy 0.48333333333333334\n",
      "Epoch [1001/2500], Loss: 0.0014 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0014 Accuracy 0.5708333333333333\n",
      "Trial B 16 Acc: 0.8818627450980392\n",
      "Epoch [1/2500], Loss: 0.0551 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.9229166666666667\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.89375\n",
      "Trial B 17 Acc: 0.888425925925926\n",
      "Epoch [1/2500], Loss: 0.0457 Accuracy 0.43333333333333335\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.9125\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.8895833333333333\n",
      "Trial B 18 Acc: 0.8942982456140351\n",
      "Epoch [1/2500], Loss: 0.0282 Accuracy 0.15416666666666667\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.8645833333333334\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9270833333333334\n",
      "Trial B 19 Acc: 0.8991666666666667\n",
      "Epoch [1/2500], Loss: 0.0641 Accuracy 0.11875\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.9020833333333333\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.9104166666666667\n",
      "Trial B 20 Acc: 0.9035714285714287\n",
      "Epoch [1/2500], Loss: 0.0409 Accuracy 0.45208333333333334\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.8854166666666666\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9208333333333333\n",
      "Trial B 21 Acc: 0.9075757575757577\n",
      "Epoch [1/2500], Loss: 0.0534 Accuracy 0.03333333333333333\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.5708333333333333\n",
      "Trial B 22 Acc: 0.8913043478260871\n",
      "Epoch [1/2500], Loss: 0.0559 Accuracy 0.43125\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.8979166666666667\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9208333333333333\n",
      "Trial B 23 Acc: 0.8954861111111113\n",
      "Epoch [1/2500], Loss: 0.0250 Accuracy 0.4791666666666667\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.8958333333333334\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.8958333333333334\n",
      "Trial B 24 Acc: 0.8996666666666668\n",
      "Epoch [1/2500], Loss: 0.0349 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.9166666666666666\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9729166666666667\n",
      "Trial B 25 Acc: 0.9032051282051283\n",
      "Epoch [1/2500], Loss: 0.0250 Accuracy 0.37916666666666665\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.95\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9520833333333333\n",
      "Trial B 26 Acc: 0.9067901234567903\n",
      "Epoch [1/2500], Loss: 0.0568 Accuracy 0.35\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.5708333333333333\n",
      "Trial B 27 Acc: 0.8934523809523812\n",
      "Epoch [1/2500], Loss: 0.0737 Accuracy 0.4395833333333333\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.5708333333333333\n",
      "Trial B 28 Acc: 0.881034482758621\n",
      "Epoch [1/2500], Loss: 0.0539 Accuracy 0.3770833333333333\n",
      "Epoch [1001/2500], Loss: 0.0016 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.9083333333333333\n",
      "Trial B 29 Acc: 0.8844444444444447\n",
      "Epoch [1/2500], Loss: 0.0630 Accuracy 0.24791666666666667\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Trial B 30 Acc: 0.8731182795698929\n",
      "Epoch [1/2500], Loss: 0.0333 Accuracy 0.44166666666666665\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.8791666666666667\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9645833333333333\n",
      "Trial B 31 Acc: 0.876822916666667\n",
      "Epoch [1/2500], Loss: 0.0242 Accuracy 0.425\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.9208333333333333\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9541666666666667\n",
      "Trial B 32 Acc: 0.8803030303030307\n",
      "Epoch [1/2500], Loss: 0.0387 Accuracy 0.55625\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Trial B 33 Acc: 0.8700980392156866\n",
      "Epoch [1/2500], Loss: 0.0378 Accuracy 0.45208333333333334\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.8958333333333334\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.90625\n",
      "Trial B 34 Acc: 0.873571428571429\n",
      "Epoch [1/2500], Loss: 0.0341 Accuracy 0.3020833333333333\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.9125\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.9020833333333333\n",
      "Trial B 35 Acc: 0.8768518518518522\n",
      "Epoch [1/2500], Loss: 0.0580 Accuracy 0.3145833333333333\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.9291666666666667\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9375\n",
      "Trial B 36 Acc: 0.8801801801801805\n",
      "Epoch [1/2500], Loss: 0.0254 Accuracy 0.0125\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.8895833333333333\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9020833333333333\n",
      "Trial B 37 Acc: 0.8828947368421055\n",
      "Epoch [1/2500], Loss: 0.0536 Accuracy 0.3333333333333333\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.90625\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.8958333333333334\n",
      "Trial B 38 Acc: 0.885683760683761\n",
      "Epoch [1/2500], Loss: 0.0215 Accuracy 0.3625\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.90625\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9041666666666667\n",
      "Trial B 39 Acc: 0.888541666666667\n",
      "Epoch [1/2500], Loss: 0.0467 Accuracy 0.13541666666666666\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.8979166666666667\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.8958333333333334\n",
      "Trial B 40 Acc: 0.8912601626016263\n",
      "Epoch [1/2500], Loss: 0.0155 Accuracy 0.052083333333333336\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.9145833333333333\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9604166666666667\n",
      "Trial B 41 Acc: 0.8936507936507939\n",
      "Epoch [1/2500], Loss: 0.0087 Accuracy 0.35208333333333336\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.90625\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.90625\n",
      "Trial B 42 Acc: 0.8959302325581399\n",
      "Epoch [1/2500], Loss: 0.0250 Accuracy 0.3375\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.9166666666666666\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9291666666666667\n",
      "Trial B 43 Acc: 0.8981060606060609\n",
      "Epoch [1/2500], Loss: 0.0218 Accuracy 0.0125\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.9104166666666667\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.89375\n",
      "Trial B 44 Acc: 0.9003703703703707\n",
      "Epoch [1/2500], Loss: 0.0526 Accuracy 0.28958333333333336\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.8916666666666667\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9041666666666667\n",
      "Trial B 45 Acc: 0.9023550724637684\n",
      "Epoch [1/2500], Loss: 0.0567 Accuracy 0.08958333333333333\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.8916666666666667\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9104166666666667\n",
      "Trial B 46 Acc: 0.9042553191489364\n",
      "Epoch [1/2500], Loss: 0.0501 Accuracy 0.04791666666666667\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0008 Accuracy 0.5708333333333333\n",
      "Trial B 47 Acc: 0.896527777777778\n",
      "Epoch [1/2500], Loss: 0.0155 Accuracy 0.5395833333333333\n",
      "Epoch [1001/2500], Loss: 0.0007 Accuracy 0.875\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.8958333333333334\n",
      "Trial B 48 Acc: 0.8984693877551023\n",
      "Epoch [1/2500], Loss: 0.0633 Accuracy 0.08125\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.9104166666666667\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9020833333333333\n",
      "Trial B 49 Acc: 0.9005000000000003\n",
      "Epoch [1/2500], Loss: 0.0339 Accuracy 0.54375\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.8770833333333333\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.8979166666666667\n",
      "Trial B 50 Acc: 0.9022875816993466\n",
      "Epoch [1/2500], Loss: 0.0669 Accuracy 0.11041666666666666\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.9020833333333333\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.8770833333333333\n",
      "Trial B 51 Acc: 0.9041666666666669\n",
      "Epoch [1/2500], Loss: 0.0234 Accuracy 0.4\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.9458333333333333\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.9625\n",
      "Trial B 52 Acc: 0.9058176100628933\n",
      "Epoch [1/2500], Loss: 0.0388 Accuracy 0.24791666666666667\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.5708333333333333\n",
      "Trial B 53 Acc: 0.89891975308642\n",
      "Epoch [1/2500], Loss: 0.0429 Accuracy 0.010416666666666666\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.9583333333333334\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.9708333333333333\n",
      "Trial B 54 Acc: 0.9006060606060609\n",
      "Epoch [1/2500], Loss: 0.0475 Accuracy 0.5645833333333333\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.9645833333333333\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9333333333333333\n",
      "Trial B 55 Acc: 0.902232142857143\n",
      "Epoch [1/2500], Loss: 0.0247 Accuracy 0.14375\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Trial B 56 Acc: 0.8957602339181289\n",
      "Epoch [1/2500], Loss: 0.0631 Accuracy 0.2708333333333333\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.5708333333333333\n",
      "Trial B 57 Acc: 0.8895114942528737\n",
      "Epoch [1/2500], Loss: 0.0616 Accuracy 0.06666666666666667\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.9020833333333333\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9333333333333333\n",
      "Trial B 58 Acc: 0.8912429378531075\n",
      "Epoch [1/2500], Loss: 0.0531 Accuracy 0.41875\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.9208333333333333\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.8875\n",
      "Trial B 59 Acc: 0.8929166666666668\n",
      "Epoch [1/2500], Loss: 0.0174 Accuracy 0.08333333333333333\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.9083333333333333\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9666666666666667\n",
      "Trial B 60 Acc: 0.8946721311475412\n",
      "Epoch [1/2500], Loss: 0.0770 Accuracy 0.4895833333333333\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Trial B 61 Acc: 0.8888440860215056\n",
      "Epoch [1/2500], Loss: 0.0223 Accuracy 0.20416666666666666\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.8895833333333333\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9104166666666667\n",
      "Trial B 62 Acc: 0.8906084656084657\n",
      "Epoch [1/2500], Loss: 0.0187 Accuracy 0.010416666666666666\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.6208333333333333\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.8916666666666667\n",
      "Trial B 63 Acc: 0.8923177083333335\n",
      "Epoch [1/2500], Loss: 0.0148 Accuracy 0.43333333333333335\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.9416666666666667\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.9416666666666667\n",
      "Trial B 64 Acc: 0.8939743589743591\n",
      "Epoch [1/2500], Loss: 0.0835 Accuracy 0.39375\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.9041666666666667\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.95625\n",
      "Trial B 65 Acc: 0.8955808080808082\n",
      "Epoch [1/2500], Loss: 0.0564 Accuracy 0.5625\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.96875\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9791666666666666\n",
      "Trial B 66 Acc: 0.8970149253731344\n",
      "Epoch [1/2500], Loss: 0.0407 Accuracy 0.18333333333333332\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.90625\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9125\n",
      "Trial B 67 Acc: 0.8984068627450982\n",
      "Epoch [1/2500], Loss: 0.0117 Accuracy 0.09791666666666667\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Trial B 68 Acc: 0.8931159420289856\n",
      "Epoch [1/2500], Loss: 0.0354 Accuracy 0.06666666666666667\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.5708333333333333\n",
      "Trial B 69 Acc: 0.8879761904761906\n",
      "Epoch [1/2500], Loss: 0.0563 Accuracy 0.06875\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.975\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.9854166666666667\n",
      "Trial B 70 Acc: 0.8895539906103287\n",
      "Epoch [1/2500], Loss: 0.0138 Accuracy 0.425\n",
      "Epoch [1001/2500], Loss: 0.0007 Accuracy 0.7729166666666667\n",
      "Epoch [2001/2500], Loss: 0.0007 Accuracy 0.78125\n",
      "Trial B 71 Acc: 0.8909722222222223\n",
      "Epoch [1/2500], Loss: 0.0136 Accuracy 0.56875\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Trial B 72 Acc: 0.8860730593607307\n",
      "Epoch [1/2500], Loss: 0.0256 Accuracy 0.035416666666666666\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.8916666666666667\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.9104166666666667\n",
      "Trial B 73 Acc: 0.8876126126126127\n",
      "Epoch [1/2500], Loss: 0.0211 Accuracy 0.09791666666666667\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.8875\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.89375\n",
      "Trial B 74 Acc: 0.8891111111111112\n",
      "Epoch [1/2500], Loss: 0.0565 Accuracy 0.22916666666666666\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.9625\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9333333333333333\n",
      "Trial B 75 Acc: 0.8904605263157894\n",
      "Epoch [1/2500], Loss: 0.0261 Accuracy 0.004166666666666667\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Trial B 76 Acc: 0.8858225108225107\n",
      "Epoch [1/2500], Loss: 0.0360 Accuracy 0.16875\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.9020833333333333\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.8916666666666667\n",
      "Trial B 77 Acc: 0.8872863247863247\n",
      "Epoch [1/2500], Loss: 0.0439 Accuracy 0.18541666666666667\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.8645833333333334\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9645833333333333\n",
      "Trial B 78 Acc: 0.8886075949367087\n",
      "Epoch [1/2500], Loss: 0.0224 Accuracy 0.38333333333333336\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.8916666666666667\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.9\n",
      "Trial B 79 Acc: 0.8898958333333331\n",
      "Epoch [1/2500], Loss: 0.0509 Accuracy 0.5083333333333333\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.8979166666666667\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.8770833333333333\n",
      "Trial B 80 Acc: 0.8911522633744853\n",
      "Epoch [1/2500], Loss: 0.0592 Accuracy 0.10625\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.93125\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.95625\n",
      "Trial B 81 Acc: 0.8923780487804874\n",
      "Epoch [1/2500], Loss: 0.0404 Accuracy 0.5104166666666666\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.9666666666666667\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.98125\n",
      "Trial B 82 Acc: 0.8935742971887546\n",
      "Epoch [1/2500], Loss: 0.0308 Accuracy 0.10416666666666667\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.9770833333333333\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.99375\n",
      "Trial B 83 Acc: 0.894742063492063\n",
      "Epoch [1/2500], Loss: 0.0319 Accuracy 0.40625\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.925\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9229166666666667\n",
      "Trial B 84 Acc: 0.8958823529411759\n",
      "Epoch [1/2500], Loss: 0.0238 Accuracy 0.16666666666666666\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.9104166666666667\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.9125\n",
      "Trial B 85 Acc: 0.896996124031007\n",
      "Epoch [1/2500], Loss: 0.0580 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Trial B 86 Acc: 0.8928160919540223\n",
      "Epoch [1/2500], Loss: 0.0656 Accuracy 0.16041666666666668\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.85\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9\n",
      "Trial B 87 Acc: 0.8940340909090903\n",
      "Epoch [1/2500], Loss: 0.0351 Accuracy 0.03333333333333333\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.9833333333333333\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9770833333333333\n",
      "Trial B 88 Acc: 0.8951310861423214\n",
      "Epoch [1/2500], Loss: 0.0230 Accuracy 0.5666666666666667\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.9145833333333333\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.9\n",
      "Trial B 89 Acc: 0.896203703703703\n",
      "Epoch [1/2500], Loss: 0.0443 Accuracy 0.45208333333333334\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.8729166666666667\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9666666666666667\n",
      "Trial B 90 Acc: 0.8973443223443215\n",
      "Epoch [1/2500], Loss: 0.0573 Accuracy 0.0375\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Trial B 91 Acc: 0.8933876811594195\n",
      "Epoch [1/2500], Loss: 0.0264 Accuracy 0.06041666666666667\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.9666666666666667\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.9708333333333333\n",
      "Trial B 92 Acc: 0.8945340501792106\n",
      "Epoch [1/2500], Loss: 0.0581 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Trial B 93 Acc: 0.8906914893617013\n",
      "Epoch [1/2500], Loss: 0.0320 Accuracy 0.3875\n",
      "Epoch [1001/2500], Loss: 0.0007 Accuracy 0.8770833333333333\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.9145833333333333\n",
      "Trial B 94 Acc: 0.8917543859649114\n",
      "Epoch [1/2500], Loss: 0.0580 Accuracy 0.19583333333333333\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.5708333333333333\n",
      "Trial B 95 Acc: 0.8880208333333325\n",
      "Epoch [1/2500], Loss: 0.0270 Accuracy 0.38333333333333336\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.5708333333333333\n",
      "Trial B 96 Acc: 0.884364261168384\n",
      "Epoch [1/2500], Loss: 0.0282 Accuracy 0.5520833333333334\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.95625\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9666666666666667\n",
      "Trial B 97 Acc: 0.8854591836734684\n",
      "Epoch [1/2500], Loss: 0.0362 Accuracy 0.16041666666666668\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.9270833333333334\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.9666666666666667\n",
      "Trial B 98 Acc: 0.8865319865319855\n",
      "Epoch [1/2500], Loss: 0.0577 Accuracy 0.08541666666666667\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.5708333333333333\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.5708333333333333\n",
      "Trial B 99 Acc: 0.882999999999999\n",
      "Epoch [1/2500], Loss: 0.0580 Accuracy 0.3541666666666667\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.875\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.9666666666666667\n",
      "Trial A 0 Acc: 0.0\n",
      "Epoch [1/2500], Loss: 0.0506 Accuracy 0.10317460317460317\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.6111111111111112\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.6177248677248677\n",
      "Trial A 1 Acc: 0.3078947368421053\n",
      "Epoch [1/2500], Loss: 0.0180 Accuracy 0.25\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6084656084656085\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.6150793650793651\n",
      "Trial A 2 Acc: 0.41578947368421054\n",
      "Epoch [1/2500], Loss: 0.0207 Accuracy 0.2830687830687831\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.6031746031746031\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5978835978835979\n",
      "Trial A 3 Acc: 0.4671052631578948\n",
      "Epoch [1/2500], Loss: 0.0391 Accuracy 0.32275132275132273\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.35714285714285715\n",
      "Trial A 4 Acc: 0.44526315789473686\n",
      "Epoch [1/2500], Loss: 0.0409 Accuracy 0.24735449735449735\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.5701058201058201\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.5727513227513228\n",
      "Trial A 5 Acc: 0.47368421052631576\n",
      "Epoch [1/2500], Loss: 0.0141 Accuracy 0.2804232804232804\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.6124338624338624\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.6137566137566137\n",
      "Trial A 6 Acc: 0.4924812030075188\n",
      "Epoch [1/2500], Loss: 0.0237 Accuracy 0.3373015873015873\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 7 Acc: 0.47565789473684206\n",
      "Epoch [1/2500], Loss: 0.0237 Accuracy 0.2208994708994709\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.5740740740740741\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.5859788359788359\n",
      "Trial A 8 Acc: 0.49298245614035086\n",
      "Epoch [1/2500], Loss: 0.0215 Accuracy 0.2328042328042328\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 9 Acc: 0.47947368421052633\n",
      "Epoch [1/2500], Loss: 0.0125 Accuracy 0.3478835978835979\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5687830687830688\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5767195767195767\n",
      "Trial A 10 Acc: 0.49138755980861243\n",
      "Epoch [1/2500], Loss: 0.0455 Accuracy 0.09259259259259259\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.5648148148148148\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5740740740740741\n",
      "Trial A 11 Acc: 0.5026315789473684\n",
      "Epoch [1/2500], Loss: 0.0303 Accuracy 0.07539682539682539\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.5833333333333334\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.5714285714285714\n",
      "Trial A 12 Acc: 0.5117408906882591\n",
      "Epoch [1/2500], Loss: 0.0664 Accuracy 0.07275132275132275\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.5714285714285714\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5767195767195767\n",
      "Trial A 13 Acc: 0.5191729323308271\n",
      "Epoch [1/2500], Loss: 0.0234 Accuracy 0.3002645502645503\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.5634920634920635\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5767195767195767\n",
      "Trial A 14 Acc: 0.5263157894736843\n",
      "Epoch [1/2500], Loss: 0.0100 Accuracy 0.03306878306878307\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 15 Acc: 0.5157894736842106\n",
      "Epoch [1/2500], Loss: 0.0254 Accuracy 0.24867724867724866\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.35714285714285715\n",
      "Trial A 16 Acc: 0.5065015479876162\n",
      "Epoch [1/2500], Loss: 0.0501 Accuracy 0.21428571428571427\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.6044973544973545\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5978835978835979\n",
      "Trial A 17 Acc: 0.5137426900584796\n",
      "Epoch [1/2500], Loss: 0.0526 Accuracy 0.21693121693121692\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6124338624338624\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6111111111111112\n",
      "Trial A 18 Acc: 0.5193905817174516\n",
      "Epoch [1/2500], Loss: 0.0235 Accuracy 0.06481481481481481\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.6190476190476191\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6111111111111112\n",
      "Trial A 19 Acc: 0.5250000000000001\n",
      "Epoch [1/2500], Loss: 0.0228 Accuracy 0.16137566137566137\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.5833333333333334\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.582010582010582\n",
      "Trial A 20 Acc: 0.5295739348370928\n",
      "Epoch [1/2500], Loss: 0.0237 Accuracy 0.2447089947089947\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.5886243386243386\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.5740740740740741\n",
      "Trial A 21 Acc: 0.5332535885167465\n",
      "Epoch [1/2500], Loss: 0.0481 Accuracy 0.14947089947089948\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 22 Acc: 0.525629290617849\n",
      "Epoch [1/2500], Loss: 0.0416 Accuracy 0.34656084656084657\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.5661375661375662\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.5727513227513228\n",
      "Trial A 23 Acc: 0.5293859649122808\n",
      "Epoch [1/2500], Loss: 0.0399 Accuracy 0.02513227513227513\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6216931216931217\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.6150793650793651\n",
      "Trial A 24 Acc: 0.5330526315789474\n",
      "Epoch [1/2500], Loss: 0.0225 Accuracy 0.12169312169312169\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5595238095238095\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.5634920634920635\n",
      "Trial A 25 Acc: 0.5366396761133605\n",
      "Epoch [1/2500], Loss: 0.0464 Accuracy 0.14814814814814814\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.5634920634920635\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.6177248677248677\n",
      "Trial A 26 Acc: 0.5401559454191035\n",
      "Epoch [1/2500], Loss: 0.0421 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.5727513227513228\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6177248677248677\n",
      "Trial A 27 Acc: 0.5436090225563911\n",
      "Epoch [1/2500], Loss: 0.0650 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.5727513227513228\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.5873015873015873\n",
      "Trial A 28 Acc: 0.5460980036297642\n",
      "Epoch [1/2500], Loss: 0.0644 Accuracy 0.22883597883597884\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.533068783068783\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.5370370370370371\n",
      "Trial A 29 Acc: 0.5487719298245615\n",
      "Epoch [1/2500], Loss: 0.0260 Accuracy 0.23941798941798942\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5687830687830688\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5833333333333334\n",
      "Trial A 30 Acc: 0.5511035653650256\n",
      "Epoch [1/2500], Loss: 0.0180 Accuracy 0.046296296296296294\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6164021164021164\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6190476190476191\n",
      "Trial A 31 Acc: 0.5532894736842107\n",
      "Epoch [1/2500], Loss: 0.0427 Accuracy 0.3306878306878307\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.35714285714285715\n",
      "Trial A 32 Acc: 0.5473684210526317\n",
      "Epoch [1/2500], Loss: 0.0238 Accuracy 0.15211640211640212\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.6283068783068783\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.6058201058201058\n",
      "Trial A 33 Acc: 0.5493808049535605\n",
      "Epoch [1/2500], Loss: 0.0255 Accuracy 0.19444444444444445\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6018518518518519\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6190476190476191\n",
      "Trial A 34 Acc: 0.5514285714285716\n",
      "Epoch [1/2500], Loss: 0.0273 Accuracy 0.2724867724867725\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.5621693121693122\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.548941798941799\n",
      "Trial A 35 Acc: 0.5532163742690059\n",
      "Epoch [1/2500], Loss: 0.0581 Accuracy 0.09259259259259259\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.35714285714285715\n",
      "Trial A 36 Acc: 0.5479374110953059\n",
      "Epoch [1/2500], Loss: 0.0608 Accuracy 0.2037037037037037\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.578042328042328\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.5648148148148148\n",
      "Trial A 37 Acc: 0.5494459833795015\n",
      "Epoch [1/2500], Loss: 0.0249 Accuracy 0.2804232804232804\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6044973544973545\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6150793650793651\n",
      "Trial A 38 Acc: 0.5512820512820513\n",
      "Epoch [1/2500], Loss: 0.0177 Accuracy 0.02513227513227513\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6124338624338624\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6137566137566137\n",
      "Trial A 39 Acc: 0.5530263157894738\n",
      "Epoch [1/2500], Loss: 0.0416 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 40 Acc: 0.5482670089858794\n",
      "Epoch [1/2500], Loss: 0.0394 Accuracy 0.27380952380952384\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5925925925925926\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6137566137566137\n",
      "Trial A 41 Acc: 0.5505012531328322\n",
      "Epoch [1/2500], Loss: 0.0482 Accuracy 0.25396825396825395\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6071428571428571\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6071428571428571\n",
      "Trial A 42 Acc: 0.5523867809057529\n",
      "Epoch [1/2500], Loss: 0.0327 Accuracy 0.3148148148148148\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.5740740740740741\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.6111111111111112\n",
      "Trial A 43 Acc: 0.554066985645933\n",
      "Epoch [1/2500], Loss: 0.0360 Accuracy 0.29365079365079366\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5727513227513228\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.5846560846560847\n",
      "Trial A 44 Acc: 0.5553216374269007\n",
      "Epoch [1/2500], Loss: 0.0239 Accuracy 0.06481481481481481\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.5793650793650794\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.5648148148148148\n",
      "Trial A 45 Acc: 0.5568649885583524\n",
      "Epoch [1/2500], Loss: 0.0303 Accuracy 0.294973544973545\n",
      "Epoch [1001/2500], Loss: 0.0007 Accuracy 0.5833333333333334\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.5701058201058201\n",
      "Trial A 46 Acc: 0.5585666293393058\n",
      "Epoch [1/2500], Loss: 0.0316 Accuracy 0.24735449735449735\n",
      "Epoch [1001/2500], Loss: 0.0008 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0008 Accuracy 0.35714285714285715\n",
      "Trial A 47 Acc: 0.5543859649122808\n",
      "Epoch [1/2500], Loss: 0.0094 Accuracy 0.013227513227513227\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 48 Acc: 0.5503759398496242\n",
      "Epoch [1/2500], Loss: 0.0866 Accuracy 0.2671957671957672\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.5674603174603174\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.5701058201058201\n",
      "Trial A 49 Acc: 0.5514736842105264\n",
      "Epoch [1/2500], Loss: 0.0393 Accuracy 0.27116402116402116\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.582010582010582\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.5582010582010583\n",
      "Trial A 50 Acc: 0.5526315789473685\n",
      "Epoch [1/2500], Loss: 0.0418 Accuracy 0.2976190476190476\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.5846560846560847\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.5687830687830688\n",
      "Trial A 51 Acc: 0.5540485829959515\n",
      "Epoch [1/2500], Loss: 0.0217 Accuracy 0.26851851851851855\n",
      "Epoch [1001/2500], Loss: 0.0016 Accuracy 0.39814814814814814\n",
      "Epoch [2001/2500], Loss: 0.0008 Accuracy 0.5674603174603174\n",
      "Trial A 52 Acc: 0.5554121151936445\n",
      "Epoch [1/2500], Loss: 0.0386 Accuracy 0.1746031746031746\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5846560846560847\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5833333333333334\n",
      "Trial A 53 Acc: 0.5569200779727096\n",
      "Epoch [1/2500], Loss: 0.0597 Accuracy 0.005291005291005291\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.5753968253968254\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.5582010582010583\n",
      "Trial A 54 Acc: 0.5578947368421053\n",
      "Epoch [1/2500], Loss: 0.0423 Accuracy 0.017195767195767195\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6164021164021164\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6216931216931217\n",
      "Trial A 55 Acc: 0.5592105263157895\n",
      "Epoch [1/2500], Loss: 0.0130 Accuracy 0.021164021164021163\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.5727513227513228\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.5886243386243386\n",
      "Trial A 56 Acc: 0.5604801477377656\n",
      "Epoch [1/2500], Loss: 0.0233 Accuracy 0.05423280423280423\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 57 Acc: 0.5569872958257713\n",
      "Epoch [1/2500], Loss: 0.0236 Accuracy 0.09126984126984126\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.35714285714285715\n",
      "Trial A 58 Acc: 0.5536128456735058\n",
      "Epoch [1/2500], Loss: 0.0376 Accuracy 0.35185185185185186\n",
      "Epoch [1001/2500], Loss: 0.0007 Accuracy 0.5687830687830688\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.582010582010582\n",
      "Trial A 59 Acc: 0.5549122807017544\n",
      "Epoch [1/2500], Loss: 0.0499 Accuracy 0.23544973544973544\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6137566137566137\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.593915343915344\n",
      "Trial A 60 Acc: 0.55625539257981\n",
      "Epoch [1/2500], Loss: 0.0487 Accuracy 0.010582010582010581\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5687830687830688\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.5767195767195767\n",
      "Trial A 61 Acc: 0.5572156196943971\n",
      "Epoch [1/2500], Loss: 0.0351 Accuracy 0.07407407407407407\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5992063492063492\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.578042328042328\n",
      "Trial A 62 Acc: 0.5582289055973265\n",
      "Epoch [1/2500], Loss: 0.0232 Accuracy 0.20899470899470898\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.5727513227513228\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5846560846560847\n",
      "Trial A 63 Acc: 0.5592105263157894\n",
      "Epoch [1/2500], Loss: 0.0278 Accuracy 0.34656084656084657\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5727513227513228\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.5701058201058201\n",
      "Trial A 64 Acc: 0.560242914979757\n",
      "Epoch [1/2500], Loss: 0.0219 Accuracy 0.19576719576719576\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0007 Accuracy 0.35714285714285715\n",
      "Trial A 65 Acc: 0.5571770334928229\n",
      "Epoch [1/2500], Loss: 0.0495 Accuracy 0.14682539682539683\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6150793650793651\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6190476190476191\n",
      "Trial A 66 Acc: 0.5583660644147682\n",
      "Epoch [1/2500], Loss: 0.0624 Accuracy 0.03042328042328042\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.5701058201058201\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.5714285714285714\n",
      "Trial A 67 Acc: 0.5591331269349844\n",
      "Epoch [1/2500], Loss: 0.0459 Accuracy 0.06084656084656084\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 68 Acc: 0.5562166285278413\n",
      "Epoch [1/2500], Loss: 0.0398 Accuracy 0.06878306878306878\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.35714285714285715\n",
      "Trial A 69 Acc: 0.5533834586466164\n",
      "Epoch [1/2500], Loss: 0.0253 Accuracy 0.0026455026455026454\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.5568783068783069\n",
      "Epoch [2001/2500], Loss: 0.0008 Accuracy 0.5529100529100529\n",
      "Trial A 70 Acc: 0.5541882876204595\n",
      "Epoch [1/2500], Loss: 0.0230 Accuracy 0.12698412698412698\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.35714285714285715\n",
      "Trial A 71 Acc: 0.5514619883040934\n",
      "Epoch [1/2500], Loss: 0.0172 Accuracy 0.2777777777777778\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.5992063492063492\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.6018518518518519\n",
      "Trial A 72 Acc: 0.5525594808940156\n",
      "Epoch [1/2500], Loss: 0.0638 Accuracy 0.0013227513227513227\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5648148148148148\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5833333333333334\n",
      "Trial A 73 Acc: 0.5535561877667139\n",
      "Epoch [1/2500], Loss: 0.0362 Accuracy 0.3253968253968254\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5595238095238095\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5992063492063492\n",
      "Trial A 74 Acc: 0.5543859649122805\n",
      "Epoch [1/2500], Loss: 0.0340 Accuracy 0.24603174603174602\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.5568783068783069\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.5727513227513228\n",
      "Trial A 75 Acc: 0.5554016620498613\n",
      "Epoch [1/2500], Loss: 0.0144 Accuracy 0.04497354497354497\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 76 Acc: 0.5528366370471631\n",
      "Epoch [1/2500], Loss: 0.0295 Accuracy 0.25132275132275134\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.5621693121693122\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5753968253968254\n",
      "Trial A 77 Acc: 0.5537786774628878\n",
      "Epoch [1/2500], Loss: 0.0286 Accuracy 0.17857142857142858\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.35714285714285715\n",
      "Trial A 78 Acc: 0.551299133910726\n",
      "Epoch [1/2500], Loss: 0.0748 Accuracy 0.1865079365079365\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.5767195767195767\n",
      "Trial A 79 Acc: 0.5520394736842104\n",
      "Epoch [1/2500], Loss: 0.0308 Accuracy 0.2804232804232804\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 80 Acc: 0.5496426250812214\n",
      "Epoch [1/2500], Loss: 0.0206 Accuracy 0.023809523809523808\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.6137566137566137\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.6031746031746031\n",
      "Trial A 81 Acc: 0.5505134788189986\n",
      "Epoch [1/2500], Loss: 0.0422 Accuracy 0.2976190476190476\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6190476190476191\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6190476190476191\n",
      "Trial A 82 Acc: 0.5513633481293594\n",
      "Epoch [1/2500], Loss: 0.0239 Accuracy 0.021164021164021163\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.5661375661375662\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.5753968253968254\n",
      "Trial A 83 Acc: 0.5520050125313282\n",
      "Epoch [1/2500], Loss: 0.0439 Accuracy 0.27645502645502645\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 84 Acc: 0.5497213622291021\n",
      "Epoch [1/2500], Loss: 0.0402 Accuracy 0.01984126984126984\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5727513227513228\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5992063492063492\n",
      "Trial A 85 Acc: 0.5505507955936352\n",
      "Epoch [1/2500], Loss: 0.0386 Accuracy 0.164021164021164\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.6005291005291006\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.6044973544973545\n",
      "Trial A 86 Acc: 0.551482153660012\n",
      "Epoch [1/2500], Loss: 0.0344 Accuracy 0.28703703703703703\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.35714285714285715\n",
      "Trial A 87 Acc: 0.5492822966507176\n",
      "Epoch [1/2500], Loss: 0.1061 Accuracy 0.1574074074074074\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.5608465608465608\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.5555555555555556\n",
      "Trial A 88 Acc: 0.5497930218805439\n",
      "Epoch [1/2500], Loss: 0.0369 Accuracy 0.022486772486772486\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.582010582010582\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.5806878306878307\n",
      "Trial A 89 Acc: 0.5505263157894735\n",
      "Epoch [1/2500], Loss: 0.0559 Accuracy 0.011904761904761904\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 90 Acc: 0.5484094852515904\n",
      "Epoch [1/2500], Loss: 0.0440 Accuracy 0.12433862433862433\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.6111111111111112\n",
      "Trial A 91 Acc: 0.5492562929061784\n",
      "Epoch [1/2500], Loss: 0.0344 Accuracy 0.3029100529100529\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6084656084656085\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6137566137566137\n",
      "Trial A 92 Acc: 0.5500848896434634\n",
      "Epoch [1/2500], Loss: 0.0298 Accuracy 0.12037037037037036\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.5621693121693122\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.6190476190476191\n",
      "Trial A 93 Acc: 0.5508958566629338\n",
      "Epoch [1/2500], Loss: 0.0465 Accuracy 0.21428571428571427\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.5740740740740741\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.5714285714285714\n",
      "Trial A 94 Acc: 0.5518005540166204\n",
      "Epoch [1/2500], Loss: 0.0264 Accuracy 0.20105820105820105\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6164021164021164\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.6203703703703703\n",
      "Trial A 95 Acc: 0.5525219298245613\n",
      "Epoch [1/2500], Loss: 0.0668 Accuracy 0.2804232804232804\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.35714285714285715\n",
      "Trial A 96 Acc: 0.5505154639175257\n",
      "Epoch [1/2500], Loss: 0.0294 Accuracy 0.05291005291005291\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.6084656084656085\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.6216931216931217\n",
      "Trial A 97 Acc: 0.5511815252416755\n",
      "Epoch [1/2500], Loss: 0.0291 Accuracy 0.1455026455026455\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.6044973544973545\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.6177248677248677\n",
      "Trial A 98 Acc: 0.5518872939925571\n",
      "Epoch [1/2500], Loss: 0.0459 Accuracy 0.2830687830687831\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.5648148148148148\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.5661375661375662\n",
      "Trial A 99 Acc: 0.5525263157894735\n",
      "Epoch [1/2500], Loss: 0.0302 Accuracy 0.2526455026455027\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.6137566137566137\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.6058201058201058\n",
      "Accuracies 0.558578947368421 0.8928333333333324\n",
      "0.07277631029748087 0.045716139980757714\n"
     ]
    }
   ],
   "source": [
    "TRIALS=100\n",
    "#without slippage\n",
    "#merge datasets\n",
    "d=dataset(names=[\"flat_detection.avi\",\"edge_detection.avi\"])\n",
    "X,ya=d.generate(STORE=5,y_labels=[[0,1,0,1,0],[1,0,0,1,0]])\n",
    "Xa=X/100\n",
    "ya=ya/10\n",
    "\n",
    "X, data_test, y, labels_test = train_test_split(Xa, ya, test_size=0.20, random_state=42)\n",
    "\n",
    "average_a=np.zeros((2500,))\n",
    "p_=0\n",
    "\n",
    "for i in range(TRIALS):\n",
    "    print(\"Trial B\",i,\"Acc:\",p_/(i+1))\n",
    "    # Create the neural network\n",
    "    model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    l,a=train(model)\n",
    "    average_a+=np.array(a)\n",
    "    #unseen data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(torch.tensor(data_test, dtype=torch.float32).to(device))\n",
    "    p_+=get_acc(predictions.cpu(),should_be=labels_test)\n",
    "\n",
    "average_a=average_a/(TRIALS) #average by 10 and then divide by 5 for scaling\n",
    "p_/=TRIALS\n",
    "\n",
    "average_a1=np.zeros((2500,))\n",
    "\n",
    "d=dataset()\n",
    "X,ya=d.generate(STORE=5,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]])\n",
    "Xa=X/100\n",
    "ya=ya/10\n",
    "\n",
    "X, data_test, y, labels_test = train_test_split(Xa, ya, test_size=0.20, random_state=42)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "p=0\n",
    "for i in range(TRIALS):\n",
    "    print(\"Trial A\",i,\"Acc:\",p/(i+1))\n",
    "    # Create the neural network\n",
    "    model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    l,a=train(model)\n",
    "    average_a1+=np.array(a)\n",
    "\n",
    "    #unseen data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model(torch.tensor(data_test, dtype=torch.float32).to(device))\n",
    "    p+=get_acc(predictions.cpu(),should_be=labels_test)\n",
    "average_a1=average_a1/(TRIALS) #average by 10 and then divide by 5 for scaling\n",
    "p/=TRIALS\n",
    "#plt.plot(average_l,'--',c=\"b\",label=\"Loss with slip data\")\n",
    "plt.plot(average_a1,c=\"b\",label=\"Accuracy with slip data\")\n",
    "\n",
    "\n",
    "print(\"Accuracies\",p,p_)\n",
    "plt.title(\"Performance of models with and without slippage over 100 trials\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.plot(average_l,c=\"r\",label=\"Loss without slip data\")\n",
    "plt.plot(average_a,c=\"r\",label=\"Accuracy without slip data\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(np.std(average_a),np.std(average_a1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0\n",
      "Epoch [1/2500], Loss: 0.0451 Accuracy 0.16173361522198731\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1416490486257928\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.12790697674418605\n",
      "Epoch [1/2500], Loss: 0.0177 Accuracy 0.12050739957716702\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.113107822410148\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.11416490486257928\n",
      "Epoch [1/2500], Loss: 0.0498 Accuracy 0.22727272727272727\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.15961945031712474\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.1427061310782241\n",
      "Epoch [1/2500], Loss: 0.0107 Accuracy 0.2452431289640592\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.16913319238900634\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.16596194503171247\n",
      "Epoch [1/2500], Loss: 0.0390 Accuracy 0.2769556025369979\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.13530655391120508\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.13530655391120508\n",
      "Epoch [1/2500], Loss: 0.0253 Accuracy 0.0507399577167019\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.12050739957716702\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.16596194503171247\n",
      "Epoch [1/2500], Loss: 0.0481 Accuracy 0.24841437632135308\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.16701902748414377\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.11839323467230443\n",
      "Epoch [1/2500], Loss: 0.0246 Accuracy 0.023255813953488372\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.13530655391120508\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.16913319238900634\n",
      "Epoch [1/2500], Loss: 0.0581 Accuracy 0.0708245243128964\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.13002114164904863\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.15010570824524314\n",
      "Epoch [1/2500], Loss: 0.0093 Accuracy 0.15327695560253699\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.160676532769556\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.13530655391120508\n",
      "Epoch [1/2500], Loss: 0.0654 Accuracy 0.004228329809725159\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1744186046511628\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.12473572938689217\n",
      "Epoch [1/2500], Loss: 0.0499 Accuracy 0.2547568710359408\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.17653276955602537\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.1744186046511628\n",
      "Epoch [1/2500], Loss: 0.0666 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.15750528541226216\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.13107822410147993\n",
      "Epoch [1/2500], Loss: 0.0431 Accuracy 0.006342494714587738\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.1416490486257928\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.12790697674418605\n",
      "Epoch [1/2500], Loss: 0.0702 Accuracy 0.0\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.16807610993657504\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.1638477801268499\n",
      "Epoch [1/2500], Loss: 0.0270 Accuracy 0.008456659619450317\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.12579281183932348\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.13107822410147993\n",
      "Epoch [1/2500], Loss: 0.0723 Accuracy 0.08985200845665962\n",
      "Epoch [1001/2500], Loss: 0.0010 Accuracy 0.16807610993657504\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.160676532769556\n",
      "Epoch [1/2500], Loss: 0.0323 Accuracy 0.12790697674418605\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.14904862579281183\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.17124735729386892\n",
      "Epoch [1/2500], Loss: 0.0448 Accuracy 0.006342494714587738\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.15644820295983086\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.14482029598308668\n",
      "Epoch [1/2500], Loss: 0.0294 Accuracy 0.005285412262156448\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.1321353065539112\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.1321353065539112\n",
      "2 0.0\n",
      "Epoch [1/2500], Loss: 0.0305 Accuracy 0.11416490486257928\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.13953488372093023\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.14059196617336153\n",
      "Epoch [1/2500], Loss: 0.0348 Accuracy 0.1522198731501057\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1553911205073996\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.16807610993657504\n",
      "Epoch [1/2500], Loss: 0.1242 Accuracy 0.0010570824524312897\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.14059196617336153\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.1649048625792812\n",
      "Epoch [1/2500], Loss: 0.0324 Accuracy 0.08773784355179703\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.15327695560253699\n",
      "Epoch [2001/2500], Loss: 0.0010 Accuracy 0.10676532769556026\n",
      "Epoch [1/2500], Loss: 0.0066 Accuracy 0.1638477801268499\n",
      "Epoch [1001/2500], Loss: 0.0007 Accuracy 0.19661733615221988\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.18604651162790697\n",
      "Epoch [1/2500], Loss: 0.0111 Accuracy 0.2346723044397463\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.12684989429175475\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.1733615221987315\n",
      "Epoch [1/2500], Loss: 0.0290 Accuracy 0.17547568710359407\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.15327695560253699\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.1744186046511628\n",
      "Epoch [1/2500], Loss: 0.0451 Accuracy 0.15010570824524314\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.16173361522198731\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.11205073995771671\n",
      "Epoch [1/2500], Loss: 0.0128 Accuracy 0.0507399577167019\n",
      "Epoch [1001/2500], Loss: 0.0017 Accuracy 0.15644820295983086\n",
      "Epoch [2001/2500], Loss: 0.0017 Accuracy 0.15644820295983086\n",
      "Epoch [1/2500], Loss: 0.0508 Accuracy 0.23150105708245244\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.12579281183932348\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.1321353065539112\n",
      "Epoch [1/2500], Loss: 0.0251 Accuracy 0.2346723044397463\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.17230443974630022\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.15961945031712474\n",
      "Epoch [1/2500], Loss: 0.0556 Accuracy 0.07822410147991543\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.1321353065539112\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.13002114164904863\n",
      "Epoch [1/2500], Loss: 0.0444 Accuracy 0.026427061310782242\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.1649048625792812\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.14904862579281183\n",
      "Epoch [1/2500], Loss: 0.0280 Accuracy 0.13107822410147993\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.16807610993657504\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.12367864693446089\n",
      "Epoch [1/2500], Loss: 0.0199 Accuracy 0.0708245243128964\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.17230443974630022\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.16279069767441862\n",
      "Epoch [1/2500], Loss: 0.0615 Accuracy 0.18921775898520085\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.12896405919661733\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.11945031712473574\n",
      "Epoch [1/2500], Loss: 0.0432 Accuracy 0.16701902748414377\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.13742071881606766\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.13002114164904863\n",
      "Epoch [1/2500], Loss: 0.0343 Accuracy 0.02536997885835095\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.16913319238900634\n",
      "Epoch [2001/2500], Loss: 0.0005 Accuracy 0.16913319238900634\n",
      "Epoch [1/2500], Loss: 0.0104 Accuracy 0.13002114164904863\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.1331923890063425\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.13953488372093023\n",
      "Epoch [1/2500], Loss: 0.0332 Accuracy 0.226215644820296\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.13742071881606766\n",
      "Epoch [2001/2500], Loss: 0.0004 Accuracy 0.14904862579281183\n",
      "3 0.0\n",
      "Epoch [1/2500], Loss: 0.0445 Accuracy 0.2167019027484144\n",
      "Epoch [1001/2500], Loss: 0.0006 Accuracy 0.17758985200845667\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.18181818181818182\n",
      "Epoch [1/2500], Loss: 0.0409 Accuracy 0.22410147991543342\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.16807610993657504\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.17019027484143764\n",
      "Epoch [1/2500], Loss: 0.0351 Accuracy 0.026427061310782242\n",
      "Epoch [1001/2500], Loss: 0.0009 Accuracy 0.17864693446088795\n",
      "Epoch [2001/2500], Loss: 0.0009 Accuracy 0.16807610993657504\n",
      "Epoch [1/2500], Loss: 0.0313 Accuracy 0.11416490486257928\n",
      "Epoch [1001/2500], Loss: 0.0002 Accuracy 0.11733615221987315\n",
      "Epoch [2001/2500], Loss: 0.0002 Accuracy 0.17230443974630022\n",
      "Epoch [1/2500], Loss: 0.0317 Accuracy 0.15327695560253699\n",
      "Epoch [1001/2500], Loss: 0.0005 Accuracy 0.1733615221987315\n",
      "Epoch [2001/2500], Loss: 0.0006 Accuracy 0.15750528541226216\n",
      "Epoch [1/2500], Loss: 0.0507 Accuracy 0.03805496828752643\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1427061310782241\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.1416490486257928\n",
      "Epoch [1/2500], Loss: 0.0288 Accuracy 0.15961945031712474\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.11839323467230443\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.16807610993657504\n",
      "Epoch [1/2500], Loss: 0.0234 Accuracy 0.12473572938689217\n",
      "Epoch [1001/2500], Loss: 0.0004 Accuracy 0.17124735729386892\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.16913319238900634\n",
      "Epoch [1/2500], Loss: 0.0310 Accuracy 0.06448202959830866\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.15327695560253699\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.11945031712473574\n",
      "Epoch [1/2500], Loss: 0.0332 Accuracy 0.05179704016913319\n",
      "Epoch [1001/2500], Loss: 0.0003 Accuracy 0.1649048625792812\n",
      "Epoch [2001/2500], Loss: 0.0003 Accuracy 0.16913319238900634\n",
      "Epoch [1/2500], Loss: 0.0491 Accuracy 0.015856236786469344\n"
     ]
    }
   ],
   "source": [
    "TRIALS=20\n",
    "TIMES=15\n",
    "average_a=np.zeros((TIMES,2500))\n",
    "\n",
    "for i in range(1,TIMES):\n",
    "    print(i,average_a[-1][-1])\n",
    "    d=dataset()\n",
    "    x,y=d.generate(STORE=i,y_labels=[[0,1,0,1,0],[1,0,0,1,0],[0,1,0,0,1]])\n",
    "    SIZE=x.shape[1]\n",
    "    x=x/100\n",
    "    y=y/10\n",
    "    n_inputs = x.shape[1]\n",
    "    m_outputs = len(y[0])\n",
    "    for j in range(TRIALS):\n",
    "        X, data_test, Y, labels_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(Y, dtype=torch.float32).to(device)\n",
    "        \n",
    "        model = SimpleNeuralNetwork(n_inputs, m_outputs).to(device)\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "        l,a=train(model)\n",
    "        average_a[i]+=a\n",
    "    average_a[i]/=TRIALS #get average\n",
    "#diplay\n",
    "plt.title(\"Performance of models with different sizes of temporal information\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.plot(average_l,c=\"r\",label=\"Loss without slip data\")\n",
    "\n",
    "\n",
    "for i,dat in enumerate(average_a):\n",
    "    plt.plot(dat,label=\"T=\"+str(i))\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,)\n"
     ]
    }
   ],
   "source": [
    "np.save(path+\"data_of_t_size\",average_a)\n",
    "print(np.max(average_a,axis=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Accuricies vs T size\")\n",
    "plt.plot(np.max(average_a,axis=1))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Temporal vector size (T)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
