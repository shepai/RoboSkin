{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n",
      "GPU: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "\n",
    "#if linux\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.version.cuda)\n",
    "print(\"GPU:\",torch.cuda.is_available())\n",
    "\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size,layers=[1000,500,200],drop_out_prob=0.2):\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        self.fc=[nn.Linear(input_size, layers[0])]\n",
    "        self.fc.append(nn.Sigmoid())\n",
    "        self.fc.append(nn.Dropout(p=drop_out_prob))\n",
    "        for i in range(1,len(layers)): #create layers \n",
    "                self.fc.append(nn.Linear(layers[i-1], layers[i]))\n",
    "                self.fc.append(nn.Sigmoid())\n",
    "                self.fc.append(nn.Dropout(p=drop_out_prob))\n",
    "        self.fc.append(nn.Linear(layers[-1], output_size))\n",
    "        self.fc_layers = nn.Sequential(*self.fc)\n",
    "    def forward(self, x):\n",
    "        x=self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "class SimpleConv2DNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size,layers=[1000,500,200],drop_out_prob=0.2):\n",
    "        super(SimpleConv2DNeuralNetwork, self).__init__()\n",
    "        input_channels=1 #greyscale\n",
    "        self.conv_layer = nn.Conv2d(in_channels=input_channels, out_channels=8, kernel_size=3)\n",
    "        self.fc=[nn.Linear(8*8*8, layers[0])]\n",
    "        self.fc.append(nn.Sigmoid())\n",
    "        self.fc.append(nn.Dropout(p=drop_out_prob))\n",
    "        for i in range(1,len(layers)): #create layers \n",
    "                self.fc.append(nn.Linear(layers[i-1], layers[i]))\n",
    "                self.fc.append(nn.Sigmoid())\n",
    "                self.fc.append(nn.Dropout(p=drop_out_prob))\n",
    "        self.fc.append(nn.Linear(layers[-1], output_size))\n",
    "        self.fc_layers = nn.Sequential(*self.fc)\n",
    "    def forward(self, x):\n",
    "        x=self.conv_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        # Reshape the tensor to match the input size of the first fully connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x=self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size 990\n",
      "Labels dataset size 990\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name=\"pickle_linear.pkl\"\n",
    "file=\"C:/Users/dexte/github/RoboSkin/Code/Models/TacTip reader/dots/\"\n",
    "\n",
    "#load dataset\n",
    "y=np.load(file+\"augmentedNewTacTip.npy\")\n",
    "X_train=np.load(file+\"augmentedNewTacTipimages.npy\")\n",
    "\n",
    "\n",
    "print(\"Training dataset size\",len(X_train))\n",
    "print(\"Labels dataset size\",len(y))\n",
    "#shape correctly\n",
    "SIZE=0.3\n",
    "y=y.reshape((y.shape[0],y.shape[1]*2))\n",
    "y=y/(255)*SIZE\n",
    "h=X_train.shape[2]*SIZE\n",
    "w=X_train.shape[1]*SIZE\n",
    "#this is the part to apply preprocessing\n",
    "X_train_grayscale = np.zeros((X_train.shape[0],int(h*w))) #((X_train.shape[0],144,192))\n",
    "for i in range(X_train.shape[0]):\n",
    "    im=X_train[i].copy()\n",
    "    im=cv2.resize(im,(int(h),int(w)),interpolation=cv2.INTER_AREA)\n",
    "    im = np.uint8(im)\n",
    "    current = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) #\n",
    "    frame = cv2.adaptiveThreshold(\n",
    "            current, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 5, 1\n",
    "        )\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    frame = cv2.erode(frame, kernel, iterations=1)\n",
    "    X_train_grayscale[i]=frame.flatten()/255 #remove flatten for conv\n",
    "\n",
    "\n",
    "plt.imshow(cv2.resize(X_train_grayscale[0].reshape(144,192),(int(h),int(w)),interpolation=cv2.INTER_AREA))\n",
    "example=(y[0].reshape((y[-1].shape[0]//2,2))*255)\n",
    "plt.scatter(example[:,0],example[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((792, 27648), (792, 266))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, data_test, Y, labels_test = train_test_split(X_train_grayscale, y, test_size=0.20, random_state=42)\n",
    "X.shape,Y.shape\n",
    "#X=X.reshape(792,1,144,192)\n",
    "#data_test=data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150000], Loss: 0.1963\n",
      "Epoch [1001/150000], Loss: 0.0096\n",
      "Epoch [2001/150000], Loss: 0.0087\n",
      "Epoch [3001/150000], Loss: 0.0079\n",
      "Epoch [4001/150000], Loss: 0.0071\n",
      "Epoch [5001/150000], Loss: 0.0065\n",
      "Epoch [6001/150000], Loss: 0.0059\n",
      "Epoch [7001/150000], Loss: 0.0055\n",
      "Epoch [8001/150000], Loss: 0.0050\n",
      "Epoch [9001/150000], Loss: 0.0046\n",
      "Epoch [10001/150000], Loss: 0.0043\n",
      "Epoch [11001/150000], Loss: 0.0041\n",
      "Epoch [12001/150000], Loss: 0.0038\n",
      "Epoch [13001/150000], Loss: 0.0037\n",
      "Epoch [14001/150000], Loss: 0.0034\n",
      "Epoch [15001/150000], Loss: 0.0033\n",
      "Epoch [16001/150000], Loss: 0.0032\n",
      "Epoch [17001/150000], Loss: 0.0031\n",
      "Epoch [18001/150000], Loss: 0.0029\n",
      "Epoch [19001/150000], Loss: 0.0028\n",
      "Epoch [20001/150000], Loss: 0.0027\n",
      "Epoch [21001/150000], Loss: 0.0026\n",
      "Epoch [22001/150000], Loss: 0.0025\n",
      "Epoch [23001/150000], Loss: 0.0025\n",
      "Epoch [24001/150000], Loss: 0.0024\n",
      "Epoch [25001/150000], Loss: 0.0023\n",
      "Epoch [26001/150000], Loss: 0.0023\n",
      "Epoch [27001/150000], Loss: 0.0022\n",
      "Epoch [28001/150000], Loss: 0.0022\n",
      "Epoch [29001/150000], Loss: 0.0022\n",
      "Epoch [30001/150000], Loss: 0.0021\n",
      "Epoch [31001/150000], Loss: 0.0021\n",
      "Epoch [32001/150000], Loss: 0.0020\n",
      "Epoch [33001/150000], Loss: 0.0020\n",
      "Epoch [34001/150000], Loss: 0.0019\n",
      "Epoch [35001/150000], Loss: 0.0019\n",
      "Epoch [36001/150000], Loss: 0.0019\n",
      "Epoch [37001/150000], Loss: 0.0019\n",
      "Epoch [38001/150000], Loss: 0.0018\n",
      "Epoch [39001/150000], Loss: 0.0018\n",
      "Epoch [40001/150000], Loss: 0.0018\n",
      "Epoch [41001/150000], Loss: 0.0018\n",
      "Epoch [42001/150000], Loss: 0.0017\n",
      "Epoch [43001/150000], Loss: 0.0017\n",
      "Epoch [44001/150000], Loss: 0.0017\n",
      "Epoch [45001/150000], Loss: 0.0017\n",
      "Epoch [46001/150000], Loss: 0.0017\n",
      "Epoch [47001/150000], Loss: 0.0016\n",
      "Epoch [48001/150000], Loss: 0.0016\n",
      "Epoch [49001/150000], Loss: 0.0016\n",
      "Epoch [50001/150000], Loss: 0.0016\n",
      "Epoch [51001/150000], Loss: 0.0016\n",
      "Epoch [52001/150000], Loss: 0.0015\n",
      "Epoch [53001/150000], Loss: 0.0015\n",
      "Epoch [54001/150000], Loss: 0.0015\n",
      "Epoch [55001/150000], Loss: 0.0015\n",
      "Epoch [56001/150000], Loss: 0.0015\n",
      "Epoch [57001/150000], Loss: 0.0015\n",
      "Epoch [58001/150000], Loss: 0.0014\n",
      "Epoch [59001/150000], Loss: 0.0014\n",
      "Epoch [60001/150000], Loss: 0.0014\n",
      "Epoch [61001/150000], Loss: 0.0014\n",
      "Epoch [62001/150000], Loss: 0.0014\n",
      "Epoch [63001/150000], Loss: 0.0014\n",
      "Epoch [64001/150000], Loss: 0.0014\n",
      "Epoch [65001/150000], Loss: 0.0014\n",
      "Epoch [66001/150000], Loss: 0.0014\n",
      "Epoch [67001/150000], Loss: 0.0014\n",
      "Epoch [68001/150000], Loss: 0.0014\n",
      "Epoch [69001/150000], Loss: 0.0013\n",
      "Epoch [70001/150000], Loss: 0.0013\n",
      "Epoch [71001/150000], Loss: 0.0013\n",
      "Epoch [72001/150000], Loss: 0.0013\n",
      "Epoch [73001/150000], Loss: 0.0013\n",
      "Epoch [74001/150000], Loss: 0.0013\n",
      "Epoch [75001/150000], Loss: 0.0013\n",
      "Epoch [76001/150000], Loss: 0.0013\n",
      "Epoch [77001/150000], Loss: 0.0013\n",
      "Epoch [78001/150000], Loss: 0.0013\n",
      "Epoch [79001/150000], Loss: 0.0012\n",
      "Epoch [80001/150000], Loss: 0.0012\n",
      "Epoch [81001/150000], Loss: 0.0012\n",
      "Epoch [82001/150000], Loss: 0.0012\n",
      "Epoch [83001/150000], Loss: 0.0012\n",
      "Epoch [84001/150000], Loss: 0.0012\n",
      "Epoch [85001/150000], Loss: 0.0012\n",
      "Epoch [86001/150000], Loss: 0.0012\n",
      "Epoch [87001/150000], Loss: 0.0012\n",
      "Epoch [88001/150000], Loss: 0.0011\n",
      "Epoch [89001/150000], Loss: 0.0012\n",
      "Epoch [90001/150000], Loss: 0.0011\n",
      "Epoch [91001/150000], Loss: 0.0012\n",
      "Epoch [92001/150000], Loss: 0.0011\n",
      "Epoch [93001/150000], Loss: 0.0011\n",
      "Epoch [94001/150000], Loss: 0.0011\n",
      "Epoch [95001/150000], Loss: 0.0011\n",
      "Epoch [96001/150000], Loss: 0.0011\n",
      "Epoch [97001/150000], Loss: 0.0011\n",
      "Epoch [98001/150000], Loss: 0.0011\n",
      "Epoch [99001/150000], Loss: 0.0011\n",
      "Epoch [100001/150000], Loss: 0.0011\n",
      "Epoch [101001/150000], Loss: 0.0011\n",
      "Epoch [102001/150000], Loss: 0.0011\n",
      "Epoch [103001/150000], Loss: 0.0011\n",
      "Epoch [104001/150000], Loss: 0.0011\n",
      "Epoch [105001/150000], Loss: 0.0011\n",
      "Epoch [106001/150000], Loss: 0.0010\n",
      "Epoch [107001/150000], Loss: 0.0010\n",
      "Epoch [108001/150000], Loss: 0.0010\n",
      "Epoch [109001/150000], Loss: 0.0010\n",
      "Epoch [110001/150000], Loss: 0.0011\n",
      "Epoch [111001/150000], Loss: 0.0010\n",
      "Epoch [112001/150000], Loss: 0.0010\n",
      "Epoch [113001/150000], Loss: 0.0010\n",
      "Epoch [114001/150000], Loss: 0.0010\n",
      "Epoch [115001/150000], Loss: 0.0010\n",
      "Epoch [116001/150000], Loss: 0.0010\n",
      "Epoch [117001/150000], Loss: 0.0010\n",
      "Epoch [118001/150000], Loss: 0.0010\n",
      "Epoch [119001/150000], Loss: 0.0010\n",
      "Epoch [120001/150000], Loss: 0.0010\n",
      "Epoch [121001/150000], Loss: 0.0010\n",
      "Epoch [122001/150000], Loss: 0.0010\n",
      "Epoch [123001/150000], Loss: 0.0010\n",
      "Epoch [124001/150000], Loss: 0.0010\n",
      "Epoch [125001/150000], Loss: 0.0010\n",
      "Epoch [126001/150000], Loss: 0.0010\n",
      "Epoch [127001/150000], Loss: 0.0009\n",
      "Epoch [128001/150000], Loss: 0.0010\n",
      "Epoch [129001/150000], Loss: 0.0009\n",
      "Epoch [130001/150000], Loss: 0.0009\n",
      "Epoch [131001/150000], Loss: 0.0009\n",
      "Epoch [132001/150000], Loss: 0.0009\n",
      "Epoch [133001/150000], Loss: 0.0009\n",
      "Epoch [134001/150000], Loss: 0.0009\n",
      "Epoch [135001/150000], Loss: 0.0009\n",
      "Epoch [136001/150000], Loss: 0.0009\n",
      "Epoch [137001/150000], Loss: 0.0009\n",
      "Epoch [138001/150000], Loss: 0.0009\n",
      "Epoch [139001/150000], Loss: 0.0009\n",
      "Epoch [140001/150000], Loss: 0.0009\n",
      "Epoch [141001/150000], Loss: 0.0009\n",
      "Epoch [142001/150000], Loss: 0.0009\n",
      "Epoch [143001/150000], Loss: 0.0009\n",
      "Epoch [144001/150000], Loss: 0.0009\n",
      "Epoch [145001/150000], Loss: 0.0009\n",
      "Epoch [146001/150000], Loss: 0.0009\n",
      "Epoch [147001/150000], Loss: 0.0009\n",
      "Epoch [148001/150000], Loss: 0.0009\n",
      "Epoch [149001/150000], Loss: 0.0009\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the size of the input (n) and output (m) layers\n",
    "n_inputs = X.shape[1]\n",
    "m_outputs = Y.shape[1]\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(Y, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the neural network model\n",
    "\n",
    "\n",
    "# Create the neural network\n",
    "model = SimpleNeuralNetwork(n_inputs, m_outputs,drop_out_prob=0.1).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss() #nn.MSELoss() #nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.02)\n",
    "\n",
    "def train(model,num_epochs,output=True):\n",
    "    loss_ar=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        y_pred = model(X_tensor)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(y_pred, y_tensor)\n",
    "\n",
    "        # Zero gradients, backward pass, and update the weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ar.append(loss.item())\n",
    "        #predict\n",
    "        # Print the current loss to monitor training progress\n",
    "        if epoch%1000==0 and output:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "    return np.array(loss_ar)\n",
    "plt.title(\"Loss while training marker prediction model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "loss=train(model,150000)\n",
    "plt.plot(loss,label=\"Loss\")\n",
    "#plt.plot(b,label=\"Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20000], Loss: 0.0007\n",
      "Epoch [1001/20000], Loss: 0.0007\n",
      "Epoch [2001/20000], Loss: 0.0007\n",
      "Epoch [3001/20000], Loss: 0.0007\n",
      "Epoch [4001/20000], Loss: 0.0007\n",
      "Epoch [5001/20000], Loss: 0.0007\n",
      "Epoch [6001/20000], Loss: 0.0007\n",
      "Epoch [7001/20000], Loss: 0.0007\n",
      "Epoch [8001/20000], Loss: 0.0007\n",
      "Epoch [9001/20000], Loss: 0.0007\n",
      "Epoch [10001/20000], Loss: 0.0007\n",
      "Epoch [11001/20000], Loss: 0.0007\n",
      "Epoch [12001/20000], Loss: 0.0007\n",
      "Epoch [13001/20000], Loss: 0.0007\n",
      "Epoch [14001/20000], Loss: 0.0007\n",
      "Epoch [15001/20000], Loss: 0.0007\n",
      "Epoch [16001/20000], Loss: 0.0007\n",
      "Epoch [17001/20000], Loss: 0.0007\n",
      "Epoch [18001/20000], Loss: 0.0007\n",
      "Epoch [19001/20000], Loss: 0.0007\n"
     ]
    }
   ],
   "source": [
    "loss=train(model,20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"DataLossA\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"C:/Users/dexte/github/RoboSkin/Code/Models/TacTip reader/pytorchModelCross.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/drs25/miniconda3/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleNeuralNetwork(\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=27648, out_features=1000, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=1000, out_features=500, bias=True)\n",
       "    (4): Sigmoid()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=500, out_features=200, bias=True)\n",
       "    (7): Sigmoid()\n",
       "    (8): Dropout(p=0.1, inplace=False)\n",
       "    (9): Linear(in_features=200, out_features=266, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, data_test, Y, labels_test = train_test_split(X_train_grayscale, y, test_size=0.20, random_state=42)\n",
    "# Define the size of the input (n) and output (m) layers\n",
    "n_inputs = X.shape[1]\n",
    "m_outputs = Y.shape[1]\n",
    "model = SimpleNeuralNetwork(n_inputs, m_outputs,drop_out_prob=0.1)#.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/Models/TacTip reader/pytorchModel.pth\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/its/home/drs25/miniconda3/lib/python3.10/tkinter/__init__.py\", line 1919, in __call__\n",
      "    if self.subst:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "     model.eval()\n",
    "     predictions = model(torch.tensor(data_test, dtype=torch.float32)).detach().numpy()\n",
    "import random\n",
    "N=random.randint(0,len(predictions)-101)\n",
    "for i in range(100):\n",
    "     example=predictions[N+i]\n",
    "     example=(example.reshape((example.shape[0]//2,2))*255)/SIZE\n",
    "     image=data_test[N+i].reshape((int(w),int(h)))\n",
    "     image=cv2.resize(image,(X_train.shape[2],X_train.shape[1]),interpolation=cv2.INTER_AREA)\n",
    "     label=(labels_test[N+i].reshape((labels_test[N+i].shape[0]//2,2))*255)/SIZE\n",
    "     plt.cla()\n",
    "     plt.imshow(image)\n",
    "     plt.scatter(example[:,0],example[:,1],c=\"b\")\n",
    "     plt.scatter(label[:,0],label[:,1],c=\"r\")\n",
    "     plt.pause(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
