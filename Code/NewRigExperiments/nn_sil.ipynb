{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import getsizeof\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.imshow(data.AugmentedX[0].reshape((5*110,120)))\\nplt.show()\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class loaded:\n",
    "    def __init__(self,frm=0,t=20):\n",
    "        data = np.load(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/texture-tactip/X_texture.npz\") #load data\n",
    "        for array_name in data:\n",
    "            self.X=(data[array_name].astype(np.uint8))\n",
    "        data = np.load(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/texture-tactip/y_texture.npz\") #load data\n",
    "        for array_name in data:\n",
    "            self.y=(data[array_name].astype(np.uint8))\n",
    "        self.keys={}\n",
    "        self.files=['wool', 'LacedMatt', 'Gfoam', 'bubble', 'Efoam', 'cotton', 'Flat', 'felt', 'Ffoam']\n",
    "        for i, name in enumerate(self.files):\n",
    "            self.keys[i]=name\n",
    "        self.keys={14: 'wool', 23: 'jeans', 20: 'LacedMatt', 22: 'Gfoam', 27: 'bubble', 16: 'Efoam', 21: 'cotton', 11: 'Flat', 24: 'felt', 26: 'Ffoam'}\n",
    "        print(\"Dataset size:\",self.X.shape[0],\"/nWindow size:\",self.X.shape[1],\"/nImage:\",self.X.shape[2:])\n",
    "        print(\"Memory needed:\",round(getsizeof(self.X)/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "        assert self.X.shape[0]==self.y.shape[0],\"Incorrect data size match y=\"+str(self.y.shape[0])+\" x=\"+str(self.X.shape[0])\n",
    "        self.X=self.X[:,frm:t]\n",
    "        #randomize order\n",
    "        n_samples = self.X.shape[0]\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        shuffled_data = self.X[indices]\n",
    "        shuffled_labels = self.y[indices]\n",
    "        self.X=shuffled_data\n",
    "        self.y=shuffled_labels\n",
    "    def augment(self):\n",
    "        #create rotations\n",
    "        self.AugmentedX=np.zeros((len(self.X)*3,*self.X.shape[1:]),dtype=np.uint8)\n",
    "        self.Augmentedy=np.zeros_like(np.concatenate((self.y,self.y,self.y)))\n",
    "        for k,i in enumerate(range(0,len(self.AugmentedX),3)): #loop through the normal data and new data\n",
    "            for j in range(len(self.X[0])):\n",
    "                self.AugmentedX[i][j]=np.copy(self.X[k][j])\n",
    "                self.AugmentedX[i+1][j]=cv2.resize(cv2.rotate(self.X[k][j].copy(), cv2.ROTATE_90_CLOCKWISE),(self.X[k][j].shape[1],self.X[k][j].shape[0]),interpolation=cv2.INTER_AREA)\n",
    "                self.AugmentedX[i+2][j]=cv2.resize(cv2.rotate(self.X[k][j].copy(), cv2.ROTATE_180),(self.X[k][j].shape[1],self.X[k][j].shape[0]),interpolation=cv2.INTER_AREA)\n",
    "                self.Augmentedy[i+1]=self.y[k]\n",
    "                self.Augmentedy[i+2]=self.y[k]\n",
    "                self.Augmentedy[i]=self.y[k]\n",
    "                #self.AugmentedX[i+3][j]=cv2.rotate(self.X[k][j], cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        print(\"Dataset size:\",self.AugmentedX.shape[0],\"/nWindow size:\",self.X.shape[1],\"/nImage:\",self.X.shape[2:])\n",
    "        print(\"Memory needed:\",round(getsizeof(self.AugmentedX)/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "        del self.X\n",
    "        del self.y\n",
    "    def applySobel(self):\n",
    "        for i in range(len(self.X)): #crop all images individually\n",
    "            for j in range(len(self.X[0])):\n",
    "                image=self.X[i][j]\n",
    "                # Apply Sobel filter in x-direction\n",
    "                sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)  # ksize=3 for a 3x3 Sobel kernel\n",
    "\n",
    "                # Apply Sobel filter in y-direction\n",
    "                sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "                # Convert the results back to uint8\n",
    "                sobel_x = np.uint8(np.absolute(sobel_x))\n",
    "                sobel_y = np.uint8(np.absolute(sobel_y))\n",
    "\n",
    "                # Combine the results to get the final edge-detected image\n",
    "                sobel_combined = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "                self.X[i][j]=sobel_combined\n",
    "\n",
    "\"\"\"\n",
    "plt.imshow(data.AugmentedX[0].reshape((5*110,120)))\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genData(frm,to):\n",
    "    data=loaded(frm=frm,t=to)\n",
    "    data.applySobel()\n",
    "    data.augment()\n",
    "    # Example: if train_labels are strings, use LabelEncoder to convert them to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_encoded = label_encoder.fit_transform(data.Augmentedy)\n",
    "    one_hot_labels = torch.nn.functional.one_hot(torch.tensor(train_labels_encoded), num_classes=len(np.unique(train_labels_encoded)))\n",
    "\n",
    "    train_images_tensor = torch.tensor(data.AugmentedX.reshape((len(data.AugmentedX),1,abs(frm-to)*110,120)), dtype=torch.float32).to(device)\n",
    "    train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "    # Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Create DataLoader for training and testing sets\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=120, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=120,shuffle=False)\n",
    "\n",
    "    print(train_images_tensor.shape)\n",
    "    print(train_labels_tensor.shape)\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self,input_height, input_width):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        height = input_height\n",
    "        width = input_width\n",
    "        \n",
    "        height = height // 2  # after first pooling\n",
    "        width = width // 2\n",
    "        height = height // 2  # after second pooling\n",
    "        width = width // 2\n",
    "        \n",
    "        # Number of output features from conv layers (channels * height * width)\n",
    "        self.flatten_size = 64 * height * width\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flatten_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.flatten_size)  # Flatten the tensor\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Loss Function and Optimizer\n",
    "def run(train_loader,frm,to):\n",
    "    model = SimpleCNN(abs(frm-to)*110,120).to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the Model\n",
    "    num_epochs = 8\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss :.4f}')\n",
    "    print('Finished Training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(model,data_loader):\n",
    "        correct=0\n",
    "        summed=0.1\n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            outputs = model(inputs)\n",
    "            a=torch.argmax(outputs,axis=1)==torch.argmax(labels,axis=1)\n",
    "\n",
    "            summed+=len(inputs)\n",
    "            correct+=len(a[a==1])\n",
    "        print(\"Accuracy:\",(correct/summed)*100,\"%\")\n",
    "        return correct/summed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 0 1\n",
      "Dataset size: 4800 /nWindow size: 20 /nImage: (110, 120)\n",
      "Memory needed: 1.18 GB\n",
      "Dataset size: 14400 /nWindow size: 1 /nImage: (110, 120)\n",
      "Memory needed: 0.18 GB\n",
      "torch.Size([14400, 1, 110, 120])\n",
      "torch.Size([14400, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dexte\\AppData\\Local\\Temp\\ipykernel_2460\\1414770746.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 263040]' is invalid for input of size 6220800",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m      8\u001b[0m     train_loader,test_loader\u001b[38;5;241m=\u001b[39mgenData(i,j)\n\u001b[1;32m----> 9\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     test_scores[i][j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][trial]\u001b[38;5;241m=\u001b[39mcalc(model,test_loader)\n\u001b[0;32m     11\u001b[0m     train_scores[i][j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][trial]\u001b[38;5;241m=\u001b[39mcalc(model,train_loader)\n",
      "Cell \u001b[1;32mIn[55], line 17\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(train_loader, frm, to)\u001b[0m\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[54], line 25\u001b[0m, in \u001b[0;36mSimpleCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[0;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[1;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m137\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Flatten the tensor \u001b[39;00m\n\u001b[0;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[-1, 263040]' is invalid for input of size 6220800"
     ]
    }
   ],
   "source": [
    "test_scores=np.zeros((10,19,3))\n",
    "train_scores=np.zeros((10,19,3))\n",
    "\n",
    "for i in range(0,10): #loop through frm dimention\n",
    "    for j in range(1,20): #loop though to dimention\n",
    "        print(\">>>>\",i,j)\n",
    "        for trial in range(3):\n",
    "            train_loader,test_loader=genData(i,j)\n",
    "            model=run(train_loader,i,j)\n",
    "            test_scores[i][j-1][trial]=calc(model,test_loader)\n",
    "            train_scores[i][j-1][trial]=calc(model,train_loader)\n",
    "        np.save(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/test_scores\",test_scores)\n",
    "        np.save(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/train_scores\",train_scores)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
