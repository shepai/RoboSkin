{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import getsizeof\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:18230\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.imshow(data.AugmentedX[0].reshape((5*110,120)))\\nplt.show()\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class loaded:\n",
    "    def __init__(self,frm=0,t=20):\n",
    "        data = np.load(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/texture-tactip/X_texture.npz\") #load data\n",
    "        for array_name in data:\n",
    "            self.X=(data[array_name].astype(np.uint8))\n",
    "        data = np.load(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/texture-tactip/y_texture.npz\") #load data\n",
    "        for array_name in data:\n",
    "            self.y=(data[array_name].astype(np.uint8))\n",
    "        self.keys={}\n",
    "        self.files=['wool', 'LacedMatt', 'Gfoam', 'bubble', 'Efoam', 'cotton', 'Flat', 'felt', 'Ffoam']\n",
    "        for i, name in enumerate(self.files):\n",
    "            self.keys[i]=name\n",
    "        self.keys={14: 'wool', 23: 'jeans', 20: 'LacedMatt', 22: 'Gfoam', 27: 'bubble', 16: 'Efoam', 21: 'cotton', 11: 'Flat', 24: 'felt', 26: 'Ffoam'}\n",
    "        print(\"Dataset size:\",self.X.shape[0],\"\\nWindow size:\",self.X.shape[1],\"\\nImage:\",self.X.shape[2:])\n",
    "        print(\"Memory needed:\",round(getsizeof(self.X)/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "        assert self.X.shape[0]==self.y.shape[0],\"Incorrect data size match y=\"+str(self.y.shape[0])+\" x=\"+str(self.X.shape[0])\n",
    "        self.X=self.X[:,frm:t]\n",
    "        #randomize order\n",
    "        n_samples = self.X.shape[0]\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        shuffled_data = self.X[indices]\n",
    "        shuffled_labels = self.y[indices]\n",
    "        self.X=shuffled_data\n",
    "        self.y=shuffled_labels\n",
    "    def augment(self):\n",
    "        #create rotations\n",
    "        self.AugmentedX=np.zeros((len(self.X)*3,*self.X.shape[1:]),dtype=np.uint8)\n",
    "        self.Augmentedy=np.zeros_like(np.concatenate((self.y,self.y,self.y)))\n",
    "        for k,i in enumerate(range(0,len(self.AugmentedX),3)): #loop through the normal data and new data\n",
    "            for j in range(len(self.X[0])):\n",
    "                self.AugmentedX[i][j]=np.copy(self.X[k][j])\n",
    "                self.AugmentedX[i+1][j]=cv2.resize(cv2.rotate(self.X[k][j].copy(), cv2.ROTATE_90_CLOCKWISE),(self.X[k][j].shape[1],self.X[k][j].shape[0]),interpolation=cv2.INTER_AREA)\n",
    "                self.AugmentedX[i+2][j]=cv2.resize(cv2.rotate(self.X[k][j].copy(), cv2.ROTATE_180),(self.X[k][j].shape[1],self.X[k][j].shape[0]),interpolation=cv2.INTER_AREA)\n",
    "                self.Augmentedy[i+1]=self.y[k]\n",
    "                self.Augmentedy[i+2]=self.y[k]\n",
    "                self.Augmentedy[i]=self.y[k]\n",
    "                #self.AugmentedX[i+3][j]=cv2.rotate(self.X[k][j], cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        print(\"Dataset size:\",self.AugmentedX.shape[0],\"\\nWindow size:\",self.X.shape[1],\"\\nImage:\",self.X.shape[2:])\n",
    "        print(\"Memory needed:\",round(getsizeof(self.AugmentedX)/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "        #randomize order\n",
    "        n_samples = self.X.shape[0]\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        shuffled_data = self.X[indices]\n",
    "        shuffled_labels = self.y[indices]\n",
    "        self.AugmentedX=shuffled_data\n",
    "        self.Augmentedy=shuffled_labels\n",
    "        del self.X\n",
    "        del self.y\n",
    "    def applySobel(self):\n",
    "        for i in range(len(self.X)): #crop all images individually\n",
    "            for j in range(len(self.X[0])):\n",
    "                image=self.X[i][j]\n",
    "                # Apply Sobel filter in x-direction\n",
    "                sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)  # ksize=3 for a 3x3 Sobel kernel\n",
    "\n",
    "                # Apply Sobel filter in y-direction\n",
    "                sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "                # Convert the results back to uint8\n",
    "                sobel_x = np.uint8(np.absolute(sobel_x))\n",
    "                sobel_y = np.uint8(np.absolute(sobel_y))\n",
    "\n",
    "                # Combine the results to get the final edge-detected image\n",
    "                sobel_combined = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "                self.X[i][j]=sobel_combined\n",
    "\n",
    "\"\"\"\n",
    "plt.imshow(data.AugmentedX[0].reshape((5*110,120)))\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genData(frm,to):\n",
    "    torch.cuda.empty_cache()\n",
    "    data=loaded(frm=frm,t=to)\n",
    "    data.applySobel()\n",
    "    data.augment()\n",
    "    n=int(len(data.AugmentedX)*0.66)\n",
    "    # Example: if train_labels are strings, use LabelEncoder to convert them to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_encoded = label_encoder.fit_transform(data.Augmentedy[0:n])\n",
    "    one_hot_labels = torch.nn.functional.one_hot(torch.tensor(train_labels_encoded), num_classes=len(np.unique(train_labels_encoded)))\n",
    "    print(\"Memory left\",round(torch.cuda.mem_get_info()[1]/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "    x_data=data.AugmentedX[0:n].reshape((len(data.AugmentedX[0:n]),1,abs(frm-to)*110,120))\n",
    "    x_data=(x_data-np.mean(x_data))/(np.max(x_data)-np.min(x_data))\n",
    "    train_images_tensor = torch.tensor(x_data, dtype=torch.float16).to(device)\n",
    "    print(\"Using\",round(getsizeof(x_data)/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "    train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float16).to(device)\n",
    "\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "    # Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Create DataLoader for training and testing sets\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=64,shuffle=False)\n",
    "\n",
    "    print(train_images_tensor.shape)\n",
    "    print(train_labels_tensor.shape)\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self,input_height, input_width):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        height = input_height\n",
    "        width = input_width\n",
    "        \n",
    "        height = height // 2  # after first pooling\n",
    "        width = width // 2\n",
    "        height = height // 2  # after second pooling\n",
    "        width = width // 2\n",
    "        \n",
    "        # Number of output features from conv layers (channels * height * width)\n",
    "        self.flatten_size = 64 * height * width\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flatten_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.flatten_size)  # Flatten the tensor\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Loss Function and Optimizer\n",
    "def run(train_loader,frm,to):\n",
    "    model = SimpleCNN(abs(frm-to)*110,120).to(device).half()\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "    # Train the Model\n",
    "    num_epochs = 100\n",
    "    clip_value = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "        if epoch%10==0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss :.4f}')\n",
    "    print('Finished Training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(model,data_loader):\n",
    "        correct=0\n",
    "        summed=0.1\n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            outputs = model(inputs)\n",
    "            a=torch.argmax(outputs,axis=1)==torch.argmax(labels,axis=1)\n",
    "\n",
    "            summed+=len(inputs)\n",
    "            correct+=len(a[a==1])\n",
    "        print(\"Accuracy:\",(correct/summed)*100,\"%\")\n",
    "        return correct/summed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 9 14 \n",
      "Max: 99.98422961677969 % \n",
      "Estimated time left: 601.9846753329039 minutes\n",
      "Dataset size: 4800 \n",
      "Window size: 20 \n",
      "Image: (110, 120)\n",
      "Memory needed: 1.18 GB\n",
      "Dataset size: 14400 \n",
      "Window size: 5 \n",
      "Image: (110, 120)\n",
      "Memory needed: 0.89 GB\n",
      "Memory left 12.0 GB\n",
      "Using 1.56 GB\n",
      "torch.Size([3168, 1, 550, 120])\n",
      "torch.Size([3168, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dexte\\AppData\\Local\\Temp\\ipykernel_17872\\2310178645.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float16).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [40/40], Loss: 86.5547\n",
      "Epoch [11/100], Step [40/40], Loss: 63.7539\n",
      "Epoch [21/100], Step [40/40], Loss: 28.1851\n",
      "Epoch [31/100], Step [40/40], Loss: 18.4707\n",
      "Epoch [41/100], Step [40/40], Loss: 13.1080\n",
      "Epoch [51/100], Step [40/40], Loss: 10.2525\n",
      "Epoch [61/100], Step [40/40], Loss: 7.5103\n",
      "Epoch [71/100], Step [40/40], Loss: 7.0323\n",
      "Epoch [81/100], Step [40/40], Loss: 5.3497\n",
      "Epoch [91/100], Step [40/40], Loss: 4.8468\n",
      "Finished Training\n",
      "Accuracy: 97.9340797981391 %\n",
      "Accuracy: 98.49650763584705 %\n",
      "Dataset size: 4800 \n",
      "Window size: 20 \n",
      "Image: (110, 120)\n",
      "Memory needed: 1.18 GB\n",
      "Dataset size: 14400 \n",
      "Window size: 5 \n",
      "Image: (110, 120)\n",
      "Memory needed: 0.89 GB\n",
      "Memory left 12.0 GB\n",
      "Using 1.56 GB\n",
      "torch.Size([3168, 1, 550, 120])\n",
      "torch.Size([3168, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dexte\\AppData\\Local\\Temp\\ipykernel_17872\\2310178645.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float16).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [40/40], Loss: 86.1055\n",
      "Epoch [11/100], Step [40/40], Loss: 45.0303\n",
      "Epoch [21/100], Step [40/40], Loss: 23.9165\n",
      "Epoch [31/100], Step [40/40], Loss: 16.6741\n",
      "Epoch [41/100], Step [40/40], Loss: 12.4977\n",
      "Epoch [51/100], Step [40/40], Loss: 10.3176\n",
      "Epoch [61/100], Step [40/40], Loss: 7.9078\n",
      "Epoch [71/100], Step [40/40], Loss: 6.8450\n",
      "Epoch [81/100], Step [40/40], Loss: 5.5736\n",
      "Epoch [91/100], Step [40/40], Loss: 5.0195\n",
      "Finished Training\n",
      "Accuracy: 97.14556063712348 %\n",
      "Accuracy: 97.43104060613236 %\n",
      "Dataset size: 4800 \n",
      "Window size: 20 \n",
      "Image: (110, 120)\n",
      "Memory needed: 1.18 GB\n",
      "Dataset size: 14400 \n",
      "Window size: 5 \n",
      "Image: (110, 120)\n",
      "Memory needed: 0.89 GB\n",
      "Memory left 12.0 GB\n",
      "Using 1.56 GB\n",
      "torch.Size([3168, 1, 550, 120])\n",
      "torch.Size([3168, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dexte\\AppData\\Local\\Temp\\ipykernel_17872\\2310178645.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float16).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [40/40], Loss: 86.6074\n",
      "Epoch [11/100], Step [40/40], Loss: 56.7959\n",
      "Epoch [21/100], Step [40/40], Loss: 25.5894\n",
      "Epoch [31/100], Step [40/40], Loss: 16.0010\n",
      "Epoch [41/100], Step [40/40], Loss: 11.6927\n",
      "Epoch [51/100], Step [40/40], Loss: 9.0209\n",
      "Epoch [61/100], Step [40/40], Loss: 7.3982\n",
      "Epoch [71/100], Step [40/40], Loss: 6.0674\n",
      "Epoch [81/100], Step [40/40], Loss: 4.9862\n",
      "Epoch [91/100], Step [40/40], Loss: 4.1385\n",
      "Finished Training\n",
      "Accuracy: 96.51474530831099 %\n",
      "Accuracy: 96.36557357641766 %\n"
     ]
    }
   ],
   "source": [
    "test_scores=np.zeros((10,14,3))\n",
    "train_scores=np.zeros((10,14,3))\n",
    "t_averages=np.zeros((10*14*3))\n",
    "\n",
    "#test_scores=np.load(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/test_scores.npy\")\n",
    "#train_scores=np.load(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/train_scores.npy\")\n",
    "c=0\n",
    "for i in range(1,10): #loop through frm dimention\n",
    "    for j in range(i+1,15): #loop though to dimention\n",
    "        print(\">>>>\",i,j,\"\\nMax:\",np.max(test_scores)*100,\"%\",\"\\nEstimated time left:\",(np.average(t_averages[t_averages!=0])*len(t_averages[t_averages==0]))/60,\"minutes\")\n",
    "        for trial in range(3):\n",
    "            t=time.time()\n",
    "            torch.cuda.empty_cache()\n",
    "            train_loader,test_loader=genData(i,j)\n",
    "            model=run(train_loader,i,j)\n",
    "            test_scores[i][j-1][trial]=calc(model,test_loader)\n",
    "            train_scores[i][j-1][trial]=calc(model,train_loader)\n",
    "            torch.cuda.empty_cache()\n",
    "            del train_loader\n",
    "            del test_loader\n",
    "            del model\n",
    "            t2=time.time()\n",
    "            t_averages[c]=t2-t\n",
    "            c+=1\n",
    "        clear_output(wait=True)\n",
    "        np.save(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/test_scores\",test_scores)\n",
    "        np.save(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/train_scores\",train_scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.9871185 , 0.98399361, 0.98816013],\n",
       "        [0.98329919, 0.96107774, 0.98989618],\n",
       "        [0.98781292, 0.99093781, 0.97427173],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar=np.load(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/test_scores.npy\")\n",
    "ar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
