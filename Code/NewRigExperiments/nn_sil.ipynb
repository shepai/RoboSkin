{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import getsizeof\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "path=\"/its/home/drs25/RoboSkin/Code/NewRigExperiments/\"\n",
    "datapath=\"/its/home/drs25/datasets/\"\n",
    "if os.name == 'nt':\n",
    "    path=\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/\"\n",
    "    datapath=\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/texture-tactip/\"\n",
    "from IPython.display import clear_output\n",
    "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:18230\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "csfont = {'fontname':'Times New Roman'}\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loaded:\n",
    "    def __init__(self,t=20,filename=\"X_data_15.npz\"):\n",
    "        data = np.load(datapath+filename) #load data\n",
    "        for array_name in data:\n",
    "            self.X=(data[array_name].astype(np.uint8))\n",
    "        data = np.load(datapath+filename.replace(\"X\",\"y\")) #load data\n",
    "        for array_name in data:\n",
    "            self.y=(data[array_name].astype(np.uint8))\n",
    "        self.keys=['Leather', 'Cork', 'wool', 'LacedMatt', 'Gfoam', 'Plastic', 'Carpet', 'bubble', 'Efoam', 'cotton', 'LongCarpet', 'Flat', 'felt', 'Jeans', 'Ffoam']\n",
    "\n",
    "        print(\"Dataset size:\",self.X.shape[0],\"\\nWindow size:\",self.X.shape[1],\"\\nImage:\",self.X.shape[2:])\n",
    "        print(\"Memory needed:\",round(getsizeof(self.X)/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "        assert self.X.shape[0]==self.y.shape[0],\"Incorrect data size match y=\"+str(self.y.shape[0])+\" x=\"+str(self.X.shape[0])\n",
    "        self.X=self.X[:,0:t]\n",
    "        #randomize order\n",
    "        n_samples = self.X.shape[0]\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        shuffled_data = self.X[indices]\n",
    "        shuffled_labels = self.y[indices]\n",
    "        self.X=shuffled_data\n",
    "        self.y=shuffled_labels\n",
    "    def shuffle(self):\n",
    "        n_samples = self.X.shape[0]\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        shuffled_data = self.X[indices]\n",
    "        shuffled_labels = self.y[indices]\n",
    "        self.X=shuffled_data\n",
    "        self.y=shuffled_labels\n",
    "    def augment(self):\n",
    "        #create rotations\n",
    "        self.AugmentedX=np.zeros((len(self.X)*3,*self.X.shape[1:]),dtype=np.uint8)\n",
    "        self.Augmentedy=np.zeros_like(np.concatenate((self.y,self.y,self.y)))\n",
    "        for k,i in enumerate(range(0,len(self.AugmentedX),3)): #loop through the normal data and new data\n",
    "            for j in range(len(self.X[0])):\n",
    "                self.AugmentedX[i][j]=np.copy(self.X[k][j])\n",
    "                self.AugmentedX[i+1][j]=cv2.resize(cv2.rotate(self.X[k][j].copy(), cv2.ROTATE_90_CLOCKWISE),(self.X[k][j].shape[1],self.X[k][j].shape[0]),interpolation=cv2.INTER_AREA)\n",
    "                self.AugmentedX[i+2][j]=cv2.resize(cv2.rotate(self.X[k][j].copy(), cv2.ROTATE_180),(self.X[k][j].shape[1],self.X[k][j].shape[0]),interpolation=cv2.INTER_AREA)\n",
    "                self.Augmentedy[i+1]=self.y[k]\n",
    "                self.Augmentedy[i+2]=self.y[k]\n",
    "                self.Augmentedy[i]=self.y[k]\n",
    "                #self.AugmentedX[i+3][j]=cv2.rotate(self.X[k][j], cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        x,y=self.zoom_augment(self.AugmentedX.copy(),self.Augmentedy.copy(),[10,20,30,40])\n",
    "        print(x.shape,self.AugmentedX.shape)\n",
    "        self.AugmentedX=np.concatenate([self.AugmentedX,x])\n",
    "        self.Augmentedy=np.concatenate([self.Augmentedy,y])\n",
    "\n",
    "        print(\"Dataset size:\",self.AugmentedX.shape[0],\"\\nWindow size:\",self.X.shape[1],\"\\nImage:\",self.X.shape[2:])\n",
    "        print(\"Memory needed:\",round(getsizeof(self.AugmentedX)/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "        self.X = self.AugmentedX\n",
    "        self.y = self.Augmentedy\n",
    "        n_samples = self.X.shape[0]\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        shuffled_data = self.X[indices]\n",
    "        shuffled_labels = self.y[indices]\n",
    "        self.X=shuffled_data\n",
    "        self.y=shuffled_labels\n",
    "        del self.AugmentedX\n",
    "        del self.Augmentedy\n",
    "    def applySobel(self):\n",
    "        for i in range(len(self.X)): #crop all images individually\n",
    "            for j in range(len(self.X[0])):\n",
    "                image=self.X[i][j]\n",
    "                # Apply Sobel filter in x-direction\n",
    "                sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)  # ksize=3 for a 3x3 Sobel kernel\n",
    "\n",
    "                # Apply Sobel filter in y-direction\n",
    "                sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "                # Convert the results back to uint8\n",
    "                sobel_x = np.uint8(np.absolute(sobel_x))\n",
    "                sobel_y = np.uint8(np.absolute(sobel_y))\n",
    "\n",
    "                # Combine the results to get the final edge-detected image\n",
    "                sobel_combined = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "                self.X[i][j]=sobel_combined\n",
    "    def zoom_augment(self,dataX, dataY, zoom_factors):\n",
    "        \"\"\"\n",
    "        Augment a dataset by zooming into the central region and resizing back to original dimensions.\n",
    "        \n",
    "        Parameters:\n",
    "            dataX (numpy array): Dataset of shape (n, t, h, w).\n",
    "            dataY (numpy array): Corresponding labels of shape (n, ...).\n",
    "            zoom_factors (list): List of zoom-in percentages (e.g., [10, 20, 30]).\n",
    "        \n",
    "        Returns:\n",
    "            augmented_dataX (list): List of augmented datasets, one for each zoom factor.\n",
    "            augmented_dataY (list): List of label arrays corresponding to each augmented dataset.\n",
    "        \"\"\"\n",
    "        n, t, h, w = dataX.shape\n",
    "        augmented_dataX = []\n",
    "        augmented_dataY = []\n",
    "        \n",
    "        for zoom in zoom_factors:\n",
    "            crop_margin = int((zoom / 100) * min(h, w) / 2)\n",
    "            cropped_and_resized = np.zeros_like(dataX)\n",
    "            \n",
    "            for i in range(n):\n",
    "                for j in range(t):\n",
    "                    # Crop the central region\n",
    "                    cropped = dataX[i, j, crop_margin:h-crop_margin, crop_margin:w-crop_margin]\n",
    "                    # Resize back to original dimensions\n",
    "                    cropped_and_resized[i, j] = cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            augmented_dataX.append(cropped_and_resized)\n",
    "            augmented_dataY.append(dataY.copy())  # Labels remain the same\n",
    "        augmented_dataX=np.array(augmented_dataX)\n",
    "        augmented_dataY=np.array(augmented_dataY)\n",
    "        return augmented_dataX.reshape((len(zoom_factors)*augmented_dataX.shape[1],*augmented_dataX.shape[2:])), augmented_dataY.reshape((len(zoom_factors)*augmented_dataY.shape[1],))\n",
    "    def resize(self,percentage):\n",
    "        h=int(self.X.shape[2]*percentage)\n",
    "        w=int(self.X.shape[3]*percentage)\n",
    "        new_array=np.zeros((*self.X.shape[0:2],h,w))\n",
    "\n",
    "        for i in range(len(self.X)): #crop all images individually\n",
    "            for j in range(len(self.X[0])):\n",
    "                image=self.X[i][j]\n",
    "                iamge = cv2.resize(image,(w,h),interpolation=cv2.INTER_AREA)\n",
    "                new_array[i][j]=iamge\n",
    "        self.X=new_array.copy()\n",
    "#data=loaded(t=4)\n",
    "#data.applySobel()\n",
    "#data.augment()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genData(frm,to,percentage=1):\n",
    "    torch.cuda.empty_cache()\n",
    "    data=loaded(to,filename=\"X_data_newMorph.npz\") #X_data_15.npz\n",
    "    data.applySobel()\n",
    "    \"\"\"data2=loaded(to,filename=\"X_data_15.npz\")\n",
    "    data2.applySobel()\n",
    "    data.X=np.concatenate([data.X,data2.X])\n",
    "    data.y=np.concatenate([data.y,data2.y])\n",
    "    del data2\n",
    "    data3=loaded(to,filename=\"X_data_newMorph.npz\")\n",
    "    data3.applySobel()\n",
    "    data.X=np.concatenate([data.X,data3.X])\n",
    "    data.y=np.concatenate([data.y,data3.y])\n",
    "    del data3\"\"\"\n",
    "    data.resize(percentage)\n",
    "    data.augment()\n",
    "    data.shuffle()\n",
    "    #add lowest unseen \n",
    "    #d=loaded(t=4,filename=\"X_data_newMorph.npz\")\n",
    "    #d.applySobel()\n",
    "    #p20=d.X[np.where(d.y==3)]\n",
    "    #data.X=np.concatenate([data.X,p20])\n",
    "    #data.y=np.concatenate([data.y,np.zeros((len(p20)))+11])\n",
    "    #data.resize(percentage)\n",
    "    print(\"LOADED DATASET...\")\n",
    "    #data.augment()\n",
    "    n=int(len(data.X)*0.7)\n",
    "    # Example: if train_labels are strings, use LabelEncoder to convert them to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_encoded = label_encoder.fit_transform(data.y[0:n])\n",
    "    one_hot_labels = torch.nn.functional.one_hot(torch.tensor(train_labels_encoded), num_classes=len(np.unique(train_labels_encoded)))\n",
    "    print(\"Memory left\",round(torch.cuda.mem_get_info()[1]/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "    x_data=data.X[0:n].reshape((len(data.X[0:n]),1,abs(frm-to)*data.X.shape[2],data.X.shape[3]))\n",
    "    del data\n",
    "    x_data=(x_data-np.mean(x_data))/(np.max(x_data)-np.min(x_data)) #preprocessing\n",
    "    \n",
    "    train_images_tensor = torch.tensor(x_data, dtype=torch.float32).to(device)\n",
    "    print(\"Using\",round(getsizeof(x_data)/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "    del x_data\n",
    "    train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "    # Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Create DataLoader for training and testing sets\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=40, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=40,shuffle=False)\n",
    "\n",
    "    print(train_images_tensor.shape)\n",
    "    print(train_labels_tensor.shape)\n",
    "    \n",
    "    return train_loader,test_loader\n",
    "\n",
    "def genDataANN(frm,to,percentage=1):\n",
    "    torch.cuda.empty_cache()\n",
    "    data=loaded(to,filename=\"X_data_15.npz\")\n",
    "    data.applySobel()\n",
    "    data.shuffle()\n",
    "    data.resize(percentage)\n",
    "    print(\"LOADED DATASET...\")\n",
    "    data.augment()\n",
    "    n=int(len(data.X)*0.7)\n",
    "    # Example: if train_labels are strings, use LabelEncoder to convert them to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_encoded = label_encoder.fit_transform(data.y[0:n])\n",
    "    one_hot_labels = torch.nn.functional.one_hot(torch.tensor(train_labels_encoded), num_classes=len(np.unique(train_labels_encoded)))\n",
    "    print(\"Memory left\",round(torch.cuda.mem_get_info()[1]/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "    x_data=data.X[0:n].reshape((len(data.X[0:n]),abs(frm-to)*data.X.shape[2]*data.X.shape[3]))\n",
    "    del data\n",
    "    x_data=(x_data-np.mean(x_data))/(np.max(x_data)-np.min(x_data)) #preprocessing\n",
    "    \n",
    "    train_images_tensor = torch.tensor(x_data, dtype=torch.float32).to(device)\n",
    "    print(\"Using\",round(getsizeof(x_data)/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "    del x_data\n",
    "    train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "    # Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Create DataLoader for training and testing sets\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=40, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=40,shuffle=False)\n",
    "\n",
    "    print(train_images_tensor.shape)\n",
    "    print(train_labels_tensor.shape)\n",
    "    \n",
    "    return train_loader,test_loader\n",
    "def gen3DData(frm,to,percentage=1):\n",
    "    torch.cuda.empty_cache()\n",
    "    data=loaded(frm=frm,t=to)\n",
    "    data.applySobel()\n",
    "    data.augment()\n",
    "    data.resize(percentage)\n",
    "    n=int(len(data.X)*0.6)\n",
    "    # Example: if train_labels are strings, use LabelEncoder to convert them to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_encoded = label_encoder.fit_transform(data.y[0:n])\n",
    "    one_hot_labels = torch.nn.functional.one_hot(torch.tensor(train_labels_encoded), num_classes=len(np.unique(train_labels_encoded)))\n",
    "    print(\"Memory left\",round(torch.cuda.mem_get_info()[1]/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "    x_data=data.X[0:n].reshape((len(data.X[0:n]),1,abs(frm-to),data.X.shape[2],data.X.shape[3]))\n",
    "    x_data=(x_data-np.mean(x_data))/(np.max(x_data)-np.min(x_data)) #preprocessing\n",
    "    train_images_tensor = torch.tensor(x_data, dtype=torch.float32).to(device)\n",
    "    print(\"Using\",round(getsizeof(x_data)/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "    train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "    # Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Create DataLoader for training and testing sets\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=40, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=40,shuffle=False)\n",
    "\n",
    "    print(train_images_tensor.shape)\n",
    "    print(train_labels_tensor.shape)\n",
    "    unique={}\n",
    "    for i in range(len(train_labels_encoded)):\n",
    "        if unique.get(train_labels_encoded[i],False)==False:\n",
    "            unique[train_labels_encoded[i]]=data.y[0:n][i]\n",
    "    return train_loader,test_loader,unique\n",
    "def genLSTMData(frm,to,percentage=1):\n",
    "    torch.cuda.empty_cache()\n",
    "    data=loaded(to,filename=\"X_data_15.npz\")\n",
    "    #data.applySobel()\n",
    "    #data=loaded(to,filename=\"X_data_15.npz\")\n",
    "    data.applySobel()\n",
    "    #data3=loaded(to,filename=\"X_data_gel_15.npz\")\n",
    "    #data3.applySobel()\n",
    "    #data.X=np.concatenate([data.X,data2.X,data3.X])\n",
    "    #data.y=np.concatenate([data.y,data2.y,data3.y])\n",
    "    #del data2\n",
    "    #del data3\n",
    "    data.augment()\n",
    "    #add lowest unseen \n",
    "    #d=loaded(t=4,filename=\"X_flat_unseen_pressures.npz\")\n",
    "    #d.applySobel()\n",
    "    #data.augment()\n",
    "    data.resize(percentage)\n",
    "    n=-1#int(len(data.X)*0.7)\n",
    "    # Example: if train_labels are strings, use LabelEncoder to convert them to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_encoded = label_encoder.fit_transform(data.y[0:n])\n",
    "    one_hot_labels = torch.nn.functional.one_hot(torch.tensor(train_labels_encoded), num_classes=len(np.unique(train_labels_encoded)))\n",
    "    print(\"Memory left\",round(torch.cuda.mem_get_info()[1]/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "    x_data=data.X[0:n].reshape((len(data.X[0:n]),abs(frm-to),data.X.shape[2]*data.X.shape[3]))\n",
    "    x_data=(x_data-np.mean(x_data))/(np.max(x_data)-np.min(x_data)) #preprocessing\n",
    "    train_images_tensor = torch.tensor(x_data, dtype=torch.float32).to(device)\n",
    "    print(\"Using\",round(getsizeof(x_data)/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "    train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "    # Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Create DataLoader for training and testing sets\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=40, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=40,shuffle=False)\n",
    "\n",
    "    print(train_images_tensor.shape)\n",
    "    print(train_labels_tensor.shape)\n",
    "    unique={}\n",
    "    for i in range(len(train_labels_encoded)):\n",
    "        if unique.get(train_labels_encoded[i],False)==False:\n",
    "            unique[train_labels_encoded[i]]=data.y[0:n][i]\n",
    "    return train_loader,test_loader\n",
    "def genCNNLSTMData(frm,to,percentage=1):\n",
    "    torch.cuda.empty_cache()\n",
    "    data=loaded(to,filename=\"X_data_newMorph.npz\")\n",
    "    data.applySobel()\n",
    "    data2=loaded(to,filename=\"X_data_15.npz\")\n",
    "    data2.applySobel()\n",
    "    data3=loaded(to,filename=\"X_data_gel_15.npz\")\n",
    "    data3.applySobel()\n",
    "    data.X=np.concatenate([data.X,data2.X,data3.X])\n",
    "    data.y=np.concatenate([data.y,data2.y,data3.y])\n",
    "    del data2\n",
    "    del data3\n",
    "    data.augment()\n",
    "\n",
    "    #data.resize(percentage)\n",
    "    n=-1#int(len(data.X)*0.7)\n",
    "    # Example: if train_labels are strings, use LabelEncoder to convert them to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_encoded = label_encoder.fit_transform(data.y[0:n])\n",
    "    one_hot_labels = torch.nn.functional.one_hot(torch.tensor(train_labels_encoded), num_classes=len(np.unique(train_labels_encoded)))\n",
    "    print(\"Memory left\",round(torch.cuda.mem_get_info()[1]/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "    x_data=data.X[0:n].reshape((len(data.X[0:n]),1,abs(frm-to),data.X.shape[2],data.X.shape[3]))\n",
    "    x_data=(x_data-np.mean(x_data))/(np.max(x_data)-np.min(x_data)) #preprocessing\n",
    "    train_images_tensor = torch.tensor(x_data, dtype=torch.float32).to(device)\n",
    "    print(\"Using\",round(getsizeof(x_data)/ 1024 / 1024/ 1024,2),\"GB\")\n",
    "    train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "    # Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Create DataLoader for training and testing sets\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=40, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=40,shuffle=False)\n",
    "\n",
    "    print(train_images_tensor.shape)\n",
    "    print(train_labels_tensor.shape)\n",
    "    unique={}\n",
    "    for i in range(len(train_labels_encoded)):\n",
    "        if unique.get(train_labels_encoded[i],False)==False:\n",
    "            unique[train_labels_encoded[i]]=data.y[0:n][i]\n",
    "    return train_loader,test_loader,unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self,input_height, input_width,output=15):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 10, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.flatten_size = 10 * (input_height // 4) * (input_width // 4)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flatten_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), self.flatten_size)  # Flatten the tensor\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "class SimpleANN(nn.Module):\n",
    "    def __init__(self,input, hidden,output=15):\n",
    "        super(SimpleANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, output)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "class Simple3DCNN(nn.Module):\n",
    "    def __init__(self, input_depth, input_height, input_width):\n",
    "        super(Simple3DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(32, 10, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        depth = input_depth\n",
    "        height = input_height\n",
    "        width = input_width\n",
    "        \n",
    "        depth = depth // 2  # after first pooling\n",
    "        height = height // 2\n",
    "        width = width // 2\n",
    "        \n",
    "        depth = depth // 2  # after second pooling\n",
    "        height = height // 2\n",
    "        width = width // 2\n",
    "        \n",
    "        # Number of output features from conv layers (channels * depth * height * width)\n",
    "        self.flatten_size = 10 * depth * height * width\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flatten_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 13)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.flatten_size)  # Flatten the tensor\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, input_width, input_height, hidden_size, num_layers, num_classes):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        \n",
    "        # Define the CNN part\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(32, 10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Calculate the CNN output size\n",
    "        cnn_output_size = self._get_cnn_output_size(input_width, input_height)\n",
    "        \n",
    "        # Define the LSTM part\n",
    "        self.lstm = nn.LSTM(input_size=cnn_output_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Define the final fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def _get_cnn_output_size(self, width, height):\n",
    "        # Create a dummy tensor with the given width and height\n",
    "        dummy_input = torch.zeros(1, 1, height, width)\n",
    "        \n",
    "        # Pass the dummy tensor through the CNN\n",
    "        dummy_output = self.cnn(dummy_input)\n",
    "        \n",
    "        # Calculate the output size by flattening the output\n",
    "        return dummy_output.view(-1).size(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, c, sequence_length, h, w = x.size()\n",
    "        # Reshape input to (batch_size * sequence_length, c, h, w) for CNN\n",
    "        c_in = x.view(batch_size * sequence_length, c, h, w)\n",
    "        \n",
    "        # Pass through CNN\n",
    "        c_out = self.cnn(c_in)\n",
    "        \n",
    "        # Flatten the CNN output\n",
    "        c_out = c_out.view(c_out.size(0), -1)\n",
    "        \n",
    "        # Reshape to (batch_size, sequence_length, cnn_output_size) for LSTM\n",
    "        lstm_in = c_out.view(batch_size, sequence_length, -1)\n",
    "        \n",
    "        # Pass through LSTM\n",
    "        lstm_out, (h_n, c_n) = self.lstm(lstm_in)\n",
    "        \n",
    "        # Get the output from the last time step\n",
    "        output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Pass through fully connected layer\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_loader,frm,to,num_epochs = 100):\n",
    "    train_history=[]\n",
    "    image=next(iter(train_loader))\n",
    "    image=image[0][0][0]\n",
    "    output=len(next(iter(train_loader))[1][0])\n",
    "    model = SimpleCNN(image.shape[0],image.shape[1],output=output).to(device)#.half()\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "    # Train the Model\n",
    "    \n",
    "    clip_value = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            #print(inputs.shape,outputs.shape,labels.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "        train_history.append(loss.cpu().detach().numpy())\n",
    "        if epoch%10==0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss :.4f}')\n",
    "    print('Finished Training')\n",
    "    return model,train_history\n",
    "\n",
    "def runANN(train_loader,frm,to,num_epochs = 100):\n",
    "    train_history=[]\n",
    "    image=next(iter(train_loader))\n",
    "    image=image[0][0]\n",
    "    output=len(next(iter(train_loader))[1][0])\n",
    "    print(\"SHAPE....\",image.shape)\n",
    "    model = SimpleANN(image.shape[0],400,output=output).to(device)#.half()\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "    # Train the Model\n",
    "    \n",
    "    clip_value = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            #print(inputs.shape,outputs.shape,labels.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "        train_history.append(loss.cpu().detach().numpy())\n",
    "        if epoch%10==0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss :.4f}')\n",
    "    print('Finished Training')\n",
    "    return model,train_history\n",
    "\n",
    "def run3D(train_loader,frm,to):\n",
    "    train_history=[]\n",
    "    image=next(iter(train_loader))\n",
    "    image=image[0][0][0]\n",
    "    model = Simple3DCNN(image.shape[0],image.shape[1],image.shape[2]).to(device)#.half()\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "    # Train the Model\n",
    "    num_epochs = 100\n",
    "    clip_value = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            #print(inputs.shape,outputs.shape,labels.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "        train_history.append(loss.cpu().detach().numpy())\n",
    "        if epoch%10==0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss :.4f}')\n",
    "    print('Finished Training')\n",
    "    return model,train_history\n",
    "def calc(model,data_loader):\n",
    "        correct=0\n",
    "        summed=0.1\n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            outputs = model(inputs)\n",
    "            a=torch.argmax(outputs,axis=1)==torch.argmax(labels,axis=1)\n",
    "\n",
    "            summed+=len(inputs)\n",
    "            correct+=len(a[a==1])\n",
    "        print(\"Accuracy:\",(correct/summed)*100,\"%\")\n",
    "        return correct/summed\n",
    "def runLSTM(train_loader,frm,to,num_epochs = 100):\n",
    "    train_history=[]\n",
    "    image=next(iter(train_loader))\n",
    "    image=image[0][0][0]\n",
    "    output=len(next(iter(train_loader))[1][0])\n",
    "    model = SimpleLSTM(image.shape[0],350,output,3).to(device)#.half()\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "    # Train the Model\n",
    "    \n",
    "    clip_value = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            #print(inputs.shape,outputs.shape,labels.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "        train_history.append(loss.cpu().detach().numpy())\n",
    "        if epoch%10==0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss :.4f}')\n",
    "    print('Finished Training')\n",
    "    return model,train_history\n",
    "def runLSTMcnn(train_loader,frm,to,num_epochs=150):\n",
    "    train_history=[]\n",
    "    image=next(iter(train_loader))\n",
    "    image=image[0][0][0][0]\n",
    "    output=len(next(iter(train_loader))[1][0])\n",
    "    model = CNN_LSTM(image.shape[1],image.shape[0],1000,1,output).to(device)#.half()\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "    # Train the Model\n",
    "    \n",
    "    clip_value = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            #print(inputs.shape,outputs.shape,labels.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "        train_history.append(loss.cpu().detach().numpy())\n",
    "        if epoch%10==0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss :.4f}')\n",
    "    print('Finished Training')\n",
    "    return model,train_history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "train_loader,test_loader=genDataANN(0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,history=runANN(train_loader,0,4,num_epochs = 100)\n",
    "print(calc(model,test_loader))\n",
    "print(calc(model,train_loader))\n",
    "torch.save(model.state_dict(), path+\"/model/mymodelANN\") #\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/NewRigExperiments/model/mymodelANN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "train_loader,test_loader=genData(0,4)\n",
    "model,history=run(train_loader,0,4,num_epochs = 100)\n",
    "print(calc(model,test_loader))\n",
    "print(calc(model,train_loader))\n",
    "torch.save(model.state_dict(), path+\"/model/mymodelCNN_augmented\") #\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/NewRigExperiments/model/mymodelgel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test=[]\n",
    "accuracy_train=[]\n",
    "\n",
    "for i in range(20):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loader,test_loader=genData(0,4)\n",
    "    model,history=run(train_loader,0,4)\n",
    "    print(calc(model,test_loader))\n",
    "    print(calc(model,train_loader))\n",
    "    torch.save(model.state_dict(), path+\"/model/mymodel_CNN\")\n",
    "    accuracy_test.append(calc(model,test_loader))\n",
    "    accuracy_train.append(calc(model,train_loader))\n",
    "\n",
    "np.save(path+\"/data/train_CNN_NM_accuracies_20_trials\",np.array(accuracy_train))\n",
    "np.save(path+\"/data/test_CNN_NM_accuracies_20_trials\",np.array(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   mew morph\n",
    "#model 1\n",
    "#95 93\n",
    "#model2\n",
    "#88 88\n",
    "#model 3 \n",
    "#95.2 96.6\n",
    "#model 4\n",
    "#92.5 92.4\n",
    "#model 5\n",
    "#92 93\n",
    "#model 6\n",
    "#98.2 98.9\n",
    "print(np.average([95,88,95.2,92.5,92,98]))\n",
    "#   standard\n",
    "#model 1\n",
    "#99.9 99.9\n",
    "#model2\n",
    "#99.9 99.9\n",
    "#model 3 \n",
    "#99.9 99.9\n",
    "#model 4\n",
    "#99.9 99.9\n",
    "#model 5\n",
    "#99.9 99.9\n",
    "print(np.average([99.9,99.9,99.9,99.9,99.9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)\n",
    "plt.grid(True)\n",
    "plt.title(\"Loss of CNN on both datasets\",fontsize=14)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(path+\"/images/loss_of_uber_model.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3000 \n",
      "Window size: 20 \n",
      "Image: (110, 120)\n",
      "Memory needed: 0.74 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1212728/3293731508.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path+\"/model/mymodelCNN_augmented\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=33000, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=15, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=loaded(4)\n",
    "image=data.X[0][0]\n",
    "data\n",
    "model = SimpleCNN(4*image.shape[0],image.shape[1],output=15).to(device)\n",
    "model.load_state_dict(torch.load(path+\"/model/mymodelCNN_augmented\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4, 110, 120)\n",
      "(5, 1, 440, 120)\n"
     ]
    }
   ],
   "source": [
    "test_data=np.load(\"/its/home/drs25/RoboSkin/Code/NewRigExperiments/texture-tactip/tactip_FoamE.npy\").astype(np.uint8)\n",
    "test_data_sliced=test_data[:,::2,:,:]\n",
    "test_data_sliced=test_data_sliced[:,2:2+4,:,:]\n",
    "crop=[60,180,40,150]\n",
    "im=test_data_sliced[:,:,crop[2]:crop[3],crop[0]:crop[1]]\n",
    "new=np.zeros((im.shape[0],im.shape[1],im.shape[2],im.shape[3]))\n",
    "for i in range(len(test_data_sliced)): #crop all images individually\n",
    "    for j in range(len(test_data_sliced[0])):\n",
    "        image=cv2.cvtColor(test_data_sliced[i][j][crop[2]:crop[3],crop[0]:crop[1]], cv2.COLOR_BGR2GRAY)\n",
    "        # Apply Sobel filter in x-direction\n",
    "        sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)  # ksize=3 for a 3x3 Sobel kernel\n",
    "\n",
    "        # Apply Sobel filter in y-direction\n",
    "        sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "        # Convert the results back to uint8\n",
    "        sobel_x = np.uint8(np.absolute(sobel_x))\n",
    "        sobel_y = np.uint8(np.absolute(sobel_y))\n",
    "\n",
    "        # Combine the results to get the final edge-detected image\n",
    "        sobel_combined = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "        new[i][j]=sobel_combined\n",
    "print(new.shape)\n",
    "new=new.reshape(new.shape[0],1,4*new.shape[2],new.shape[3])\n",
    "print(new.shape)\n",
    "new=(new-np.mean(new))/(np.max(new)-np.min(new))\n",
    "test_data_sliced_tensor=torch.tensor(new,dtype=torch.float64).float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preds=model(test_data_sliced_tensor)\n",
    "names=['Carpet', 'LacedMatt', 'wool', 'Cork', 'Felt', 'LongCarpet', 'cotton', 'Plastic', 'Flat', 'Ffoam', 'Gfoam', 'bubble', 'Efoam', 'jeans', 'Leather']\n",
    "\n",
    "classes=torch.argmax(preds,axis=1)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar=[]\n",
    "acc=[]\n",
    "for i in range(5):\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        train_loader,test_loader,unique=genData(0,4)\n",
    "        model,history=run(train_loader,0,4)\n",
    "        ar.append(history)\n",
    "        print(calc(model,test_loader))\n",
    "        print(calc(model,train_loader))\n",
    "        acc.append(calc(model,test_loader))\n",
    "        if acc[-1]>=max(acc):\n",
    "            torch.save(model.state_dict(), path+\"/model/mymmodel_\") #\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/NewRigExperiments/model/mymodelgel\")\n",
    "    except MemoryError as e:\n",
    "        try:\n",
    "            del train_loader\n",
    "            del test_loader\n",
    "            del model\n",
    "        except: \n",
    "            pass\n",
    "ar=np.array(ar)\n",
    "acc=np.array(acc)\n",
    "\n",
    "\n",
    "np.save(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/accuracies_of_NM_uber\",acc)\n",
    "np.save(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/loss_of_NM_uber\",ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T EXPERIEMTN\n",
    "\n",
    "ar_=[]\n",
    "acc_=[]\n",
    "for j in range(1,20,2):\n",
    "    clear_output(wait=True)\n",
    "    print(\"t SIZE:\",j)\n",
    "    ar=[]\n",
    "    acc=[]\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            torch.cuda.empty_cache()\n",
    "            train_loader,test_loader,unique=genLSTMData(0,j)\n",
    "            model,history=runLSTM(train_loader,0,j)\n",
    "            ar.append(history)\n",
    "            print(calc(model,test_loader))\n",
    "            print(calc(model,train_loader))\n",
    "            acc.append(calc(model,test_loader))\n",
    "            if acc[-1]>=max(acc):\n",
    "                torch.save(model.state_dict(), path+\"/models/lstm_\") #\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/NewRigExperiments/model/mymodelgel\")\n",
    "            del train_loader\n",
    "            del test_loader\n",
    "            del model\n",
    "        except MemoryError as e:\n",
    "            try:\n",
    "                del train_loader\n",
    "                del test_loader\n",
    "                del model\n",
    "            except: \n",
    "                pass\n",
    "    ar=np.array(ar)\n",
    "    acc=np.array(acc)\n",
    "    ar_.append(ar)\n",
    "    acc_.append(acc)\n",
    "    np.save(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/LSTMaccuracies_of_NM\",np.array(acc_))\n",
    "    np.save(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/LSTMloss_of_NM\",np.array(ar_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores=np.zeros((10,14,3))\n",
    "train_scores=np.zeros((10,14,3))\n",
    "t_averages=np.zeros((10*14*3))\n",
    "\n",
    "#test_scores=np.load(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/test_scores.npy\")\n",
    "#train_scores=np.load(\"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/saves/train_scores.npy\")\n",
    "c=0\n",
    "for i in range(1,10): #loop through frm dimention\n",
    "    for j in range(i+1,15): #loop though to dimention\n",
    "        print(\">>>>\",i,j,\"\\nMax:\",np.max(test_scores)*100,\"%\",\"\\nEstimated time left:\",(np.average(t_averages[t_averages!=0])*len(t_averages[t_averages==0]))/60,\"minutes\")\n",
    "        for trial in range(3):\n",
    "            t=time.time()\n",
    "            torch.cuda.empty_cache()\n",
    "            train_loader,test_loader,__=genData(i,j)\n",
    "            model=run(train_loader,i,j)\n",
    "            test_scores[i][j-1][trial]=calc(model,test_loader)\n",
    "            train_scores[i][j-1][trial]=calc(model,train_loader)\n",
    "            torch.cuda.empty_cache()\n",
    "            del train_loader\n",
    "            del test_loader\n",
    "            del model\n",
    "            t2=time.time()\n",
    "            t_averages[c]=t2-t\n",
    "            c+=1\n",
    "        clear_output(wait=True)\n",
    "        np.save(path+\"saves/test_scores_NM_\",test_scores)\n",
    "        np.save(path+\"saves/train_scores_NM\",train_scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resolutions=[0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.7,0.8,0.9,1]\n",
    "scores_test=np.zeros((len(resolutions),3))#np.load(path+\"/data/test_resolutions_new.npy\")#np.load(path+\"/data/test_resolutions_uber.npy\")#np.zeros((len(resolutions),3))\n",
    "scores_train=np.zeros((len(resolutions),3))#np.load(path+\"/data/train_resolutions_new.npy\")#np.load(path+\"/data/train_resolutions_uber.npy\")#np.zeros((len(resolutions),3))\n",
    "#ind=resolutions.index(0.7)\n",
    "ind=0\n",
    "try:\n",
    "    for i, res in enumerate((resolutions[ind:])): #\n",
    "        i+=ind\n",
    "        print(\"Testing resolution\",res)\n",
    "        for j in range(3): #three trials on each\n",
    "            torch.cuda.empty_cache()\n",
    "            train_loader,test_loader=genData(0,4,res)\n",
    "            model,history=run(train_loader,0,4,num_epochs = 130)\n",
    "            test_acc=calc(model,test_loader)\n",
    "            train_acc=calc(model,train_loader)\n",
    "            #look at other stuff\n",
    "            del train_loader\n",
    "            del test_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            #scores_test_NM[i][j]=len(a[a==0])/len(preds)\n",
    "            scores_test[i][j]=test_acc\n",
    "            scores_train[i][j]=train_acc\n",
    "            print(\"\\t\\t\",test_acc*100,\"%\",train_acc*100,\"%\")\n",
    "            del model\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(res)\n",
    "np.save(path+\"/data/test_resolutions_new\",scores_test)\n",
    "np.save(path+\"/data/train_resolutions_new\",scores_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path+\"/data/test_resolutions_uber\",scores_test)\n",
    "np.save(path+\"/data/train_resolutions_uber\",scores_train)\n",
    "#np.save(path+\"/data/resolutions_uberNM\",scores_test_NM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_test=np.average(scores_test,axis=1)*100\n",
    "max_test=np.max(scores_test,axis=1)*100\n",
    "average_train=np.average(scores_train,axis=1)*100\n",
    "max_train=np.max(scores_train,axis=1)*100\n",
    "average_NM=np.average(scores_test_NM,axis=1)*100\n",
    "max_NM=np.max(scores_test_NM,axis=1)*100\n",
    "\n",
    "\n",
    "plt.plot(average_test,c=\"r\",label=\"Average test\")\n",
    "plt.plot(max_test,\"--\",c=\"r\",label=\"Max test\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(average_train,c=\"b\",label=\"Average train\")\n",
    "plt.plot(max_train,\"--\",c=\"b\",label=\"Max train\")\n",
    "plt.title(\"Accuracy vs resolution\")\n",
    "plt.plot(average_NM,c=\"g\",label=\"Average new morphology\")\n",
    "plt.plot(max_NM,\"--\",c=\"g\",label=\"Max new morphology\")\n",
    "plt.grid(True)\n",
    "plt.xlim([0,0.7])\n",
    "plt.xticks([i for i in range(0,len(resolutions),2)],labels=[resolutions[i] for i in range(0,len(resolutions),2)])\n",
    "plt.xlabel(\"Resolution\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(path+\"/images/NM_resolution_uber.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3000 \n",
      "Window size: 20 \n",
      "Image: (110, 120)\n",
      "Memory needed: 0.74 GB\n"
     ]
    }
   ],
   "source": [
    "train_loader,test_loader=genLSTMData(0,4)\n",
    "model,history=runLSTM(train_loader,0,4)\n",
    "print(calc(model,test_loader))\n",
    "print(calc(model,train_loader))\n",
    "torch.save(model.state_dict(), path+\"/model/mymodel_lstm_augment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test=[]\n",
    "accuracy_train=[]\n",
    "\n",
    "for i in range(20):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loader,test_loader=genLSTMData(0,4)\n",
    "    model,history=runLSTM(train_loader,0,4)\n",
    "    print(calc(model,test_loader))\n",
    "    print(calc(model,train_loader))\n",
    "    torch.save(model.state_dict(), path+\"/model/mymodel_lstm_nm\")\n",
    "    accuracy_test.append(calc(model,test_loader))\n",
    "    accuracy_train.append(calc(model,train_loader))\n",
    "\n",
    "np.save(path+\"/data/train_LSTM_NM_accuracies_20_trials\",np.array(accuracy_train))\n",
    "np.save(path+\"/data/test_LSTM_NM_accuracies_20_trials\",np.array(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN\n",
    "torch.cuda.empty_cache()\n",
    "train_loader,test_loader,unique=genCNNLSTMData(0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,test_loader,unique=genCNNLSTMData(0,4)\n",
    "model,history=runLSTMcnn(train_loader,0,4,num_epochs=120)\n",
    "print(calc(model,test_loader))\n",
    "print(calc(model,train_loader))\n",
    "torch.save(model.state_dict(), path+\"/model/uber_lstmCNN\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resolutions=[0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.7,0.8,0.9,1]\n",
    "scores_test=np.zeros((len(resolutions),3))#np.load(path+\"/data/test_resolutions_new.npy\")#np.load(path+\"/data/test_resolutions_uber.npy\")#np.zeros((len(resolutions),3))\n",
    "scores_train=np.zeros((len(resolutions),3))#np.load(path+\"/data/train_resolutions_new.npy\")#np.load(path+\"/data/train_resolutions_uber.npy\")#np.zeros((len(resolutions),3))\n",
    "#ind=resolutions.index(0.7)\n",
    "ind=0\n",
    "try:\n",
    "    for i, res in enumerate((resolutions[ind:])): #\n",
    "        i+=ind\n",
    "        print(\"Testing resolution\",res)\n",
    "        for j in range(3): #three trials on each\n",
    "            torch.cuda.empty_cache()\n",
    "            train_loader,test_loader=genLSTMData(0,4,res)\n",
    "            print(\"*************\")\n",
    "            model,history=runLSTM(train_loader,0,4,num_epochs = 130)\n",
    "            print(\"*************\")\n",
    "            test_acc=calc(model,test_loader)\n",
    "            train_acc=calc(model,train_loader)\n",
    "            #look at other stuff\n",
    "            del train_loader\n",
    "            del test_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            #scores_test_NM[i][j]=len(a[a==0])/len(preds)\n",
    "            scores_test[i][j]=test_acc\n",
    "            scores_train[i][j]=train_acc\n",
    "            print(\"\\t\\t\",test_acc*100,\"%\",train_acc*100,\"%\")\n",
    "            del model\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(res)\n",
    "np.save(path+\"/data/test_lstm_resolutions_new\",scores_test)\n",
    "np.save(path+\"/data/train_lstm_resolutions_new\",scores_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_cnn=np.load(path+\"/data/test_resolutions.npy\")*100\n",
    "tr_cnn=np.load(path+\"/data/train_resolutions.npy\")*100\n",
    "te_cnn_n=np.load(path+\"/data/test_resolutions_new.npy\")*100\n",
    "tr_cnn_n=np.load(path+\"/data/train_resolutions_new.npy\")*100\n",
    "\n",
    "te_lstm=np.load(path+\"/data/test_lstm_resolutions.npy\")*100\n",
    "tr_lstm=np.load(path+\"/data/train_lstm_resolutions.npy\")*100\n",
    "te_lstm_n=np.load(path+\"/data/test_lstm_resolutions_new.npy\")*100\n",
    "tr_lstm_n=np.load(path+\"/data/train_lstm_resolutions_new.npy\")*100\n",
    "\n",
    "plt.plot(np.average(tr_cnn,axis=1),c=\"b\",label=\"CNN standard marker train\")\n",
    "plt.plot(np.average(te_cnn,axis=1),\"--\",c=\"b\",label=\"CNN standard marker test\")\n",
    "plt.plot(np.average(tr_cnn_n,axis=1),c=\"g\",label=\"CNN new marker train\")\n",
    "plt.plot(np.average(te_cnn_n,axis=1),\"--\",c=\"g\",label=\"CNN new marker test\")\n",
    "plt.plot(np.average(tr_lstm,axis=1),c=\"r\",label=\"LSTM standard marker train\")\n",
    "plt.plot(np.average(te_lstm,axis=1),\"--\",c=\"r\",label=\"LSTM standard marker test\")\n",
    "plt.plot(np.average(tr_lstm_n,axis=1),c=\"m\",label=\"LSTM new marker train\")\n",
    "plt.plot(np.average(te_lstm_n,axis=1),\"--\",c=\"m\",label=\"LSTM new marker test\")\n",
    "plt.grid(1)\n",
    "plt.xlabel(\"Resolution scale\")\n",
    "plt.xticks([i for i in range(len(resolutions))],resolutions)\n",
    "plt.ylabel(\"Percentage (%)\")\n",
    "plt.title(\"Average performance of models with varying resolution\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+\"/images/resolution_models.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), path+\"/model/mymodel_lstm_cnn\")\n",
    "print(calc(model,test_loader))\n",
    "print(calc(model,train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions=[0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.7,0.8,0.9,1]\n",
    "test_scores=np.zeros((len(resolutions),5))\n",
    "train_scores=np.zeros((len(resolutions),5))\n",
    "for i,res in enumerate(resolutions):\n",
    "    print(\"RESOLUTIONS\",i,\"/\",len(resolutions))\n",
    "    for trial in range(5):\n",
    "        train_loader,test_loader=genDataANN(0,4,res)\n",
    "        model,history=runANN(train_loader,0,4)\n",
    "        test_scores[i][trial]=calc(model,test_loader)\n",
    "        train_scores[i][trial]=calc(model,train_loader)\n",
    "        del train_loader\n",
    "        del model\n",
    "    np.save(path+\"/saves/ANNresolutions_train\",train_scores)\n",
    "    np.save(path+\"/saves/ANNresolutions_test\",test_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=next(iter(train_loader))\n",
    "print(image[0][0][0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loader,test_loader,unique=genData(0,4)\n",
    "    model,history=run(train_loader,0,4)\n",
    "    print(calc(model,test_loader))\n",
    "    print(calc(model,train_loader))\n",
    "except MemoryError as e:\n",
    "    try:\n",
    "        del train_loader\n",
    "        del test_loader\n",
    "        del model\n",
    "    except: \n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3d \n",
    "try:\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loader,test_loader,unique=gen3DData(0,4)\n",
    "    model,history=run3D(train_loader,0,4)\n",
    "    print(calc(model,test_loader))\n",
    "    print(calc(model,train_loader))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    del train_loader\n",
    "    del test_loader\n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)\n",
    "plt.show()\n",
    "np.save(\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/NewRigExperiments/data/ubermodellstmcnn.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=None\n",
    "real=None\n",
    "keys=['Carpet', 'LacedMatt', 'wool', 'Cork', 'Felt', 'LongCarpet', 'Cotton', 'Plastic', 'Flat', 'Ffoam', 'Gfoam', 'bubble', 'Efoam', 'Jeans', 'Leather']\n",
    "for i, (inputs, labels) in enumerate(test_loader):\n",
    "    outputs = model(inputs)\n",
    "    a=torch.argmax(outputs.detach(),axis=1)\n",
    "    if type(preds)==type(None):\n",
    "        preds=a.numpy().copy()\n",
    "        real=np.argmax(labels.numpy().copy(),axis=1)\n",
    "    else:\n",
    "        preds=np.concatenate([preds,a.numpy().copy()])\n",
    "        real=np.concatenate([real,np.argmax(labels.numpy().copy(),axis=1)])\n",
    "\n",
    "\n",
    "def compute_confusion_matrix(true_labels, pred_labels, num_classes):\n",
    "    matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    un=np.unique(real)\n",
    "    for t, p in zip(true_labels, pred_labels):\n",
    "        matrix[t, p] += 1\n",
    "    return matrix/len(true_labels)\n",
    "\n",
    "print(real.shape,preds.shape)\n",
    "# Combine all predictions\n",
    "predictions = [preds]\n",
    "model_names = ['Neural Network']\n",
    "num_classes = len(np.unique(real))\n",
    "un=np.unique(real)\n",
    "indices = np.arange(num_classes)\n",
    "# Plotting confusion matrices for each model\n",
    "fig, axes = plt.subplots(1, len(predictions), figsize=(6, 6))\n",
    "\n",
    "for i, preds in enumerate(predictions):\n",
    "    cm = compute_confusion_matrix(real, preds, num_classes=len(np.unique(real)))\n",
    "    \n",
    "    ax = axes[i] if len(predictions) > 1 else axes\n",
    "    cax = ax.matshow(cm, cmap='Blues')\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "    \n",
    "    for (j, k), value in np.ndenumerate(cm):\n",
    "        ax.text(k, j, f'{round(value*100) if round(value*100,1) == 0.0 else round(value*100,1)}', ha='center', va='center', color='red')\n",
    "    ax.set_title(f'Confusion Matrix for {model_names[i]}',fontsize=14)\n",
    "    ax.set_xlabel('Predicted Labels',fontsize=14)\n",
    "    ax.set_xticks(indices)\n",
    "    ax.set_xticklabels([keys[unique[j]] for j in range(num_classes)],rotation=90,fontsize=14)\n",
    "    ax.set_ylabel('True Labels',fontsize=12)\n",
    "    ax.set_yticks(indices)\n",
    "    ax.set_yticklabels([keys[unique[j]] for j in range(num_classes)],rotation=0,fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+\"/images/NM_confusionCNN.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"C:/Users/dexte/Documents/GitHub/RoboSkin/Code/NewRigExperiments/model/mymodel\") #\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/NewRigExperiments/model/mymodel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN(abs(0-4)*110,120,15).to(device)\n",
    "model.load_state_dict(torch.load(path+\"/model/uber_model\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform on unseen pressures\n",
    "\n",
    "#load in numpy\n",
    "data=np.load(datapath+\"datasets/X_texture_pout.npz\")\n",
    "for array_name in data:\n",
    "    x_unseen=(data[array_name].astype(np.uint8))\n",
    "data=np.load(datapath+\"datasets/y_texture_pout.npz\")\n",
    "for array_name in data:\n",
    "    y_unseen=(data[array_name].astype(np.uint8))\n",
    "print(x_unseen.shape)\n",
    "#cut temporal size\n",
    "x_unseen=x_unseen[:,0:4]\n",
    "X=np.zeros_like(x_unseen)\n",
    "#apply sobel filter\n",
    "for i in range(len(x_unseen)): #crop all images individually\n",
    "    for j in range(len(x_unseen[0])):\n",
    "        image=x_unseen[i][j]\n",
    "        # Apply Sobel filter in x-direction\n",
    "        sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)  # ksize=3 for a 3x3 Sobel kernel\n",
    "\n",
    "        # Apply Sobel filter in y-direction\n",
    "        sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "        # Convert the results back to uint8\n",
    "        sobel_x = np.uint8(np.absolute(sobel_x))\n",
    "        sobel_y = np.uint8(np.absolute(sobel_y))\n",
    "\n",
    "        # Combine the results to get the final edge-detected image\n",
    "        sobel_combined = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "        X[i][j]=sobel_combined\n",
    "unique_=[\"Flat\",\"wool\",\"Efoam\",\"LongCarpet\",\"LacedMatt\",\"cotton\",\"Gfoam\",\"Carpet\",\"felt\",\"Ffoam\",\"bubble\",\"Cork\",\"Jeans\"]\n",
    "keys={'Cork': 38, 'wool': 19, 'LacedMatt': 28, 'Gfoam': 30, 'Carpet': 31, 'bubble': 37, 'Efoam': 21, 'cotton': 29, 'LongCarpet': 25, 'Flat': 16, 'felt': 34, 'Jeans': 39, 'Ffoam': 36}\n",
    "        \n",
    "unique_={i:keys[unique_[i]] for i in range(len(unique_))}\n",
    "\n",
    "#concat\n",
    "X=X.reshape((4,len(X)//4,1,abs(0-4)*110,120))\n",
    "X=torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y=y_unseen.reshape(4,len(y_unseen)//4)\n",
    "print(X.shape,unique_)\n",
    "#run through model\n",
    "predsA=torch.argmax(model(X[0]),axis=1).detach().numpy()\n",
    "predsB=torch.argmax(model(X[1]),axis=1).detach().numpy()\n",
    "predsC=torch.argmax(model(X[2]),axis=1).detach().numpy()\n",
    "predsD=torch.argmax(model(X[3]),axis=1).detach().numpy()\n",
    "data=np.array([predsA,predsB,predsC,predsD])\n",
    "for i,batch in enumerate(data):\n",
    "    for key in np.unique(batch):\n",
    "        batch[batch==key]=unique_[key]\n",
    "data=data.reshape((len(x_unseen)))\n",
    "y=y.reshape((len(x_unseen)))\n",
    "\n",
    "#show accuracy (maybe confusion matrix of sorts)\n",
    "correct=0\n",
    "summed=0.1\n",
    "a=data==y\n",
    "summed+=len(x_unseen)\n",
    "correct+=len(a[a==1])\n",
    "print(\"Accuracy:\",(correct/summed)*100,\"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUm of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader,test_loader=genData(0,4)\n",
    "#model,history=run(train_loader,0,4,num_epochs = 100)\n",
    "train_loader,test_loader=genLSTMData(0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_loaders_by_classes(train_loader, test_loader, n):\n",
    "    # Get the class labels from the train_loader (assuming the label is in the second position of each batch)\n",
    "    train_classes = []  # Use a set to automatically handle uniqueness\n",
    "    for data, labels in train_loader:\n",
    "        # Flatten the labels and update the set with unique labels\n",
    "        l=np.argmax(labels.cpu().numpy().astype(np.uint8),axis=1)\n",
    "        train_classes.extend(l)  # Flatten to 1D and convert to numpy array\n",
    "    train_classes=np.array(train_classes).flatten()\n",
    "    train_classes = train_classes.tolist()  # Convert the set back to a list\n",
    "    \n",
    "    # Randomly select 'n' classes\n",
    "    selected_classes = random.sample(train_classes, n)\n",
    "    # Function to filter a loader by selected classes\n",
    "    def filter_loader(loader, selected_classes):\n",
    "        filtered_data = []\n",
    "        filtered_labels = []\n",
    "\n",
    "        for data, labels in loader:\n",
    "            batch_size = data.size(0)  # Get the batch size\n",
    "            # Iterate through the batch and check if any label in the sample matches the selected classes\n",
    "            for i in range(batch_size):\n",
    "                sample_labels = torch.argmax(labels[i])  # Labels for the i-th sample in the batch\n",
    "                if sample_labels.cpu().item() in selected_classes:\n",
    "                    filtered_data.append(data[i])  # Append the corresponding data sample\n",
    "                    filtered_labels.append(labels[i])  # Append the corresponding labels\n",
    "\n",
    "        # Convert lists back to tensors\n",
    "        filtered_data = torch.stack(filtered_data) if filtered_data else torch.Tensor()\n",
    "        filtered_labels = torch.stack(filtered_labels) if filtered_labels else torch.Tensor()\n",
    "        # Return a new DataLoader with the filtered data\n",
    "        return torch.utils.data.DataLoader(\n",
    "            torch.utils.data.TensorDataset(filtered_data, filtered_labels),\n",
    "            batch_size=loader.batch_size\n",
    "        )\n",
    "\n",
    "    # Create the new filtered train and test loaders\n",
    "    filtered_train_loader = filter_loader(train_loader, selected_classes)\n",
    "    filtered_test_loader = filter_loader(test_loader, selected_classes)\n",
    "\n",
    "    return filtered_train_loader, filtered_test_loader\n",
    "\n",
    "test_acc=np.zeros((15,5))\n",
    "train_acc=np.zeros((15,5))\n",
    "\n",
    "for i in range(2,15):\n",
    "    for j in range(5):\n",
    "        print(\"Size\",i,\"trial\",j)\n",
    "        tl,tl2=filter_loaders_by_classes(train_loader, test_loader, i)\n",
    "        model,history=runLSTM(tl,0,4,num_epochs = 100)\n",
    "        test_acc[i][j]=calc(model,tl2)\n",
    "        train_acc[i][j]=calc(model,tl)\n",
    "\n",
    "np.save(path+\"/data/test_acc_varying_dataset_size_optical_lstm\",test_acc)\n",
    "np.save(path+\"/data/train_acc_varying_dataset_size_optical_lstm\",train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot code for above\n",
    "train_tactip_cnn=np.average(np.load(path+\"/data/train_acc_varying_dataset_size_optical_cnn.npy\"),axis=1)[2:]*100\n",
    "test_tactip_cnn=np.average(np.load(path+\"/data/test_acc_varying_dataset_size_optical_cnn.npy\"),axis=1)[2:]*100\n",
    "train_press_cnn=np.average(np.load(path+\"/data/train_acc_varying_dataset_size_electricalALL_lstm.npy\"),axis=1)[2:]\n",
    "test_press_cnn=np.average(np.load(path+\"/data/test_acc_varying_dataset_size_electricalALL_lstm.npy\"),axis=1)[2:]\n",
    "train_tactip_lstm=np.average(np.load(path+\"/data/train_acc_varying_dataset_size_optical_lstm.npy\"),axis=1)[2:]*100\n",
    "test_tactip_lstm=np.average(np.load(path+\"/data/test_acc_varying_dataset_size_optical_lstm.npy\"),axis=1)[2:]*100\n",
    "\n",
    "plt.plot(train_tactip_cnn,c=\"g\",label=\"Train CNN TacTip\")\n",
    "plt.plot(test_tactip_cnn,\"--\",c=\"g\",label=\"Test CNN TacTip\")\n",
    "\n",
    "plt.plot(train_press_cnn,c=\"r\",label=\"Train LSTM Electrical\")\n",
    "plt.plot(test_press_cnn,\"--\",c=\"r\",label=\"test LSTM Electrical\")\n",
    "\n",
    "plt.plot(train_tactip_lstm,c=\"b\",label=\"Train LSTM TacTip\")\n",
    "plt.plot(test_tactip_lstm,\"--\",c=\"b\",label=\"test LSTM TacTip\")\n",
    "\n",
    "plt.xticks([i for i in range(len(train_tactip_cnn))],[i for i in range(2,14)])\n",
    "plt.grid(1)\n",
    "plt.title(\"How dataset size influences classifier performance\")\n",
    "plt.xlabel(\"Number of Classes\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+\"/images/datasetsize.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.load(path+\"saves/test_scores.npy\")\n",
    "train=np.load(path+\"saves/train_scores.npy\")\n",
    "\n",
    "test=np.max(test,axis=2)*100\n",
    "\"\"\"test=(test-np.min(test))/(np.max(test)-np.min(test))\n",
    "test*=255\"\"\"\n",
    "test[test==0]=80\n",
    "plt.imshow(test,cmap=\"plasma\")\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(test.shape[0]):\n",
    "    for j in range(test.shape[1]):\n",
    "        num=int(test[i, j])\n",
    "        if num==80: num=\"na\"\n",
    "        plt.text(j, i, num, ha='center', va='center', color='white')\n",
    "\n",
    "plt.title(\"Averaged accuracy of CNN models on testing data\")\n",
    "plt.xlabel(\"Window end position\")\n",
    "plt.ylabel(\"Window start position\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "train=np.max(train,axis=2)*100\n",
    "train[train==0]=80\n",
    "plt.imshow(train,cmap=\"plasma\")\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(train.shape[0]):\n",
    "    for j in range(train.shape[1]):\n",
    "        num=int(train[i, j])\n",
    "        if num==80: num=\"na\"\n",
    "        plt.text(j, i, num, ha='center', va='center', color='white')\n",
    "plt.title(\"Averaged accuracy of CNN models on training data\")\n",
    "plt.xlabel(\"Window end position\")\n",
    "plt.ylabel(\"Window start position\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=loaded(4,filename=\"X_data_newMorph.npz\")\n",
    "data.applySobel()\n",
    "sample_of_data=data.X[0:10]\n",
    "\n",
    "model = SimpleCNN(abs(4)*data.X.shape[2],data.X.shape[3],output=15).to(device)\n",
    "model.load_state_dict(torch.load(path+\"/model/mymodel\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "x_data=data.X[0:4].reshape((len(data.X[0:4]),1,abs(4)*data.X.shape[2],data.X.shape[3]))\n",
    "x_data=(x_data-np.mean(x_data))/(np.max(x_data)-np.min(x_data))\n",
    "train_images_tensor = torch.tensor(x_data, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#forward pass\n",
    "x = model.pool(model.relu(model.conv1(train_images_tensor)))#.cpu().detach().numpy()\n",
    "x = model.pool(model.relu(model.conv2(x))).cpu().detach().numpy()\n",
    "print(x[0][0].shape)\n",
    "fig, axes = plt.subplots(1, 10, figsize=(15, 5))\n",
    "axes = axes.flatten()\n",
    "axes[0].imshow(train_images_tensor[0][0].cpu().detach().numpy(),cmap=\"gray\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].set_title(\"Original image\",fontsize=11)\n",
    "for i in range(1,10):\n",
    "    axes[i].imshow(x[2][i],cmap=\"gray\")\n",
    "    axes[i].axis(\"off\")\n",
    "    axes[i].set_title(\"Feature depth \"+str(i+1),fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+\"images/featuresALL_uberModel.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "data=loaded(t=4)\n",
    "data.applySobel()\n",
    "data.augment()\n",
    "\n",
    "# Reduce dimensionality with PCA\n",
    "pca = PCA(n_components=833)\n",
    "x_data=data.X[0:].reshape((len(data.X[0:]),1,abs(4)*data.X.shape[2],data.X.shape[3]))\n",
    "labels=data.y[0:]\n",
    "print(x_data.reshape(len(x_data), -1).shape)\n",
    "pca_features = pca.fit_transform(x_data.reshape(len(x_data), -1))\n",
    "\n",
    "# Further reduce dimensionality with t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_features = tsne.fit_transform(pca_features)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=labels, cmap='tab20')\n",
    "plt.colorbar()\n",
    "plt.title('t-SNE Visualization of Optical Tactile Sensor Images')\n",
    "plt.savefig(path+\"/images/clusters.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/its/home/drs25/Documents/GitHub/RoboSkin/Code/Models/TacTip reader/pickle_imputer_sobel.pkl','rb') as file:\n",
    "    reg=pickle.load(file)\n",
    "data=loaded(t=4)\n",
    "data.applySobel()\n",
    "def predict(reg,dat):\n",
    "    dat=dat.flatten()\n",
    "    p=reg.predict([dat])\n",
    "    p=p.reshape((p.shape[0],p.shape[1]//2,2))\n",
    "    return p\n",
    "sample=data.X[0:750]\n",
    "print(sample.shape)\n",
    "X_prime=np.zeros((len(sample),sample.shape[1],260,270),dtype=np.uint8)\n",
    "coords=np.zeros((len(sample),sample.shape[1],133,2))\n",
    "for i in range(len(sample)): #create data aas linear images\n",
    "    for j in range(len(sample[0])):\n",
    "        X_prime[i][j]=cv2.resize(sample[i][j],(270,260),interpolation=cv2.INTER_AREA)+140\n",
    "        coords[i][j]=predict(reg,X_prime[i][j])[0]\n",
    "X_alt=X_prime\n",
    "X_alt[X_alt>255]=255\n",
    "print(sample.shape,X_alt.shape)\n",
    "plt.imshow(X_alt[0][0],cmap=\"gray\")\n",
    "pred=predict(reg,X_alt[0][0])[0]\n",
    "plt.scatter(pred[:,0],pred[:,1])\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/NewRigExperiments/images/transfertogel.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/its/home/drs25/Documents/GitHub/RoboSkin/Code/Models/TacTip reader/pickle_imputer_sobel.pkl','rb') as file:\n",
    "    reg=pickle.load(file)\n",
    "data=loaded(t=5)\n",
    "data.applySobel()\n",
    "def predict(reg,dat):\n",
    "    dat=dat.flatten()\n",
    "    p=reg.predict([dat])\n",
    "    p=p.reshape((p.shape[0],p.shape[1]//2,2))\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=data.X\n",
    "print(sample.shape)\n",
    "X_prime=np.zeros((len(sample),sample.shape[1],260,270),dtype=np.uint8)\n",
    "coords=np.zeros((len(sample),sample.shape[1],133,2))\n",
    "for i in range(len(sample)): #create data aas linear images\n",
    "    for j in range(len(sample[0])):\n",
    "        X_prime[i][j]=cv2.resize(sample[i][j],(270,260),interpolation=cv2.INTER_AREA)#+10\n",
    "        coords[i][j]=predict(reg,X_prime[i][j])[0]\n",
    "X_alt=X_prime\n",
    "X_alt[X_alt>255]=255\n",
    "print(sample.shape,X_alt.shape)\n",
    "plt.imshow(X_alt[0][0],cmap=\"gray\")\n",
    "pred=predict(reg,X_alt[0][0])[0]\n",
    "plt.scatter(pred[:,0],pred[:,1])\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/NewRigExperiments/images/transfertogel.pdf\")\n",
    "plt.show()\n",
    "del sample\n",
    "del X_prime\n",
    "del X_alt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer1_size, hidden_layer2_size, output_size):\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        \n",
    "        # Define the first fully connected layer\n",
    "        self.fc1 = nn.Linear(input_size, hidden_layer1_size)\n",
    "        \n",
    "        # Define the second fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_layer1_size, hidden_layer2_size)\n",
    "\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_layer2_size, 50)\n",
    "        \n",
    "        # Define the output fully connected layer\n",
    "        self.fc4 = nn.Linear(50, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply the first fully connected layer followed by ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Apply the second fully connected layer followed by ReLU activation\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        # Apply the output fully connected layer\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.round(coords.reshape((len(coords),-1)))\n",
    "X=(X-np.min(X))/(np.max(X)-np.min(X))\n",
    "un=np.unique(data.y)\n",
    "# Number of classes\n",
    "num_classes = np.max(data.y) + 1\n",
    "# One-hot encoding\n",
    "one_hot_encoded = np.eye(num_classes)[data.y]\n",
    "y=one_hot_encoded\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "input_size = len(X[0])       # Number of input features\n",
    "hidden_layer1_size = len(X[0]) //2  # Number of neurons in the first hidden layer\n",
    "hidden_layer2_size = 800  # Number of neurons in the second hidden layer\n",
    "output_size = len(un)     # Number of output features\n",
    "\n",
    "# Create the neural network\n",
    "model = SimpleNeuralNetwork(input_size, hidden_layer1_size, hidden_layer2_size, output_size).to(device)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "print(X.shape,y.shape,X.dtype,y.dtype)\n",
    "# Create a TensorDataset and DataLoader\n",
    "#dataset = TensorDataset(torch.Tensor(train_X).to(device), torch.Tensor(train_y).to(device))\n",
    "#dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "train_X_=torch.Tensor(train_X).to(device)\n",
    "train_y_=torch.Tensor(train_y).to(device)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Assuming a classification problem\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #for inputs, labels in dataloader:\n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(train_X_)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = criterion(outputs, train_y_)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Optimize\n",
    "    optimizer.step()\n",
    "    if epoch%100==0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=torch.Tensor(test_X).to(device)\n",
    "outputs = model(inputs)\n",
    "outputs=outputs.cpu().detach().numpy()\n",
    "print(test_y.shape,outputs.shape)\n",
    "correct=np.argmax(test_y,axis=1)==np.argmax(outputs,axis=1)\n",
    "print(np.sum(correct)/len(correct) *100,\"%\")\n",
    "inputs=torch.Tensor(train_X).to(device)\n",
    "outputs = model(inputs)\n",
    "outputs=outputs.cpu().detach().numpy()\n",
    "print(test_y.shape,outputs.shape)\n",
    "correct=np.argmax(train_y,axis=1)==np.argmax(outputs,axis=1)\n",
    "print(np.sum(correct)/len(correct) *100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords.reshape((len(coords),-1)).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "class SimpleLSTMDrop(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.2):\n",
    "        super(SimpleLSTMDrop, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.round(coords.reshape((len(coords),5,-1)))\n",
    "X=(X-np.min(X))/(np.max(X)-np.min(X))\n",
    "un=np.unique(data.y)\n",
    "# Number of classes\n",
    "num_classes = np.max(data.y) + 1\n",
    "# One-hot encoding\n",
    "one_hot_encoded = np.eye(num_classes)[data.y]\n",
    "y=one_hot_encoded\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "input_size = len(X[0][0])       # Number of input features\n",
    "output_size = len(un)     # Number of output features\n",
    "print(X.shape,y.shape,X.dtype,train_X.shape)\n",
    "\n",
    "train_X_=torch.Tensor(train_X)\n",
    "train_y_=torch.Tensor(train_y)\n",
    "\n",
    "# Model, loss function, optimizer\n",
    "model = SimpleLSTM(input_size, 100, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(train_X_)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = criterion(outputs, train_y_)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=torch.Tensor(test_X)\n",
    "outputs = model(inputs)\n",
    "outputs=outputs.cpu().detach().numpy()\n",
    "print(test_y.shape,outputs.shape)\n",
    "correct=np.argmax(test_y,axis=1)==np.argmax(outputs,axis=1)\n",
    "print(np.sum(correct)/len(correct) *100,\"%\")\n",
    "inputs=torch.Tensor(train_X)\n",
    "outputs = model(inputs)\n",
    "outputs=outputs.cpu().detach().numpy()\n",
    "print(test_y.shape,outputs.shape)\n",
    "correct=np.argmax(train_y,axis=1)==np.argmax(outputs,axis=1)\n",
    "print(np.sum(correct)/len(correct) *100,\"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotchange(average):\n",
    "    magnitudes=[]\n",
    "    for t in range(len(average)-1):\n",
    "        magnitudes.append(euclidean_distance(average[t],average[t+1]))\n",
    "    ar=np.array(magnitudes).T\n",
    "    return ar#(ar-np.min(ar))/(np.max(ar)-np.min(ar))\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    # Convert points to numpy arrays\n",
    "    point1 = np.array(point1)\n",
    "    point2 = np.array(point2)\n",
    "    \n",
    "    # Calculate the distance\n",
    "    distance = np.linalg.norm(point1 - point2,axis=1)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "#create dataset\n",
    "d1=coords[:,:-1,:]\n",
    "d2=coords[:,1:,:]\n",
    "distances=np.linalg.norm(d1 - d2,axis=3)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = distances\n",
    "X=(X-np.min(X))/(np.max(X)-np.min(X))\n",
    "un=np.unique(data.y)\n",
    "# Number of classes\n",
    "num_classes = np.max(data.y) + 1\n",
    "# One-hot encoding\n",
    "one_hot_encoded = np.eye(num_classes)[data.y]\n",
    "y=one_hot_encoded\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "input_size = len(X[0][0])       # Number of input features\n",
    "output_size = len(un)     # Number of output features\n",
    "print(X.shape,y.shape,X.dtype,train_X.shape)\n",
    "\n",
    "train_X_=torch.Tensor(train_X)\n",
    "train_y_=torch.Tensor(train_y)\n",
    "\n",
    "# Model, loss function, optimizer\n",
    "model = SimpleLSTM(input_size, 300, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(train_X_)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = criterion(outputs, train_y_)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=torch.Tensor(test_X)\n",
    "outputs = model(inputs)\n",
    "outputs=outputs.cpu().detach().numpy()\n",
    "print(test_y.shape,outputs.shape)\n",
    "correct=np.argmax(test_y,axis=1)==np.argmax(outputs,axis=1)\n",
    "print(np.sum(correct)/len(correct) *100,\"%\")\n",
    "inputs=torch.Tensor(train_X)\n",
    "outputs = model(inputs)\n",
    "outputs=outputs.cpu().detach().numpy()\n",
    "print(test_y.shape,outputs.shape)\n",
    "correct=np.argmax(train_y,axis=1)==np.argmax(outputs,axis=1)\n",
    "print(np.sum(correct)/len(correct) *100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = distances\n",
    "X=(X-np.min(X))/(np.max(X)-np.min(X))\n",
    "un=np.unique(data.y)\n",
    "# Number of classes\n",
    "num_classes = np.max(data.y) + 1\n",
    "# One-hot encoding\n",
    "one_hot_encoded = np.eye(num_classes)[data.y]\n",
    "y=one_hot_encoded\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "input_size = len(X[0][0])       # Number of input features\n",
    "output_size = len(un)     # Number of output features\n",
    "print(X.shape,y.shape,X.dtype,train_X.shape)\n",
    "\n",
    "train_X_=torch.Tensor(train_X)\n",
    "train_y_=torch.Tensor(train_y)\n",
    "\n",
    "# Model, loss function, optimizer\n",
    "model = SimpleLSTMDrop(input_size, 300, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 600\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(train_X_)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = criterion(outputs, train_y_)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "inputs=torch.Tensor(test_X)\n",
    "outputs = model(inputs)\n",
    "outputs=outputs.cpu().detach().numpy()\n",
    "print(test_y.shape,outputs.shape)\n",
    "correct=np.argmax(test_y,axis=1)==np.argmax(outputs,axis=1)\n",
    "print(np.sum(correct)/len(correct) *100,\"%\")\n",
    "inputs=torch.Tensor(train_X)\n",
    "outputs = model(inputs)\n",
    "outputs=outputs.cpu().detach().numpy()\n",
    "print(test_y.shape,outputs.shape)\n",
    "correct=np.argmax(train_y,axis=1)==np.argmax(outputs,axis=1)\n",
    "print(np.sum(correct)/len(correct) *100,\"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = distances.reshape((len(distances),-1))\n",
    "X=(X-np.min(X))/(np.max(X)-np.min(X))\n",
    "un=np.unique(data.y)\n",
    "# Number of classes\n",
    "num_classes = np.max(data.y) + 1\n",
    "# One-hot encoding\n",
    "one_hot_encoded = np.eye(num_classes)[data.y]\n",
    "y=one_hot_encoded\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "input_size = len(X[0])       # Number of input features\n",
    "output_size = len(un)     # Number of output features\n",
    "print(X.shape,y.shape,X.dtype,train_X.shape)\n",
    "\n",
    "train_X_=torch.Tensor(train_X).to(device)\n",
    "train_y_=torch.Tensor(train_y).to(device)\n",
    "\n",
    "# Create the neural network\n",
    "model = SimpleNeuralNetwork(input_size, hidden_layer1_size, hidden_layer2_size, output_size).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Assuming a classification problem\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #for inputs, labels in dataloader:\n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(train_X_)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = criterion(outputs, train_y_)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Optimize\n",
    "    optimizer.step()\n",
    "    if epoch%100==0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=torch.Tensor(test_X).to(device)\n",
    "outputs = model(inputs)\n",
    "outputs=outputs.cpu().detach().numpy()\n",
    "print(test_y.shape,outputs.shape)\n",
    "correct=np.argmax(test_y,axis=1)==np.argmax(outputs,axis=1)\n",
    "print(np.sum(correct)/len(correct) *100,\"%\")\n",
    "inputs=torch.Tensor(train_X).to(device)\n",
    "outputs = model(inputs)\n",
    "outputs=outputs.cpu().detach().numpy()\n",
    "print(test_y.shape,outputs.shape)\n",
    "correct=np.argmax(train_y,axis=1)==np.argmax(outputs,axis=1)\n",
    "print(np.sum(correct)/len(correct) *100,\"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.round(distances.reshape((len(distances),1,4,-1)))\n",
    "X=(X-np.min(X))/(np.max(X)-np.min(X))\n",
    "un=np.unique(data.y)\n",
    "# Number of classes\n",
    "num_classes = np.max(data.y) + 1\n",
    "# One-hot encoding\n",
    "one_hot_encoded = np.eye(num_classes)[data.y]\n",
    "y=one_hot_encoded\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "input_size = len(X[0][0])       # Number of input features\n",
    "output_size = len(un)     # Number of output features\n",
    "print(X.shape,y.shape,X.dtype,train_X.shape)\n",
    "\n",
    "train_X_=torch.Tensor(train_X)\n",
    "train_y_=torch.Tensor(train_y)\n",
    "\n",
    "# Model, loss function, optimizer\n",
    "model = SimpleCNN(len(distances[0]),len(distances[0][0]))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(train_X_)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = criterion(outputs, train_y_)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=torch.Tensor(test_X)#.to(device)\n",
    "outputs = model(inputs)\n",
    "outputs=outputs.cpu().detach().numpy()\n",
    "print(test_y.shape,outputs.shape)\n",
    "correct=np.argmax(test_y,axis=1)==np.argmax(outputs,axis=1)\n",
    "print(np.sum(correct)/len(correct) *100,\"%\")\n",
    "inputs=torch.Tensor(train_X)#.to(device)\n",
    "outputs = model(inputs)\n",
    "outputs=outputs.cpu().detach().numpy()\n",
    "print(test_y.shape,outputs.shape)\n",
    "correct=np.argmax(train_y,axis=1)==np.argmax(outputs,axis=1)\n",
    "print(np.sum(correct)/len(correct) *100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path+\"/data/distances\",distances)\n",
    "np.save(path+\"/data/distancesy\",data.y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferability of normal model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,test_loader,unique=genData(0,4)\n",
    "model,history=run(train_loader,0,4)\n",
    "torch.save(model.state_dict(), path+\"/model/mymodelgel\") #\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/NewRigExperiments/model/mymodelgel\")\n",
    "data=loaded(4)\n",
    "image=data.X[0][0]\n",
    "modelA = SimpleCNN(4*image.shape[0],image.shape[1]).to(device)\n",
    "modelA.load_state_dict(torch.load(path+\"/model/mymodelgel\"))\n",
    "modelA.eval()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelA = SimpleCNN(4*image.shape[0],image.shape[1]).to(device)\n",
    "modelA.load_state_dict(torch.load(path+\"/model/mymodelgel\"))\n",
    "modelA.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc(model,test_loader))\n",
    "print(calc(model,train_loader))\n",
    "\n",
    "import pickle\n",
    "with open('/its/home/drs25/Documents/GitHub/RoboSkin/Code/Models/TacTip reader/pickle_imputer_sobel.pkl','rb') as file:\n",
    "    reg=pickle.load(file)\n",
    "data=loaded(t=4)\n",
    "data.applySobel()\n",
    "def predict(reg,dat):\n",
    "    dat=dat.flatten()\n",
    "    p=reg.predict([dat])\n",
    "    p=p.reshape((p.shape[0],p.shape[1]//2,2))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=data.X[0:300]\n",
    "X_prime=np.zeros((len(sample),sample.shape[1],*data.X[0][0].shape),dtype=np.uint8)\n",
    "coords=np.zeros((len(sample),sample.shape[1],133,2)).astype(np.uint16)\n",
    "divh=X_prime[0][0].shape[0]/270\n",
    "divw=X_prime[0][0].shape[1]/260\n",
    "print(divh,divw,X_prime[0][0].shape)\n",
    "for i in range(len(sample)): #create data aas linear images\n",
    "    for j in range(len(sample[0])):\n",
    "        temp=cv2.resize(sample[i][j],(270,260),interpolation=cv2.INTER_AREA)#+10\n",
    "        coords[i][j]=np.round(predict(reg,temp)[0])\n",
    "        #X_prime[i][j]*=0 \n",
    "        for point in zip(coords[i][j][:,0],coords[i][j][:,1]):\n",
    "            p1=int(point[0]*divh)\n",
    "            p2=int(point[1]*divw)\n",
    "            cv2.circle(X_prime[i][j],(p1,p2),1,(255),2)\n",
    "del sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_prime[0][0],cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(data.X[0][0],cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=(X_prime-np.mean(X_prime))/(np.max(X_prime)-np.min(X_prime))\n",
    "x=x.reshape((len(x),1,x.shape[1]*x.shape[2],x.shape[3]))\n",
    "print(x.shape)\n",
    "test=torch.tensor(x, dtype=torch.float32)\n",
    "print(test.dtype)\n",
    "label=data.y[0:300]\n",
    "preds=model(test)\n",
    "preds=torch.argmax(preds,axis=1).cpu().detach().numpy()\n",
    "a=np.abs(label-preds)\n",
    "print(len(a[a==0])/len(a) *100,\"%\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=loaded(4,filename=\"X_data_nomarker.npz\")\n",
    "data.applySobel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=data.X[0][0]\n",
    "model = SimpleCNN(4*image.shape[0],image.shape[1],output=15).to(device)\n",
    "model.load_state_dict(torch.load(path+\"/model/mymodelnomarker\"))\n",
    "model.eval()\n",
    "n=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at frquency \n",
    "def generate_saliency_maps(model, inputs, target_class):\n",
    "    model.eval()\n",
    "    inputs.requires_grad = True  # Ensure gradients can be computed for input\n",
    "\n",
    "    # Forward pass to get the predictions\n",
    "    outputs = model(inputs)  # outputs should be of shape (N, num_classes) if model outputs logits\n",
    "    score = outputs[:, target_class].sum()  # Sum over the batch for a single target class\n",
    "    \n",
    "    # Backward pass to calculate gradients\n",
    "    model.zero_grad()\n",
    "    score.backward()\n",
    "    \n",
    "    # Get the absolute value of the gradients as saliency map\n",
    "    saliency = inputs.grad.abs()  # Shape will be (N, t, w, h)\n",
    "\n",
    "    return saliency\n",
    "\n",
    "# Plotting Function\n",
    "def plot_saliency_map(saliency, original_frames, time_index):\n",
    "    \"\"\"Plot saliency map for a specific time index in the sequence\"\"\"\n",
    "    # Average over the batch if needed, to show a single example\n",
    "    saliency_frame = saliency[0, time_index].detach().cpu().numpy()  # Shape (w, h)\n",
    "    original_frame = original_frames[0, time_index].detach().cpu().numpy()\n",
    "    \n",
    "    # Normalize saliency map for visualization\n",
    "    saliency_frame = (saliency_frame - saliency_frame.min()) / (saliency_frame.max() - saliency_frame.min())\n",
    "    \n",
    "    # Plot the original frame with saliency map overlay\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 6))\n",
    "    ax[0].imshow(original_frame[0:110,:], cmap='gray')\n",
    "    ax[0].set_title(\"Original Frame\",fontsize=15,**csfont)\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(original_frame[0:110,:], cmap='gray')\n",
    "    ax[1].imshow(saliency_frame[0:110,:], cmap='hot', alpha=0.5)  # Overlay saliency map\n",
    "    ax[1].set_title(f\"Saliency Map - Frame {time_index}\",fontsize=15,**csfont)\n",
    "    ax[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path+\"/images/saliency_map.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "# Load a sample from your dataset\n",
    "shape=data.X[0].shape\n",
    "n=10\n",
    "sample_input = torch.tensor(data.X[0:n],dtype=torch.float32).reshape((len(data.X[0:n]),1,4*data.X.shape[2],data.X.shape[3]))  # Shape (1, t, w, h) - single sample for visualization\n",
    "\n",
    "print(sample_input.shape)\n",
    "# Generate saliency maps for the sample\n",
    "target_class = 0  # Replace with the class index of interest\n",
    "saliency_maps = generate_saliency_maps(model, sample_input, target_class)\n",
    "\n",
    "# Plot saliency for each frame in the temporal sequence\n",
    "for time_index in range(sample_input.shape[1]):  # Iterate over t frames\n",
    "    plot_saliency_map(saliency_maps, sample_input, time_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking out segments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=loaded(4,filename=\"X_data_15.npz\")\n",
    "data.applySobel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample=data.X[0:300].reshape((300,1,4*len(data.X[0][0]),len(data.X[0][0][0]))).copy()\n",
    "images=[sample[0][0].copy(),sample[0][0].copy(),sample[0][0].copy(),sample[0][0].copy(),sample[0][0].copy(),sample[0][0].copy(),sample[0][0].copy(),sample[0][0].copy()]\n",
    "images[0][0:-1,50:75]=0\n",
    "images[1][0:-1,20:45]=0\n",
    "images[2][0:-1,70:95]=0\n",
    "images[3][0:-1,60:70]=0\n",
    "images[4][0:110,0:120]=0\n",
    "images[5][0:220,0:120]=0\n",
    "images[6][0:330,0:120]=0\n",
    "images[7][110:330,0:120]=0\n",
    "label=[\"50:75\",\"20:45\",\"70:95\",\"60:70\",\"Segment removed\",\"Two removed\",\"Three removed\",\"Only first and last\"]\n",
    "label=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]\n",
    "sample[:,0:330,0:120]=0\n",
    "#sample=sample.reshape((300,4,len(data.X[0][0])*len(data.X[0][0][0]))).copy()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(images), figsize=(15,8))\n",
    "axes = axes.flatten()\n",
    "for i in range(len(images)):\n",
    "    axes[i].set_title(label[i],fontsize=30,**csfont)\n",
    "    axes[i].imshow(images[i])\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+\"/images/samplesCrops_.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=data.X[0:300].reshape((300,4*len(data.X[0][0]),len(data.X[0][0][0]))).copy()\n",
    "\"\"\"\n",
    "images[0][0:-1,50:75]=0\n",
    "images[1][0:-1,20:45]=0\n",
    "images[2][0:-1,70:95]=0\n",
    "images[3][0:-1,60:70]=0\n",
    "images[4][0:110,0:120]=0\n",
    "images[5][0:220,0:120]=0\n",
    "images[6][0:330,0:120]=0\n",
    "images[7][110:330,0:120]=0\n",
    "\"\"\"\n",
    "sample[:,110:330,0:120]=0\n",
    "#sample=sample.reshape((300,4,len(data.X[0][0])*len(data.X[0][0][0]))).copy() # lstm\n",
    "sample=sample.reshape((300,1,4*len(data.X[0][0]),len(data.X[0][0][0]))).copy()\n",
    "\n",
    "image=sample[0][0]\n",
    "print(image.shape)\n",
    "#model=SimpleCNN(data.X.shape[2]*4,data.X.shape[3],15).to(device)#.half()\n",
    "\"\"\"model=SimpleLSTM(image.shape[1],1000,15).to(device)\n",
    "model.load_state_dict(torch.load(path+\"/model/mymodel_lstm\"))\n",
    "model.eval()\"\"\"\n",
    "model = SimpleCNN(image.shape[0],image.shape[1],output=15).to(device)\n",
    "model.load_state_dict(torch.load(path+\"/model/mymodel_newMorph\"))\n",
    "model.eval()\n",
    "x=(sample-np.mean(sample))/(np.max(sample)-np.min(sample))\n",
    "#x=x.reshape((len(x),4,x.shape[2]//4*x.shape[3]))\n",
    "\n",
    "print(x.shape)\n",
    "test=torch.tensor(x, dtype=torch.float32).to(device)\n",
    "print(test.dtype)\n",
    "label=data.y[0:300]\n",
    "preds=model(test)\n",
    "preds=torch.argmax(preds,axis=1).cpu().detach().numpy()\n",
    "a=np.abs(label-preds)\n",
    "print(len(a[a==0])/len(a) *100,\"%\")\n",
    "plt.imshow(image.reshape((4*len(data.X[0][0]),len(data.X[0][0][0]))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixA=np.array([[56.3,98,99.3],[52,100,53.3],[72.3,100,70],[89.33,100,100],[98.6,100,95.6],[91.3,100,64.6],[83.3,97,47.3],[97,100,79.6]]) #cnn\n",
    "matrixB=np.array([[43.4,63,100],[19.3,92.6,12.3],[23.3,86,83.6],[88.6,90.3,100],[86,68.3,86.3],[72.6,45,56.9],[49,34,32.6],[68.6,61.6,60]])\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot matrixA in the top half with 'YlGn' colormap\n",
    "ax.imshow(matrixA.T, cmap='YlGn', aspect='auto', extent=[0, 8, 6, 3])\n",
    "\n",
    "# Plot matrixB in the bottom half with 'gray' colormap\n",
    "ax.imshow(matrixB.T, cmap='YlOrRd', aspect='auto', extent=[0, 8, 3, 0])\n",
    "\n",
    "# Set ticks\n",
    "ax.set_xticks(np.arange(8) + 0.5)\n",
    "ax.set_xticklabels([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"],fontsize=20,**csfont)\n",
    "ax.set_yticks(np.arange(6)+1)\n",
    "ax.set_yticklabels([\"  NM\", \"  S\", \"  0M\", \"  NM\", \"  S\", \"  0M\"], rotation=90, ha=\"left\", rotation_mode=\"anchor\",fontsize=20,**csfont)\n",
    "\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(matrixA.shape[0]):\n",
    "    for j in range(matrixA.shape[1]):\n",
    "        ax.text(i+0.5, j+0.5+3, f\"{matrixA[i, j]:.1f}%\", ha='center', va='center', color='white' if matrixA[i, j] > 70 else 'black',fontsize=18,**csfont)\n",
    "\n",
    "for i in range(matrixB.shape[0]):\n",
    "    for j in range(matrixB.shape[1]):\n",
    "        ax.text(i+0.5, j+0.5, f\"{matrixB[i, j]:.1f}%\", ha='center', va='center', color='white' if matrixB[i, j] > 90 else 'black',fontsize=18,**csfont)\n",
    "\n",
    "\n",
    "plt.title(\"Model results\",fontsize=20,**csfont)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+\"/images/LSTM_different_markers.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different pressures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,test_loader,unique=genData(0,4)\n",
    "model,history=run(train_loader,0,4)\n",
    "torch.save(model.state_dict(), path+\"/model/mymodel_withLowPressure\") #\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/NewRigExperiments/model/mymodelgel\")\n",
    "data=loaded(4)\n",
    "image=data.X[0][0]\n",
    "print(calc(model,test_loader))\n",
    "print(calc(model,train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=loaded(4,filename=\"X_data_15.npz\")\n",
    "image=data.X[0][0]\n",
    "#model = SimpleCNN(4*image.shape[0],image.shape[1],output=15).to(device)\n",
    "model=SimpleLSTM(image.shape[0]*image.shape[1],1000,15).to(device)#.half()\n",
    "model.load_state_dict(torch.load(path+\"/model/mymodel_lstm\"))\n",
    "model.eval()\n",
    "#print(calc(model,test_loader))\n",
    "#print(calc(model,train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "d=loaded(t=4,filename=\"X_flat_unseen_pressures.npz\")\n",
    "d.applySobel()\n",
    "sample=d.X\n",
    "label=d.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=d.X\n",
    "x=(sample-np.mean(sample))/(np.max(sample)-np.min(sample))\n",
    "x=x.reshape((len(x),x.shape[1],x.shape[2]*x.shape[3]))\n",
    "test=torch.tensor(x, dtype=torch.float32).to(device)\n",
    "preds=model(test)\n",
    "preds=torch.argmax(preds,axis=1).cpu().detach().numpy()\n",
    "a=preds[preds==11]\n",
    "print(len(a)/len(preds) *100,\"%\")\n",
    "del test\n",
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p20=d.X[np.where(d.y==3)]\n",
    "p30=d.X[np.where(d.y==0)]\n",
    "p40=d.X[np.where(d.y==2)]\n",
    "p50=d.X[np.where(d.y==1)]\n",
    "data=[p20,p30,p40,p50]\n",
    "accs=[]\n",
    "for i in range(4):\n",
    "    sample=data[i]\n",
    "    label=11\n",
    "    x=(sample-np.mean(sample))/(np.max(sample)-np.min(sample))\n",
    "    x=x.reshape((len(x),1,x.shape[1]*x.shape[2],x.shape[3]))  #n,1,t*h,w for cnn, n,t,h*w for lstm, n,1,t,h,w for cnn-lstm\n",
    "    test=torch.tensor(x, dtype=torch.float32).to(device)\n",
    "    preds=model(test)\n",
    "    preds=torch.argmax(preds,axis=1).cpu().detach().numpy()\n",
    "    a=len(preds[preds==label])\n",
    "    print(a/len(preds) *100,\"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models on other data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=loaded(4,filename=\"X_data_nomarker.npz\")\n",
    "image=data.X[0][0].copy()\n",
    "del data\n",
    "#model = SimpleCNN(4*image.shape[0],image.shape[1],output=15).to(device)\n",
    "#print(calc(model,test_loader))\n",
    "#print(calc(model,train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=SimpleCNN(4*image.shape[0],image.shape[1],output=15).to(device)\n",
    "#model=SimpleLSTM(image.shape[0]*image.shape[1],1000,15).to(device)\n",
    "model=CNN_LSTM(image.shape[1],image.shape[0],1000,1,15).to(device)\n",
    "model.load_state_dict(torch.load(path+\"/model/uber_lstmCNN\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "d=loaded(t=4,filename=\"X_data_nomarker.npz\") #X_data_gel_15.npz X_data_newMorph.npz X_data_15.npz\n",
    "d.applySobel()\n",
    "sample=d.X[0:800]\n",
    "label=d.y[0:800]\n",
    "del d\n",
    "x=(sample-np.mean(sample))/(np.max(sample)-np.min(sample))\n",
    "x=x.reshape((len(x),1,x.shape[1],x.shape[2],x.shape[3]))\n",
    "test=torch.tensor(x, dtype=torch.float32).to(device)\n",
    "preds=model(test)\n",
    "preds=torch.argmax(preds,axis=1).cpu().detach().numpy()\n",
    "a=preds-label\n",
    "print(len(a[a==0])/len(preds) *100,\"%\")\n",
    "del test\n",
    "del x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferring large models to small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=loaded(4,filename=\"X_data_15.npz\")\n",
    "image=data.X[0][0]\n",
    "data\n",
    "model = SimpleCNN(4*image.shape[0],image.shape[1],output=15).to(device)\n",
    "model.load_state_dict(torch.load(path+\"/model/uber_model\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=loaded(t=4,filename=\"X_data_15.npz\") #X_data_gel_15.npz X_data_newMorph.npz X_data_15.npz\n",
    "d.applySobel()\n",
    "d.resize(0.1)\n",
    "\n",
    "sample=d.X\n",
    "sampley=d.y\n",
    "image=sample[0][0]\n",
    "print(image.shape)\n",
    "#copy over correct convolutions\n",
    "modelB=SimpleCNN(image.shape[0]*d.X.shape[1],image.shape[1],15).to(device)\n",
    "modelB.conv1=model.conv1\n",
    "modelB.conv2=model.conv2\n",
    "#freeze conv layers\n",
    "modelB.conv1.requires_grad=False\n",
    "modelB.conv2.requires_grad=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(sampley)\n",
    "one_hot_labels = torch.nn.functional.one_hot(torch.tensor(train_labels_encoded), num_classes=len(np.unique(train_labels_encoded)))\n",
    "x=(sample-np.mean(sample))/(np.max(sample)-np.min(sample))\n",
    "x=x.reshape((len(x),1,x.shape[1]*x.shape[2],x.shape[3]))\n",
    "\n",
    "train_images_tensor = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "# Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader for training and testing sets\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=40, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=40,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train_history=[]\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(modelB.parameters(), lr=0.005)\n",
    "\n",
    "# Train the Model\n",
    "num_epochs=50\n",
    "clip_value = 5\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = modelB(inputs)\n",
    "        #print(inputs.shape,outputs.shape,labels.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(modelB.parameters(), clip_value)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "    train_history.append(loss.cpu().detach().numpy())\n",
    "    if epoch%10==0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss :.4f}')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc(modelB,test_loader))\n",
    "print(calc(modelB,train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GEL\n",
    "# 5%\n",
    "# train % 58.95 test 57.99 % \n",
    "\n",
    "#10%\n",
    "# train % 91.70 test 92.81 % \n",
    "\n",
    "#15%\n",
    "# train % 93.37 test 94.81\n",
    "\n",
    "#20%\n",
    "# train % 96.99 test 98.15\n",
    "\n",
    "#25%\n",
    "# train % 99.9 test 99.98 % \n",
    "\n",
    "#NEWMORPH\n",
    "# 5%\n",
    "# train % 74.32 test 75.37 % \n",
    "\n",
    "#10%\n",
    "# train % 89.17 test 89.02 % \n",
    "\n",
    "#15%\n",
    "# train % 82.92 test 84.98 %\n",
    "\n",
    "#20%\n",
    "# train % 96.87 test 95.75 %\n",
    "\n",
    "#25%\n",
    "# train % 90.1 test 88.25 % \n",
    "\n",
    "#SILICONE\n",
    "# 5%\n",
    "# train % - test - % \n",
    "\n",
    "#10%\n",
    "# train % - test - % \n",
    "\n",
    "#15%\n",
    "# train % 79 test 74 %\n",
    "\n",
    "#20%\n",
    "# train % 88 test 90 %\n",
    "\n",
    "#25%\n",
    "# train % - test - % "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## automate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automate the shit out of it\n",
    "def long(file,type1,num):\n",
    "    resolution=[0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.7,0.8]\n",
    "    acc_test=np.zeros((len(resolution),5))\n",
    "    acc_train=np.zeros((len(resolution),5))\n",
    "    num_epochs=80\n",
    "    history=np.zeros((len(resolution),5,num_epochs))\n",
    "\n",
    "    for i in range(len(resolution)):\n",
    "        d=loaded(t=4,filename=file) #X_data_gel_15.npz X_data_newMorph.npz X_data_15.npz\n",
    "        d.applySobel()\n",
    "        image=d.X[0][0]\n",
    "        model = SimpleCNN(4*image.shape[0],image.shape[1],output=15).to(device)\n",
    "        model.load_state_dict(torch.load(path+\"/model/mymodelgel\"))\n",
    "        model.eval()\n",
    "        d.resize(resolution[i])\n",
    "        \n",
    "        sample=d.X\n",
    "        sampley=d.y\n",
    "        image=sample[0][0]\n",
    "        print(image.shape)\n",
    "        \n",
    "        #copy over correct convolutions\n",
    "        modelB=SimpleCNN(image.shape[0]*d.X.shape[1],image.shape[1],num).to(device)\n",
    "        modelB.conv1=model.conv1\n",
    "        modelB.conv2=model.conv2\n",
    "        #freeze conv layers\n",
    "        modelB.conv1.requires_grad=False\n",
    "        modelB.conv2.requires_grad=False\n",
    "\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        train_labels_encoded = label_encoder.fit_transform(sampley)\n",
    "        one_hot_labels = torch.nn.functional.one_hot(torch.tensor(train_labels_encoded), num_classes=len(np.unique(train_labels_encoded)))\n",
    "        x=(sample-np.mean(sample))/(np.max(sample)-np.min(sample))\n",
    "        x=x.reshape((len(x),1,x.shape[1]*x.shape[2],x.shape[3]))\n",
    "\n",
    "        train_images_tensor = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "        train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "        # Create a TensorDataset\n",
    "        dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "        # Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        test_size = len(dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "        # Create DataLoader for training and testing sets\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=40, shuffle=True)\n",
    "        test_loader = DataLoader(dataset=test_dataset, batch_size=40,shuffle=False)\n",
    "        max_=0\n",
    "        for j in range(5):\n",
    "            clear_output(wait=True)\n",
    "            print(\"Resolution\",resolution[i],\"Trial\",j)\n",
    "            criterion = nn.CrossEntropyLoss().to(device)\n",
    "            optimizer = optim.SGD(modelB.parameters(), lr=0.005)\n",
    "\n",
    "            # Train the Model\n",
    "            \n",
    "            clip_value = 5\n",
    "            for epoch in range(num_epochs):\n",
    "                running_loss = 0.0\n",
    "                for k, (inputs, labels) in enumerate(train_loader):\n",
    "                    # Zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Forward pass\n",
    "                    outputs = modelB(inputs)\n",
    "                    #print(inputs.shape,outputs.shape,labels.shape)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass and optimize\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(modelB.parameters(), clip_value)\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Print statistics\n",
    "                    running_loss += loss.item()\n",
    "                history[i][j][epoch]=running_loss/(k+1) #save average loss per epoch\n",
    "            test=calc(modelB,test_loader)\n",
    "            train=calc(modelB,train_loader)\n",
    "            acc_train[i][j]=train\n",
    "            acc_test[i][j]=test\n",
    "            if test>max_:\n",
    "                max_=test\n",
    "                torch.save(modelB.state_dict(), path+\"/model/standard_c_gel/cnn_res\"+str(resolution[i])+\"_\"+str(type1))\n",
    "        del train_loader\n",
    "        del test_loader\n",
    "    \n",
    "    np.save(path+\"/data/train_uber_\"+type1+\"_long_standard_c\",acc_train)\n",
    "    np.save(path+\"/data/test_uber_\"+type1+\"_long_standard_c\",acc_test)\n",
    "    np.save(path+\"/data/histroy_\"+type1+\"_long_standard_c\",history)\n",
    "\n",
    "#X_data_gel_15.npz X_data_newMorph.npz X_data_15.npz\n",
    "long(\"X_data_gel_15.npz\",\"gel\",15)\n",
    "#long(\"X_data_15.npz\",\"sil\",15)\n",
    "#long(\"X_data_newMorph.npz\",\"nm\",13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_train=np.load(path+\"/data/train_uber_sil_long_standard_c.npy\")\n",
    "sil_test=np.load(path+\"/data/test_uber_sil_long_standard_c.npy\")\n",
    "gel_train=np.load(path+\"/data/train_uber_gel_long_standard_c.npy\")\n",
    "gel_test=np.load(path+\"/data/test_uber_gel_long_standard_c.npy\")\n",
    "#nm_train=np.load(path+\"/data/train_uber_nm_long.npy\")\n",
    "#nm_test=np.load(path+\"/data/test_uber_nm_long.npy\")\n",
    "\n",
    "average_sil_test=np.average(sil_test,axis=1)*100\n",
    "max_sil_test=np.max(sil_test,axis=1)*100\n",
    "average_sil_train=np.average(sil_train,axis=1)*100\n",
    "average_gel_test=np.average(gel_test,axis=1)*100\n",
    "max_gel_test=np.max(gel_test,axis=1)*100\n",
    "average_gel_train=np.average(gel_train,axis=1)*100\n",
    "#average_nm_test=np.average(nm_test,axis=1)*100\n",
    "#max_nm_test=np.max(nm_test,axis=1)*100\n",
    "#average_nm_train=np.average(nm_train,axis=1)*100\n",
    "\n",
    "plt.plot(average_sil_test,c=\"b\",label=\"Silicone test\")\n",
    "plt.plot(max_sil_test,\"--\",c=\"b\",label=\"Silicone max\")\n",
    "plt.plot(average_gel_test,c=\"g\",label=\"Gel test\")\n",
    "plt.plot(max_gel_test,\"--\",c=\"g\",label=\"Gel max\")\n",
    "#plt.plot(average_nm_test,c=\"r\",label=\"NM test\")\n",
    "#plt.plot(max_nm_test,\"--\",c=\"r\",label=\"NM max\")\n",
    "\n",
    "#plt.plot(average_sil_train,c=\"b\",label=\"Silicone train\")\n",
    "resolution=[0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.7,0.8]\n",
    "plt.xticks([i for i in range(len(resolution))],resolution)\n",
    "plt.ylabel(\"Aacuracy %\")\n",
    "plt.xlabel(\"Resolution multiplier\")\n",
    "plt.title(\"Resolution vs accuracy on pretrained conv layer\",fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(path+\"/images/resolution_just_own_transfer.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "sil_history=np.load(path+\"/data/histroy_sil_long_untrained.npy\")\n",
    "gel_history=np.load(path+\"/data/histroy_gel_long_untrained.npy\")\n",
    "nm_history=np.load(path+\"/data/histroy_nm_long_untrained.npy\")\n",
    "print(sil_history.shape)\n",
    "\n",
    "sil_history_av=np.average(sil_history,axis=1)\n",
    "#gel_history_av=np.average(gel_history,axis=1)\n",
    "#nm_history_av=np.average(nm_history,axis=1)\n",
    "print(sil_history_av.shape)\n",
    "# Create a colormap that gets darker\n",
    "colors = cm.viridis(np.linspace(0, 1, len(resolution)))\n",
    "\n",
    "for i in range(len(sil_history_av)):\n",
    "    plt.plot(sil_history_av[i],color=colors[i],label=\"Resolution \"+str(resolution[i]))\n",
    "#plt.plot(gel_history_av,label=\"Average loss gel\")\n",
    "#plt.plot(nm_history_av,label=\"Average loss new morphology\")\n",
    "plt.title(\"Loss over training\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average loss\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(path+\"/images/resolution_loss_untrained.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_X=[]\n",
    "images_f=[]\n",
    "images_o=[]\n",
    "for i in range(len(resolution)-1):\n",
    "    filename=\"cnn_res\"+str(resolution[i])+\"_gel\"\n",
    "\n",
    "    data=loaded(4,filename=\"X_data_15.npz\")\n",
    "    data.applySobel()\n",
    "    data.resize(resolution[i])\n",
    "    image=data.X[0][0]\n",
    "\n",
    "    model = SimpleCNN(4*image.shape[0],image.shape[1],output=15).to(device)\n",
    "    model.load_state_dict(torch.load(path+\"/model/res/\"+filename))\n",
    "    model.eval()\n",
    "\n",
    "    sample=data.X[0:13]\n",
    "    sampley=data.y[0:13]\n",
    "\n",
    "    x=(sample-np.mean(sample))/(np.max(sample)-np.min(sample))\n",
    "    x=x.reshape((len(x),1,x.shape[1]*x.shape[2],x.shape[3]))\n",
    "\n",
    "    train_images_tensor = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "\n",
    "    #preds=torch.argmax(model(train_images_tensor)).cpu().detach().numpy()\n",
    "    x = model.pool(model.relu(model.conv1(train_images_tensor)))#.cpu().detach().numpy()\n",
    "    x = model.pool(model.relu(model.conv2(x))).cpu().detach().numpy()\n",
    "    images_X.append(train_images_tensor[0][0].cpu().detach().numpy())\n",
    "    images_f.append(x.copy())\n",
    "\n",
    "    model = SimpleCNN(4*image.shape[0],image.shape[1],output=15).to(device)\n",
    "    model.load_state_dict(torch.load(path+\"/model/learnedres/\"+filename))\n",
    "    model.eval()\n",
    "\n",
    "    #preds=torch.argmax(model(train_images_tensor)).cpu().detach().numpy()\n",
    "    x = model.pool(model.relu(model.conv1(train_images_tensor)))#.cpu().detach().numpy()\n",
    "    x = model.pool(model.relu(model.conv2(x))).cpu().detach().numpy()\n",
    "    images_o.append(x.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(3, len(resolution)-1, figsize=(10, 8))\n",
    "#axes = axes.flatten()\n",
    "\n",
    "for i in range(len(images_X)):\n",
    "    axes[0][i].imshow(images_X[i],cmap=\"gray\")\n",
    "    axes[0][i].axis(\"off\")\n",
    "    axes[0][i].set_ylabel(\"Original res \"+str(resolution[i]),fontsize=11)\n",
    "    #print(images_f[i][0].shape)\n",
    "    axes[1][i].imshow(images_f[i][0][0],cmap=\"gray\")\n",
    "    axes[1][i].axis(\"off\")\n",
    "    #axes[1][i].set_title(\"Feature res\"+str(resolution[i]),fontsize=11)\n",
    "    axes[2][i].imshow(images_o[i][1][0],cmap=\"gray\")\n",
    "    axes[2][i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+\"images/features_norm_transfer.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# playing with points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=loaded(t=10)\n",
    "data.applySobel()\n",
    "\n",
    "data2=loaded(filename=\"X_data_newMorph.npz\",t=10)\n",
    "data2.applySobel()\n",
    "\n",
    "data3=loaded(filename=\"X_data_nomarker.npz\",t=10)\n",
    "data3.applySobel()\n",
    "\n",
    "#data.augment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dense_optical_flows(dataset):\n",
    "    n, t, h, w = dataset.shape\n",
    "    optical_flows = np.zeros((n, t-1, h, w), dtype=np.uint8)  # Change to uint8 for 0-255 range\n",
    "    \n",
    "    # Optical flow parameters for higher sensitivity\n",
    "    pyr_scale = 0.1     # Lowered for more sensitivity to small movements\n",
    "    levels = 20         # Increased number of pyramid levels\n",
    "    winsize = 5         # Reduced window size for finer detail\n",
    "    iterations = 6      # More iterations per level\n",
    "    poly_n = 5          # Polynomial window size (typically fixed)\n",
    "    poly_sigma = 1.0    # Lowered for more detailed flow calculations\n",
    "    \n",
    "    for i in range(n):  # Loop over each sample\n",
    "        for j in range(t - 1):  # Loop over each pair of frames\n",
    "            # Convert frames to grayscale if needed\n",
    "            frame1 = dataset[i, j].astype(np.uint8)\n",
    "            frame2 = dataset[i, j + 1].astype(np.uint8)\n",
    "            \n",
    "            # Calculate dense optical flow with more sensitive parameters\n",
    "            flow = cv2.calcOpticalFlowFarneback(frame1, frame2, None, \n",
    "                                                pyr_scale, levels, winsize, \n",
    "                                                iterations, poly_n, poly_sigma, 0)\n",
    "            \n",
    "            # Calculate the magnitude and angle of the flow\n",
    "            mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "            \n",
    "            # Normalize the magnitude to the range 0-255 and convert to uint8\n",
    "            mag = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "            optical_flows[i, j] = mag  # Store the normalized magnitude\n",
    "\n",
    "    return optical_flows\n",
    "\n",
    "\n",
    "def compute_dense_optical_flows(dataset):\n",
    "    n, t, h, w = dataset.shape\n",
    "    optical_flows = np.zeros((n, t-1, h, w), dtype=np.uint8)  # Change to uint8 for 0-255 range\n",
    "    \n",
    "    # Parameters for Lucas-Kanade optical flow\n",
    "    lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
    "                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    \n",
    "    for i in range(n):  # Loop over each sample\n",
    "        for j in range(t - 1):  # Loop over each pair of frames\n",
    "            # Convert frames to grayscale if needed\n",
    "            frame1 = dataset[i, j].astype(np.uint8)\n",
    "            frame2 = dataset[i, j + 1].astype(np.uint8)\n",
    "            \n",
    "            # Detect good features to track in the first frame\n",
    "            p0 = cv2.goodFeaturesToTrack(frame1, mask=None, maxCorners=500, qualityLevel=0.01, minDistance=5)\n",
    "            \n",
    "            # Calculate optical flow using Lucas-Kanade\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(frame1, frame2, p0, None, **lk_params)\n",
    "            \n",
    "            # Filter only good points where flow is successfully calculated\n",
    "            if p1 is not None:\n",
    "                good_new = p1[st == 1]\n",
    "                good_old = p0[st == 1]\n",
    "                \n",
    "                # Create a mask to draw the optical flow vectors\n",
    "                mask = np.zeros_like(frame1, dtype=np.uint8)\n",
    "                \n",
    "                # Draw the optical flow vectors\n",
    "                for (new, old) in zip(good_new, good_old):\n",
    "                    a, b = new.ravel()\n",
    "                    c, d = old.ravel()\n",
    "                    cv2.line(mask, (int(c), int(d)), (int(a), int(b)), 255, 1)\n",
    "                    \n",
    "                # Store the mask as the flow field representation for this pair of frames\n",
    "                optical_flows[i, j] = mask\n",
    "\n",
    "    return optical_flows\n",
    "    \n",
    "flow_data=compute_dense_optical_flows(data.X)\n",
    "flow_data2=compute_dense_optical_flows(data2.X)\n",
    "flow_data3=compute_dense_optical_flows(data3.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(dataset, y, segment_size=0.2):\n",
    "    n, t, h, w = dataset.shape\n",
    "    \n",
    "    # Create an empty array for the augmented data\n",
    "    augmented_data = dataset.copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(t):\n",
    "            # Randomly determine the segment's position and size\n",
    "            seg_h = int(h * segment_size)\n",
    "            seg_w = int(w * segment_size)\n",
    "            start_h = np.random.randint(0, h - seg_h)\n",
    "            start_w = np.random.randint(0, w - seg_w)\n",
    "            \n",
    "            # Remove (mask) the segment in the image\n",
    "            augmented_data[i, j, start_h:start_h + seg_h, start_w:start_w + seg_w] = 0\n",
    "    \n",
    "    # Concatenate the original and augmented data\n",
    "    combined_data = np.concatenate((dataset, augmented_data), axis=0)\n",
    "    \n",
    "    # Duplicate the labels for the augmented dataset\n",
    "    combined_y = np.concatenate((y, y), axis=0)\n",
    "    \n",
    "    # Shuffle the combined dataset and labels together\n",
    "    indices = np.arange(2 * n)\n",
    "    np.random.shuffle(indices)\n",
    "    combined_data = combined_data[indices]\n",
    "    combined_y = combined_y[indices]\n",
    "    \n",
    "    return combined_data, combined_y\n",
    "\n",
    "flow_data_a,flow_y=augment(flow_data,data.y)\n",
    "#flow_data_a,flow_y=augment(np.concatenate([flow_data,flow_data2,flow_data3]),np.concatenate([data.y,data2.y,data3.y]))\n",
    "flow_data_a,flow_y=augment(flow_data_a,flow_y)\n",
    "flow_data_a,flow_y=augment(flow_data_a,flow_y)\n",
    "#flow_data_a,flow_y=augment(flow_data2,data2.y)\n",
    "#flow_data_a=flow_data\n",
    "#flow_y=data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_grid(images_grid,data):\n",
    "    \"\"\"\n",
    "    Plots a grid of images, where each sublist in images_grid represents a row of images.\n",
    "    \n",
    "    Parameters:\n",
    "    images_grid (list of lists): List of lists where each sublist contains images for a row.\n",
    "    \"\"\"\n",
    "    num_rows = len(images_grid)\n",
    "    num_cols = max(len(row) for row in images_grid)\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 2, num_rows * 2))\n",
    "    \n",
    "    # Flatten axes if there's only one row or column for consistency\n",
    "    if num_rows == 1:\n",
    "        axes = [axes]\n",
    "    if num_cols == 1:\n",
    "        axes = [[ax] for ax in axes]\n",
    "    c=0\n",
    "    # Plot each image in the correct position\n",
    "    for row_idx, row_images in enumerate(images_grid):\n",
    "        for col_idx, img in enumerate(row_images):\n",
    "            ax = axes[row_idx][col_idx]\n",
    "            ax.set_title(data.keys[data.y[c]])\n",
    "            ax.imshow(img, cmap='gist_heat' if img.ndim == 2 else None)\n",
    "            ax.axis('off')  # Hide the axes for a cleaner look\n",
    "        c+=1\n",
    "    # Hide any unused subplots if the rows have different lengths\n",
    "    for row_idx in range(num_rows):\n",
    "        for col_idx in range(len(images_grid[row_idx]), num_cols):\n",
    "            axes[row_idx][col_idx].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_images_grid(flow_data_a[0:5],data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train network on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=-1\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(flow_y[0:n])\n",
    "one_hot_labels = torch.nn.functional.one_hot(torch.tensor(train_labels_encoded), num_classes=len(np.unique(train_labels_encoded)))\n",
    "x_data=flow_data_a[0:n].reshape((len(flow_data_a[0:n]),1,abs(flow_data_a.shape[1])*flow_data_a.shape[2],flow_data_a.shape[3]))\n",
    "x_data=(x_data-np.mean(x_data))/(np.max(x_data)-np.min(x_data)) #preprocessing\n",
    "train_images_tensor = torch.tensor(x_data, dtype=torch.float32).to(device)\n",
    "del x_data\n",
    "train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "# Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader for training and testing sets\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=40, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=40,shuffle=False)\n",
    "model,history=run(train_loader,0,4,num_epochs = 100)\n",
    "print(calc(model,test_loader))\n",
    "print(calc(model,train_loader))\n",
    "torch.save(model.state_dict(), path+\"/model/mymodelcnn_optic_flow\") #\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/NewRigExperiments/model/mymodelgel\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=-1\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(flow_y[0:n])\n",
    "one_hot_labels = torch.nn.functional.one_hot(torch.tensor(train_labels_encoded), num_classes=len(np.unique(train_labels_encoded)))\n",
    "x_data=flow_data_a[0:n].reshape((len(flow_data_a[0:n]),abs(flow_data_a.shape[1]),flow_data_a.shape[2]*flow_data_a.shape[3]))\n",
    "#x_data=(x_data-np.mean(x_data))/(np.max(x_data)-np.min(x_data)) #preprocessing\n",
    "x/=255\n",
    "train_images_tensor = torch.tensor(x_data, dtype=torch.float32).to(device)\n",
    "del x_data\n",
    "train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "# Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader for training and testing sets\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=40, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=40,shuffle=False)\n",
    "model,history=runLSTM(train_loader,0,10,num_epochs = 200)\n",
    "print(calc(model,test_loader))\n",
    "print(calc(model,train_loader))\n",
    "torch.save(model.state_dict(), path+\"/model/mymodellstm_optic_flow\") #\"/its/home/drs25/Documents/GitHub/RoboSkin/Code/NewRigExperiments/model/mymodelgel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=-1\n",
    "x_data=flow_data[0:n].reshape((len(flow_data[0:n]),abs(flow_data.shape[1]),flow_data.shape[2]*flow_data.shape[3]))\n",
    "image=x_data[0][0]\n",
    "model = SimpleLSTM(image.shape[0],350,15).to(device)#.half()\n",
    "model.load_state_dict(torch.load(path+\"/model/mymodellstm_optic_flow\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=-1\n",
    "x_data=flow_data[0:n].reshape((len(flow_data[0:n]),1,abs(flow_data.shape[1])*flow_data.shape[2],flow_data.shape[3]))\n",
    "image=x_data[0][0]\n",
    "model = SimpleCNN(image.shape[0],image.shape[1],15).to(device)#.half()\n",
    "model.load_state_dict(torch.load(path+\"/model/mymodelcnn_optic_flow\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=200\n",
    "torch.cuda.empty_cache()\n",
    "x=torch.tensor(flow_data2.reshape((flow_data2.shape[0],flow_data2.shape[1],flow_data2.shape[2]*flow_data2.shape[3])), dtype=torch.float32).to(device) #lstm\n",
    "#x=torch.tensor(flow_data2.reshape((flow_data2.shape[0],1,flow_data2.shape[1]*flow_data2.shape[2],flow_data2.shape[3])), dtype=torch.float32).to(device) #cnn\n",
    "x/=255\n",
    "#x=(x-torch.mean(x))/(torch.max(x)-torch.min(x)) #preprocessing\n",
    "preds=model(x[0:sample])\n",
    "vals=torch.argmax(preds,axis=1).cpu().detach().numpy()\n",
    "error=np.abs(vals-data2.y[0:sample])\n",
    "\n",
    "print(\"Accuracy \",len(np.where(error==0)[0]),\"/400\",\":\",len(np.where(error==0)[0])/400 *100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "sample=200\n",
    "x=torch.tensor(flow_data3.reshape((flow_data3.shape[0],flow_data3.shape[1],flow_data3.shape[2]*flow_data3.shape[3])), dtype=torch.float32).to(device) #lstm\n",
    "#x=torch.tensor(flow_data3.reshape((flow_data3.shape[0],1,flow_data3.shape[1]*flow_data3.shape[2],flow_data3.shape[3])), dtype=torch.float32).to(device) #cnn\n",
    "x/=255\n",
    "#x=(x-torch.mean(x))/(torch.max(x)-torch.min(x)) #preprocessing\n",
    "preds=model(x[0:sample])\n",
    "vals=torch.argmax(preds,axis=1).cpu().detach().numpy()\n",
    "error=np.abs(vals-data3.y[0:sample])\n",
    "\n",
    "print(\"Accuracy \",len(np.where(error==0)[0]),\"/400\",\":\",len(np.where(error==0)[0])/400 *100,\"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_layers, num_classes, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        # Embedding layer to convert inputs to model dimension\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        \n",
    "        # Transformer Encoder Layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output layer to map to number of classes\n",
    "        self.fc_out = nn.Linear(model_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply embedding\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Transformer encoder expects input as (sequence_length, batch_size, model_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        # Apply transformer encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # Get the mean of the output sequence (global average pooling)\n",
    "        x = x.mean(dim=0)\n",
    "        \n",
    "        # Output layer\n",
    "        output = self.fc_out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_Tmodel(model, train_loader, test_loader, num_epochs, learning_rate=0.001):\n",
    "    # Set up the optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Train the model on the training data\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            predicted = torch.argmax(outputs,axis=1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(torch.argmax(labels,axis=1)).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "        # Evaluate the model on the test data\n",
    "        evaluate_Tmodel(model, test_loader)\n",
    "\n",
    "def evaluate_Tmodel(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.argmax(outputs,axis=1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(torch.argmax(labels,axis=1)).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=-1\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(flow_y[0:n])\n",
    "one_hot_labels = torch.nn.functional.one_hot(torch.tensor(train_labels_encoded), num_classes=len(np.unique(train_labels_encoded)))\n",
    "x_data=flow_data_a[0:n].reshape((len(flow_data_a[0:n]),abs(flow_data_a.shape[1]),flow_data_a.shape[2]*flow_data_a.shape[3])).astype(np.float64)\n",
    "#x_data=(x_data-np.mean(x_data))/(np.max(x_data)-np.min(x_data)) #preprocessing\n",
    "x_data/=255\n",
    "train_images_tensor = torch.tensor(x_data, dtype=torch.float32).to(device)\n",
    "train_labels_tensor = torch.tensor(one_hot_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "# Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader for training and testing sets\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=40, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=40,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomorrow to do\n",
    "#work out paramaters for model\n",
    "model=TransformerModel(x_data.shape[2],20,20,3,15).to(device)\n",
    "train_Tmodel(model, train_loader, test_loader,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General experiments *salute* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def augment_with_missing_data(data, mask_fraction=0.3, random_seed=None):\n",
    "    \"\"\"\n",
    "    Augments a dataset by randomly removing large portions of the data.\n",
    "\n",
    "    Parameters:\n",
    "    - data (numpy array): Input data of shape (n, t, h, w)\n",
    "    - mask_fraction (float): Fraction of each image to be removed (0-1)\n",
    "    - random_seed (int): Optional seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - augmented_data (numpy array): Augmented dataset\n",
    "    \"\"\"\n",
    "    if random_seed:\n",
    "        random.seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    n, t, h, w = data.shape\n",
    "    augmented_data = data.copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(t):\n",
    "            # Determine mask size\n",
    "            mask_height = int(h * mask_fraction)\n",
    "            mask_width = int(w * mask_fraction)\n",
    "            \n",
    "            # Choose a random position for the mask\n",
    "            top_left_y = random.randint(0, h - mask_height)\n",
    "            top_left_x = random.randint(0, w - mask_width)\n",
    "            \n",
    "            # Apply the mask\n",
    "            augmented_data[i, j, top_left_y:top_left_y + mask_height, top_left_x:top_left_x + mask_width] = 0\n",
    "    \n",
    "    return augmented_data\n",
    "\n",
    "# Example usage:\n",
    "data=loaded(t=5)\n",
    "data.applySobel()\n",
    "data.augment()\n",
    "augmented_data = augment_with_missing_data(data.X, mask_fraction=0.3, random_seed=42)\n",
    "data_=augmented_data.reshape((len(augmented_data),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_components = 30  # Number of principal components to retain\n",
    "pca = PCA(n_components=n_components)\n",
    "pca_data = pca.fit_transform(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_data, data.y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train a Random Forest Classifier\n",
    "rfc = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions and evaluate the model\n",
    "y_pred = rfc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy of Random Forest Classifier:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=loaded(filename=\"X_data_newMorph.npz\",t=5)\n",
    "data.applySobel()\n",
    "data.augment()\n",
    "\n",
    "data_alt=data.X.reshape((len(data.X),-1))\n",
    "pca_data = pca.fit_transform(data_alt)\n",
    "y_pred = rfc.predict(pca_data)\n",
    "accuracy = accuracy_score(data.y, y_pred)\n",
    "print(\"Accuracy of Random Forest Classifier:\", accuracy)\n",
    "print(\"\\nClassification Report:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
